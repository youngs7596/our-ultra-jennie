#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Scout v1.0 FactorAnalyzer - ì˜¤í”„ë¼ì¸ íŒ©í„° ë¶„ì„ ë°°ì¹˜ ì‘ì—…

ì—­í• : Scoutì˜ 'ì§€ëŠ¥'ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ì£¼ê¸°ì  ë°°ì¹˜ ì‘ì—… (ì£¼ 1íšŒ)

ì£¼ìš” ê¸°ëŠ¥:
1. íŒ©í„° ì˜ˆì¸¡ë ¥ ë¶„ì„: IC(Information Coefficient), IR(Information Ratio) ê³„ì‚°
2. ì¡°ê±´ë¶€ ìŠ¹ë¥  ë¶„ì„: "ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ + ë‰´ìŠ¤ì ìˆ˜ 70â†‘" â†’ ìŠ¹ë¥  80%
3. ë‰´ìŠ¤ ì˜í–¥ë„ ë¶„ì„: ì¹´í…Œê³ ë¦¬ë³„ D+5 ìŠ¹ë¥ , í‰ê·  ìˆ˜ìµë¥ 
4. [v1.0.2] ì¬ë¬´ ë°ì´í„°(PER/PBR/ROE) DB ì—°ë™
5. [v1.0.2] ë‰´ìŠ¤+ìˆ˜ê¸‰ ë³µí•© ì¡°ê±´ ë¶„ì„
6. [v1.0.2] NEWS_FACTOR_STATS í…Œì´ë¸” ì±„ìš°ê¸°
7. [v1.0.2] Recency Weighting ê°€ì¤‘ì¹˜ ë°˜ì˜

ë¶„ì„ ê²°ê³¼ëŠ” DBì— ì €ì¥ë˜ì–´ QuantScorerì—ì„œ í™œìš©ë©ë‹ˆë‹¤.

[GPT í”¼ë“œë°± ë°˜ì˜]
- ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ ìŠ¹ë¥  ë¶„ì„ ì¶”ê°€
- ì™¸êµ­ì¸/ê¸°ê´€ ìˆ˜ê¸‰ ì¡°ê±´ ë¶„ì„ ì¶”ê°€
- PER/PBR/ROE ì¬ë¬´ ë°ì´í„° DB ì—°ë™
- Recency Weighting ì‹¤ì œ ê°€ì¤‘ì¹˜ ë°˜ì˜
"""

import logging
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, TYPE_CHECKING
from datetime import datetime, timedelta, timezone
from dataclasses import dataclass

from .schema import (
    get_confidence_level,
    create_hybrid_scoring_tables,
    execute_upsert,
    is_oracle,
)
from shared.database import _is_mariadb

# [v1.1] SQLAlchemy Repository ì§€ì› (í…ŒìŠ¤íŠ¸ ìš©ì´ì„±)
if TYPE_CHECKING:
    from shared.db.factor_repository import FactorRepository

logger = logging.getLogger(__name__)


@dataclass
class FactorAnalysisResult:
    """íŒ©í„° ë¶„ì„ ê²°ê³¼"""
    factor_key: str
    factor_name: str
    ic_mean: float           # Information Coefficient í‰ê· 
    ic_std: float            # IC í‘œì¤€í¸ì°¨
    ir: float                # Information Ratio
    hit_rate: float          # ì ì¤‘ë¥ 
    recommended_weight: float # ì¶”ì²œ ê°€ì¤‘ì¹˜
    sample_count: int        # í‘œë³¸ ìˆ˜


@dataclass
class ConditionPerformance:
    """ì¡°ê±´ë¶€ ì„±ê³¼ ê²°ê³¼"""
    target_type: str         # STOCK, SECTOR, ALL
    target_code: str         # ì¢…ëª©ì½”ë“œ/ì„¹í„°ì½”ë“œ/ALL
    condition_key: str       # ì¡°ê±´ í‚¤
    condition_desc: str      # ì¡°ê±´ ì„¤ëª…
    win_rate: float          # ìŠ¹ë¥ 
    avg_return: float        # í‰ê·  ìˆ˜ìµë¥ 
    sample_count: int        # í‘œë³¸ ìˆ˜
    recent_win_rate: float   # ìµœê·¼ 3ê°œì›” ìŠ¹ë¥ 
    recent_sample_count: int # ìµœê·¼ 3ê°œì›” í‘œë³¸


class FactorAnalyzer:
    """
    ì˜¤í”„ë¼ì¸ íŒ©í„° ë¶„ì„ê¸°
    
    ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ íŒ©í„°ë³„ ì˜ˆì¸¡ë ¥ì„ ì¸¡ì •í•˜ê³  DBì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    
    # ë¶„ì„ ê¸°ê°„ ì„¤ì •
    DEFAULT_LOOKBACK_YEARS = 2     # ê¸°ë³¸ ë¶„ì„ ê¸°ê°„ (2ë…„)
    RECENT_MONTHS = 3              # ìµœê·¼ì„± ë¶„ì„ ê¸°ê°„ (3ê°œì›”)
    FORWARD_DAYS = [5, 10, 20]     # ë¯¸ë˜ ìˆ˜ìµë¥  ì¸¡ì • ê¸°ê°„
    
    # íŒ©í„° ì •ì˜
    FACTOR_DEFINITIONS = {
        'momentum_6m': {
            'name': '6ê°œì›” ëª¨ë©˜í…€',
            'calc_func': '_calc_momentum_6m',
        },
        'momentum_1m': {
            'name': '1ê°œì›” ëª¨ë©˜í…€',
            'calc_func': '_calc_momentum_1m',
        },
        'value_per': {
            'name': 'PER (ì €í‰ê°€)',
            'calc_func': '_calc_per_factor',
        },
        'value_pbr': {
            'name': 'PBR (ì €í‰ê°€)',
            'calc_func': '_calc_pbr_factor',
        },
        'quality_roe': {
            'name': 'ROE (ìˆ˜ìµì„±)',
            'calc_func': '_calc_roe_factor',
        },
        'technical_rsi_oversold': {
            'name': 'RSI ê³¼ë§¤ë„',
            'calc_func': '_calc_rsi_oversold',
        },
        'supply_foreign_buy': {
            'name': 'ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜',
            'calc_func': '_calc_foreign_buy',
        },
    }
    
    # ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ì •ì˜
    NEWS_CATEGORIES = [
        'ì‹¤ì ',      # ì–´ë‹ ì„œí”„ë¼ì´ì¦ˆ/ì‡¼í¬
        'ìˆ˜ì£¼',      # ëŒ€ê·œëª¨ ê³„ì•½
        'ì‹ ì‚¬ì—…',    # ì‹ ê·œ ì§„ì¶œ
        'M&A',      # ì¸ìˆ˜í•©ë³‘
        'ë°°ë‹¹',      # ë°°ë‹¹ ë°œí‘œ
        'ê·œì œ',      # ê·œì œ ì´ìŠˆ
        'ê²½ì˜',      # ê²½ì˜ê¶Œ ë¶„ìŸ, CEO ì´ìŠˆ
    ]

    DISCLOSURE_TABLE = 'STOCK_DISCLOSURES'
    
    # [v1.0.5] ì‹œì¥ êµ­ë©´ ì •ì˜
    MARKET_REGIME_THRESHOLDS = {
        'BULL': 0.10,      # 6ê°œì›” ìˆ˜ìµë¥  +10% ì´ìƒ
        'BEAR': -0.10,     # 6ê°œì›” ìˆ˜ìµë¥  -10% ì´í•˜
        'SIDEWAYS': 0.0,   # ê·¸ ì‚¬ì´
    }
    
    # [v1.0.5] ì¢…ëª© ê·¸ë£¹ ë¶„ë¥˜ (ì‹œê°€ì´ì•¡ ê¸°ì¤€)
    STOCK_GROUP_THRESHOLDS = {
        'LARGE': 10_000_000_000_000,   # 10ì¡° ì´ìƒ: ëŒ€í˜•ì£¼
        'MID': 1_000_000_000_000,      # 1ì¡° ì´ìƒ: ì¤‘í˜•ì£¼
        'SMALL': 0,                     # ê·¸ ì™¸: ì†Œí˜•ì£¼
    }
    
    def __init__(self, db_conn=None, *, repository: "FactorRepository" = None):
        """
        ì´ˆê¸°í™”
        
        [v1.1] ë‘ ê°€ì§€ ëª¨ë“œ ì§€ì›:
        1. ë ˆê±°ì‹œ ëª¨ë“œ: db_conn ì§ì ‘ ì „ë‹¬ (í•˜ìœ„ í˜¸í™˜ì„±)
        2. Repository ëª¨ë“œ: FactorRepository ì£¼ì… (í…ŒìŠ¤íŠ¸ ìš©ì´)
        
        Args:
            db_conn: DB ì—°ê²° ê°ì²´ (ë ˆê±°ì‹œ, deprecated)
            repository: FactorRepository ì¸ìŠ¤í„´ìŠ¤ (ê¶Œì¥)
        
        Usage:
            # ë ˆê±°ì‹œ ë°©ì‹ (í•˜ìœ„ í˜¸í™˜ì„±)
            analyzer = FactorAnalyzer(db_conn)
            
            # ê¶Œì¥ ë°©ì‹ (í…ŒìŠ¤íŠ¸ ìš©ì´)
            from shared.db.factor_repository import FactorRepository
            repo = FactorRepository(session)
            analyzer = FactorAnalyzer(repository=repo)
        """
        self.db_conn = db_conn
        self._repository = repository
        
        # Repository ëª¨ë“œì¸ ê²½ìš° db_conn í•„ìš” ì—†ìŒ
        if repository is not None:
            logger.info("   [FactorAnalyzer] Repository ëª¨ë“œë¡œ ì´ˆê¸°í™”")
        elif db_conn is not None:
            # ë ˆê±°ì‹œ ëª¨ë“œ: í…Œì´ë¸” ìƒì„± í™•ì¸
            create_hybrid_scoring_tables(db_conn)
            logger.info("   [FactorAnalyzer] ë ˆê±°ì‹œ(db_conn) ëª¨ë“œë¡œ ì´ˆê¸°í™”")
        else:
            logger.warning("âš ï¸ [FactorAnalyzer] DB ì—°ê²° ì—†ì´ ì´ˆê¸°í™”ë¨ (ë¶„ì„ ê¸°ëŠ¥ ì œí•œ)")
        
        # [v1.0.5] ì‹œì¥ êµ­ë©´ ìºì‹œ
        self._market_regime_cache = None
        self._stock_group_cache = {}
        
        logger.info("âœ… FactorAnalyzer ì´ˆê¸°í™” ì™„ë£Œ")
    
    @property
    def repository(self) -> Optional["FactorRepository"]:
        """Repository ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (lazy initialization)"""
        if self._repository is not None:
            return self._repository
        
        # ë ˆê±°ì‹œ ëª¨ë“œì—ì„œ repositoryê°€ í•„ìš”í•œ ê²½ìš° ìë™ ìƒì„±
        if self.db_conn is not None:
            try:
                from shared.db.factor_repository import FactorRepository
                from shared.db.connection import get_session
                
                session = get_session()
                self._repository = FactorRepository(session)
                logger.debug("   [FactorAnalyzer] Repository ìë™ ìƒì„±")
                return self._repository
            except Exception as e:
                logger.warning(f"âš ï¸ [FactorAnalyzer] Repository ìë™ ìƒì„± ì‹¤íŒ¨: {e}")
        
        return None
    
    def detect_market_regime(self, lookback_days: int = 120) -> str:
        """
        [v1.0.5] í˜„ì¬ ì‹œì¥ êµ­ë©´ ê°ì§€
        
        KOSPI 200 ì§€ìˆ˜ì˜ ìµœê·¼ 6ê°œì›” ìˆ˜ìµë¥ ë¡œ íŒë‹¨:
        - BULL: +10% ì´ìƒ
        - BEAR: -10% ì´í•˜
        - SIDEWAYS: ê·¸ ì‚¬ì´
        
        Returns:
            'BULL', 'BEAR', 'SIDEWAYS'
        """
        if self._market_regime_cache:
            return self._market_regime_cache
        
        try:
            cursor = self.db_conn.cursor()
            
            # KOSPI 200 ì§€ìˆ˜ ë°ì´í„° ì¡°íšŒ (ì¢…ëª©ì½”ë“œ '0001' ë˜ëŠ” ë³„ë„ í…Œì´ë¸”)
            cursor.execute("""
                SELECT CLOSE_PRICE, PRICE_DATE
                FROM STOCK_DAILY_PRICES_3Y
                WHERE STOCK_CODE = '0001'
                ORDER BY PRICE_DATE DESC
                LIMIT %s
            """, (lookback_days,))
            
            rows = cursor.fetchall()
            cursor.close()
            
            if len(rows) < 30:
                logger.warning("   ì‹œì¥ êµ­ë©´ ê°ì§€: KOSPI ë°ì´í„° ë¶€ì¡±, SIDEWAYS ê¸°ë³¸ê°’ ì‚¬ìš©")
                return 'SIDEWAYS'
            
            # ìˆ˜ìµë¥  ê³„ì‚°
            recent_price = rows[0][0] if not isinstance(rows[0], dict) else rows[0]['CLOSE_PRICE']
            old_price = rows[-1][0] if not isinstance(rows[-1], dict) else rows[-1]['CLOSE_PRICE']
            
            returns = (recent_price / old_price - 1)
            
            if returns >= self.MARKET_REGIME_THRESHOLDS['BULL']:
                regime = 'BULL'
            elif returns <= self.MARKET_REGIME_THRESHOLDS['BEAR']:
                regime = 'BEAR'
            else:
                regime = 'SIDEWAYS'
            
            self._market_regime_cache = regime
            logger.info(f"   ğŸ“ˆ ì‹œì¥ êµ­ë©´ ê°ì§€: {regime} (6ê°œì›” ìˆ˜ìµë¥ : {returns:.1%})")
            
            return regime
            
        except Exception as e:
            logger.warning(f"   ì‹œì¥ êµ­ë©´ ê°ì§€ ì‹¤íŒ¨: {e}, SIDEWAYS ê¸°ë³¸ê°’ ì‚¬ìš©")
            return 'SIDEWAYS'
    
    def classify_stock_group(self, stock_code: str) -> str:
        """
        [v1.0.5] ì¢…ëª© ê·¸ë£¹ ë¶„ë¥˜ (ì‹œê°€ì´ì•¡ ê¸°ì¤€)
        [v1.1] Repository ëª¨ë“œ ì§€ì›
        
        Returns:
            'LARGE', 'MID', 'SMALL'
        """
        if stock_code in self._stock_group_cache:
            return self._stock_group_cache[stock_code]
        
        try:
            # [v1.1] Repository ëª¨ë“œ ìš°ì„ 
            if self.repository is not None:
                market_cap = self.repository.get_market_cap(stock_code)
            else:
                # ë ˆê±°ì‹œ ëª¨ë“œ
                cursor = self.db_conn.cursor()
                cursor.execute("""
                    SELECT MARKET_CAP FROM STOCK_MASTER WHERE STOCK_CODE = %s
                """, (stock_code,))
                
                row = cursor.fetchone()
                cursor.close()
                
                if not row:
                    return 'SMALL'
                
                market_cap = row[0] if not isinstance(row, dict) else row.get('MARKET_CAP', 0)
            
            if market_cap is None:
                market_cap = 0
            
            if market_cap >= self.STOCK_GROUP_THRESHOLDS['LARGE']:
                group = 'LARGE'
            elif market_cap >= self.STOCK_GROUP_THRESHOLDS['MID']:
                group = 'MID'
            else:
                group = 'SMALL'
            
            self._stock_group_cache[stock_code] = group
            return group
            
        except Exception as e:
            logger.debug(f"   ì¢…ëª© ê·¸ë£¹ ë¶„ë¥˜ ì‹¤íŒ¨ ({stock_code}): {e}")
            return 'SMALL'
    
    # [v1.0.6 Phase B] ì„¹í„° ë¶„ë¥˜
    SECTOR_MAPPING = {
        # KOSPI200 ì„¹í„° ì½”ë“œ ë§¤í•‘
        'ë°˜ë„ì²´': ['005930', '000660', '034730', '042700'],  # ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤ ë“±
        'ë°”ì´ì˜¤': ['068270', '207940', '091990', '145020'],  # ì…€íŠ¸ë¦¬ì˜¨, ì‚¼ë°” ë“±
        'ê¸ˆìœµ': ['105560', '055550', '086790', '316140'],    # KB, ì‹ í•œ ë“±
        'ìë™ì°¨': ['005380', '000270', '012330', '011210'],  # í˜„ëŒ€ì°¨, ê¸°ì•„ ë“±
        'í™”í•™': ['051910', '011170', '009830', '010140'],    # LGí™”í•™ ë“±
        'ê±´ì„¤': ['000720', '006360', '047050', '034310'],    # í˜„ëŒ€ê±´ì„¤ ë“±
        'ì² ê°•': ['005490', '004020', '000880', '001450'],    # POSCO ë“±
        'ìœ í†µ': ['035420', '035720', '034220', '030200'],    # ë„¤ì´ë²„, ì¹´ì¹´ì˜¤ ë“±
    }
    
    def get_stock_sector(self, stock_code: str) -> str:
        """
        [v1.0.6 Phase B] ì¢…ëª©ì˜ ì„¹í„° ë¶„ë¥˜
        [v1.1] Repository ëª¨ë“œ ì§€ì›
        
        STOCK_MASTERì˜ SECTOR_KOSPI200 ë˜ëŠ” INDUSTRY_CODE ê¸°ë°˜
        """
        # ìºì‹œ í™•ì¸
        cache_key = f"sector_{stock_code}"
        if hasattr(self, '_sector_cache') and cache_key in self._sector_cache:
            return self._sector_cache[cache_key]
        
        if not hasattr(self, '_sector_cache'):
            self._sector_cache = {}
        
        # í•˜ë“œì½”ë”©ëœ ë§¤í•‘ ë¨¼ì € í™•ì¸
        for sector, codes in self.SECTOR_MAPPING.items():
            if stock_code in codes:
                self._sector_cache[cache_key] = sector
                return sector
        
        # DBì—ì„œ ì¡°íšŒ
        try:
            # [v1.1] Repository ëª¨ë“œ ìš°ì„ 
            if self.repository is not None:
                sector_kospi, industry_code = self.repository.get_stock_sector(stock_code)
                sector = sector_kospi or industry_code
            else:
                # ë ˆê±°ì‹œ ëª¨ë“œ
                cursor = self.db_conn.cursor()
                cursor.execute("""
                    SELECT SECTOR_KOSPI200, INDUSTRY_CODE 
                    FROM STOCK_MASTER 
                    WHERE STOCK_CODE = %s
                """, (stock_code,))
                
                row = cursor.fetchone()
                cursor.close()
                
                if row:
                    sector = row[0] if not isinstance(row, dict) else row.get('SECTOR_KOSPI200')
                else:
                    sector = None
            
            if sector:
                self._sector_cache[cache_key] = sector
                return sector
            
            self._sector_cache[cache_key] = 'ê¸°íƒ€'
            return 'ê¸°íƒ€'
            
        except Exception as e:
            logger.debug(f"   ì„¹í„° ë¶„ë¥˜ ì‹¤íŒ¨ ({stock_code}): {e}")
            return 'ê¸°íƒ€'
    
    def group_stocks_by_sector(self, stock_codes: List[str]) -> Dict[str, List[str]]:
        """
        [v1.0.6 Phase B] ì¢…ëª©ë“¤ì„ ì„¹í„°ë³„ë¡œ ê·¸ë£¹í™”
        """
        sector_groups = {}
        
        for code in stock_codes:
            sector = self.get_stock_sector(code)
            if sector not in sector_groups:
                sector_groups[sector] = []
            sector_groups[sector].append(code)
        
        return sector_groups
    
    def analyze_by_sector(self, 
                          stock_codes: List[str],
                          factor_key: str = 'technical_rsi_oversold',
                          forward_days: int = 5) -> Dict[str, Dict]:
        """
        [v1.0.6 Phase B] ì„¹í„°ë³„ íŒ©í„° ë¶„ì„
        
        Returns:
            {sector: {ic_mean, hit_rate, sample_count, ...}}
        """
        logger.info(f"   ğŸ“Š ì„¹í„°ë³„ {factor_key} ë¶„ì„ (D+{forward_days})")
        
        sector_groups = self.group_stocks_by_sector(stock_codes)
        results = {}
        
        for sector, codes in sector_groups.items():
            if len(codes) < 5:  # ìµœì†Œ 5ê°œ ì¢…ëª© ì´ìƒ
                continue
            
            try:
                result = self.analyze_factor(codes, factor_key, forward_days)
                if result and result.sample_count >= 30:
                    results[sector] = {
                        'ic_mean': result.ic_mean,
                        'hit_rate': result.hit_rate,
                        'sample_count': result.sample_count,
                        'stock_count': len(codes),
                    }
                    logger.info(f"      {sector} ({len(codes)}ê°œ): "
                               f"IC={result.ic_mean:.4f}, ì ì¤‘ë¥ ={result.hit_rate:.1%}")
            except Exception as e:
                logger.debug(f"      {sector} ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return results
    
    def _is_mariadb(self) -> bool:
        """í˜„ì¬ DB íƒ€ì…ì´ MariaDBì¸ì§€ í™•ì¸"""
        import os
        return os.getenv("DB_TYPE", "ORACLE").upper() == "MARIADB"
    
    def _get_historical_prices(self, 
                               stock_codes: List[str],
                               days: int = 504) -> Dict[str, pd.DataFrame]:
        """
        ì¢…ëª©ë³„ ê³¼ê±° ê°€ê²© ë°ì´í„° ì¡°íšŒ
        
        [v1.1] Repository ëª¨ë“œ ì§€ì› (SQLAlchemy ORM)
        
        Args:
            stock_codes: ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
            days: ì¡°íšŒ ì¼ìˆ˜ (ê¸°ë³¸ 504ì¼ â‰ˆ 2ë…„)
        
        Returns:
            {stock_code: DataFrame} ë”•ì…”ë„ˆë¦¬
        """
        # [v1.1] Repository ëª¨ë“œ ìš°ì„ 
        if self.repository is not None:
            return self.repository.get_historical_prices_bulk(stock_codes, days)
        
        # ë ˆê±°ì‹œ ëª¨ë“œ (raw SQL)
        result = {}
        
        try:
            cursor = self.db_conn.cursor()
            
            for code in stock_codes:
                cursor.execute("""
                    SELECT PRICE_DATE, CLOSE_PRICE, VOLUME, HIGH_PRICE, LOW_PRICE
                    FROM STOCK_DAILY_PRICES_3Y
                    WHERE STOCK_CODE = %s
                    ORDER BY PRICE_DATE DESC
                    LIMIT %s
                """, (code, days))
                
                rows = cursor.fetchall()
                
                if rows:
                    if isinstance(rows[0], dict):
                        df = pd.DataFrame(rows)
                    else:
                        df = pd.DataFrame(rows, columns=[
                            'PRICE_DATE', 'CLOSE_PRICE', 'VOLUME', 'HIGH_PRICE', 'LOW_PRICE'
                        ])
                    
                    df = df.sort_values('PRICE_DATE').reset_index(drop=True)
                    result[code] = df
            
            cursor.close()
            
        except Exception as e:
            logger.error(f"   (FactorAnalyzer) ê°€ê²© ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return result
    
    def _calculate_forward_returns(self, 
                                   df: pd.DataFrame,
                                   forward_days: int = 5) -> pd.Series:
        """
        ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°
        
        Args:
            df: ê°€ê²© ë°ì´í„°í”„ë ˆì„ (CLOSE_PRICE ì»¬ëŸ¼ í•„ìš”)
            forward_days: ë¯¸ë˜ ì¼ìˆ˜
        
        Returns:
            ë¯¸ë˜ ìˆ˜ìµë¥  Series
        """
        return df['CLOSE_PRICE'].pct_change(forward_days).shift(-forward_days) * 100
    
    def _calc_momentum_6m(self, df: pd.DataFrame) -> pd.Series:
        """6ê°œì›” ëª¨ë©˜í…€ ê³„ì‚°"""
        return df['CLOSE_PRICE'].pct_change(120) * 100
    
    def _calc_momentum_1m(self, df: pd.DataFrame) -> pd.Series:
        """1ê°œì›” ëª¨ë©˜í…€ ê³„ì‚°"""
        return df['CLOSE_PRICE'].pct_change(20) * 100
    
    def _calc_per_factor(self, df: pd.DataFrame, per_values: pd.Series = None) -> pd.Series:
        """PER íŒ©í„° (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ ìŒìˆ˜ë¡œ ë³€í™˜)"""
        if per_values is not None:
            return -per_values  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ ìŒìˆ˜
        return pd.Series([0] * len(df))
    
    def _calc_pbr_factor(self, df: pd.DataFrame, pbr_values: pd.Series = None) -> pd.Series:
        """PBR íŒ©í„° (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ ìŒìˆ˜ë¡œ ë³€í™˜)"""
        if pbr_values is not None:
            return -pbr_values
        return pd.Series([0] * len(df))
    
    def _calc_roe_factor(self, df: pd.DataFrame, roe_values: pd.Series = None) -> pd.Series:
        """ROE íŒ©í„° (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)"""
        if roe_values is not None:
            return roe_values
        return pd.Series([0] * len(df))
    
    def _calc_rsi_oversold(self, df: pd.DataFrame, period: int = 14) -> pd.Series:
        """RSI ê³¼ë§¤ë„ íŒ©í„° (30 ì´í•˜ë©´ ë†’ì€ ê°’)"""
        close = df['CLOSE_PRICE']
        delta = close.diff()
        gain = delta.where(delta > 0, 0).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        
        # RSIê°€ ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ (100 - RSI) ë°˜í™˜
        return 100 - rsi
    
    def _calc_foreign_buy(self, df: pd.DataFrame, foreign_data: pd.Series = None) -> pd.Series:
        """ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ íŒ©í„°"""
        if foreign_data is not None:
            return foreign_data
        return pd.Series([0] * len(df))
    
    def calculate_ic(self, 
                     factor_values: pd.Series,
                     forward_returns: pd.Series) -> Tuple[float, float, float]:
        """
        Information Coefficient ê³„ì‚°
        
        IC = íŒ©í„° ê°’ê³¼ ë¯¸ë˜ ìˆ˜ìµë¥ ì˜ ìƒê´€ê³„ìˆ˜
        
        Args:
            factor_values: íŒ©í„° ê°’ Series
            forward_returns: ë¯¸ë˜ ìˆ˜ìµë¥  Series
        
        Returns:
            (IC í‰ê· , IC í‘œì¤€í¸ì°¨, Information Ratio)
        """
        # ê²°ì¸¡ì¹˜ ì œê±°
        valid = pd.DataFrame({
            'factor': factor_values,
            'return': forward_returns
        }).dropna()
        
        if len(valid) < 30:
            return 0.0, 1.0, 0.0
        
        # [v1.0.4] íŒ©í„° ê°’ì´ ìƒìˆ˜ì¸ì§€ í™•ì¸ (ìƒìˆ˜ë©´ ìƒê´€ê³„ìˆ˜ ê³„ì‚° ë¶ˆê°€)
        if valid['factor'].nunique() <= 1:
            logger.debug("   (FactorAnalyzer) íŒ©í„° ê°’ì´ ìƒìˆ˜ì…ë‹ˆë‹¤. IC=0 ë°˜í™˜")
            return 0.0, 1.0, 0.0
        
        # ìˆœìœ„ ìƒê´€ê³„ìˆ˜ (Spearman) ì‚¬ìš©
        ic = valid['factor'].corr(valid['return'], method='spearman')
        
        # [v1.0.4] NaN ì²˜ë¦¬
        if pd.isna(ic):
            logger.debug("   (FactorAnalyzer) ICê°€ NaNì…ë‹ˆë‹¤. IC=0 ë°˜í™˜")
            return 0.0, 1.0, 0.0
        
        # ë¡¤ë§ IC ê³„ì‚° (60ì¼ ìœˆë„ìš°)
        rolling_ic = valid['factor'].rolling(60).corr(valid['return'])
        ic_std = rolling_ic.std()
        
        if pd.isna(ic_std) or ic_std <= 0:
            ir = 0.0
            ic_std = 1.0
        else:
            ir = ic / ic_std
        
        return float(ic), float(ic_std), float(ir)
    
    def analyze_factor(self,
                       stock_codes: List[str],
                       factor_key: str,
                       forward_days: int = 5) -> FactorAnalysisResult:
        """
        ë‹¨ì¼ íŒ©í„°ì˜ ì˜ˆì¸¡ë ¥ ë¶„ì„
        
        Args:
            stock_codes: ë¶„ì„ ëŒ€ìƒ ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
            factor_key: íŒ©í„° í‚¤ (ì˜ˆ: 'momentum_6m')
            forward_days: ë¯¸ë˜ ìˆ˜ìµë¥  ì¸¡ì • ê¸°ê°„
        
        Returns:
            FactorAnalysisResult ê°ì²´
        """
        factor_def = self.FACTOR_DEFINITIONS.get(factor_key)
        if not factor_def:
            raise ValueError(f"Unknown factor: {factor_key}")
        
        logger.info(f"   (FactorAnalyzer) {factor_def['name']} ë¶„ì„ ì¤‘...")
        
        # ê°€ê²© ë°ì´í„° ì¡°íšŒ
        price_data = self._get_historical_prices(stock_codes)
        
        all_factors = []
        all_returns = []
        
        for code, df in price_data.items():
            if len(df) < 150:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬
                continue
            
            # íŒ©í„° ê³„ì‚°
            calc_func = getattr(self, factor_def['calc_func'])
            factor_values = calc_func(df)
            
            # ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°
            forward_returns = self._calculate_forward_returns(df, forward_days)
            
            # ë‘ ì‹œë¦¬ì¦ˆë¥¼ í•©ì³ì„œ ë™ì‹œì— ìœ íš¨í•œ ì¸ë±ìŠ¤ë§Œ ì¶”ì¶œ
            combined = pd.DataFrame({
                'factor': factor_values,
                'return': forward_returns
            }).dropna()
            
            all_factors.extend(combined['factor'].tolist())
            all_returns.extend(combined['return'].tolist())
        
        if len(all_factors) < 100:
            logger.warning(f"   (FactorAnalyzer) {factor_key} í‘œë³¸ ë¶€ì¡± ({len(all_factors)}ê°œ)")
            return FactorAnalysisResult(
                factor_key=factor_key,
                factor_name=factor_def['name'],
                ic_mean=0.0,
                ic_std=1.0,
                ir=0.0,
                hit_rate=0.5,
                recommended_weight=0.05,
                sample_count=len(all_factors),
            )
        
        # IC ê³„ì‚°
        factor_series = pd.Series(all_factors)
        return_series = pd.Series(all_returns)
        ic_mean, ic_std, ir = self.calculate_ic(factor_series, return_series)
        
        # ì ì¤‘ë¥  ê³„ì‚° (íŒ©í„° ìƒìœ„ 20%ì˜ í‰ê·  ìˆ˜ìµë¥ ì´ ì–‘ìˆ˜ì¸ ë¹„ìœ¨)
        combined = pd.DataFrame({'factor': all_factors, 'return': all_returns}).dropna()
        top_quantile = combined[combined['factor'] >= combined['factor'].quantile(0.8)]
        hit_rate = (top_quantile['return'] > 0).mean() if len(top_quantile) > 0 else 0.5
        
        # ì¶”ì²œ ê°€ì¤‘ì¹˜ ê³„ì‚° (IR ê¸°ë°˜)
        # IRì´ 0.5 ì´ìƒì´ë©´ ë†’ì€ ê°€ì¤‘ì¹˜, 0 ì´í•˜ë©´ ë‚®ì€ ê°€ì¤‘ì¹˜
        if ir >= 0.5:
            recommended_weight = min(0.20, 0.10 + ir * 0.1)
        elif ir >= 0:
            recommended_weight = 0.10
        else:
            recommended_weight = max(0.02, 0.05 + ir * 0.05)
        
        result = FactorAnalysisResult(
            factor_key=factor_key,
            factor_name=factor_def['name'],
            ic_mean=round(ic_mean, 4),
            ic_std=round(ic_std, 4),
            ir=round(ir, 4),
            hit_rate=round(hit_rate, 4),
            recommended_weight=round(recommended_weight, 4),
            sample_count=len(all_factors),
        )
        
        logger.info(f"   âœ… {factor_def['name']}: IC={ic_mean:.4f}, IR={ir:.4f}, "
                   f"ì ì¤‘ë¥ ={hit_rate:.1%}, í‘œë³¸={len(all_factors)}")
        
        return result
    
    def analyze_condition_performance(self,
                                      stock_code: str,
                                      condition_key: str,
                                      condition_func,
                                      forward_days: int = 5) -> Optional[ConditionPerformance]:
        """
        ì¡°ê±´ë¶€ ì„±ê³¼ ë¶„ì„
        
        "íŠ¹ì • ì¡°ê±´ì´ ë°œìƒí–ˆì„ ë•Œì˜ ë¯¸ë˜ ìˆ˜ìµë¥ " ë¶„ì„
        
        Args:
            stock_code: ì¢…ëª© ì½”ë“œ (ë˜ëŠ” 'ALL')
            condition_key: ì¡°ê±´ í‚¤ (ì˜ˆ: 'news_score_70')
            condition_func: ì¡°ê±´ íŒë‹¨ í•¨ìˆ˜ (df -> bool Series)
            forward_days: ë¯¸ë˜ ìˆ˜ìµë¥  ì¸¡ì • ê¸°ê°„
        
        Returns:
            ConditionPerformance ê°ì²´ ë˜ëŠ” None
        """
        price_data = self._get_historical_prices([stock_code])
        
        if stock_code not in price_data:
            return None
        
        df = price_data[stock_code]
        
        # ì¡°ê±´ ë°œìƒ ì‹œì  íŒë³„
        condition_mask = condition_func(df)
        
        # ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°
        forward_returns = self._calculate_forward_returns(df, forward_days)
        
        # ì¡°ê±´ ë°œìƒ ì‹œì ì˜ ìˆ˜ìµë¥ ë§Œ ì¶”ì¶œ
        condition_returns = forward_returns[condition_mask].dropna()
        
        if len(condition_returns) < 5:
            return None
        
        # í†µê³„ ê³„ì‚°
        win_rate = (condition_returns > 0).mean()
        avg_return = condition_returns.mean()
        
        # ìµœê·¼ 3ê°œì›” í†µê³„
        recent_cutoff = datetime.now() - timedelta(days=90)
        if 'PRICE_DATE' in df.columns:
            recent_mask = df['PRICE_DATE'] >= recent_cutoff
            recent_returns = forward_returns[condition_mask & recent_mask].dropna()
            recent_win_rate = (recent_returns > 0).mean() if len(recent_returns) > 0 else win_rate
            recent_sample_count = len(recent_returns)
        else:
            recent_win_rate = win_rate
            recent_sample_count = 0
        
        return ConditionPerformance(
            target_type='STOCK',
            target_code=stock_code,
            condition_key=condition_key,
            condition_desc=condition_key,
            win_rate=round(win_rate, 4),
            avg_return=round(avg_return, 4),
            sample_count=len(condition_returns),
            recent_win_rate=round(recent_win_rate, 4),
            recent_sample_count=recent_sample_count,
        )
    
    def _sanitize_for_db(self, value):
        """
        [v1.0.3] DB ì €ì¥ì„ ìœ„í•´ NaN/inf ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜
        """
        import math
        if value is None:
            return None
        if isinstance(value, float):
            if math.isnan(value) or math.isinf(value):
                return None
        return value
    
    def save_factor_metadata(self, result: FactorAnalysisResult, market_regime: str = 'ALL') -> bool:
        """
        íŒ©í„° ë¶„ì„ ê²°ê³¼ë¥¼ FACTOR_METADATAì— ì €ì¥
        
        [v1.0.3] Claude Opus 4.5 í”¼ë“œë°±: Oracle MERGE INTO í˜¸í™˜ì„± ì¶”ê°€
        [v1.0.4] NaN/inf ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜í•˜ì—¬ MySQL í˜¸í™˜ì„± í™•ë³´
        """
        try:
            cursor = self.db_conn.cursor()
            
            columns = [
                'FACTOR_KEY', 'FACTOR_NAME', 'MARKET_REGIME',
                'IC_MEAN', 'IC_STD', 'IR', 'HIT_RATE',
                'RECOMMENDED_WEIGHT', 'SAMPLE_COUNT',
                'ANALYSIS_START_DATE', 'ANALYSIS_END_DATE'
            ]
            values = (
                result.factor_key,
                result.factor_name,
                market_regime,
                self._sanitize_for_db(result.ic_mean),
                self._sanitize_for_db(result.ic_std),
                self._sanitize_for_db(result.ir),
                self._sanitize_for_db(result.hit_rate),
                self._sanitize_for_db(result.recommended_weight),
                result.sample_count,
                datetime.now() - timedelta(days=self.DEFAULT_LOOKBACK_YEARS * 365),
                datetime.now(),
            )
            unique_keys = ['FACTOR_KEY', 'MARKET_REGIME']
            
            execute_upsert(cursor, 'FACTOR_METADATA', columns, values, unique_keys)
            
            self.db_conn.commit()
            cursor.close()
            return True
            
        except Exception as e:
            logger.error(f"   (FactorAnalyzer) FACTOR_METADATA ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def save_factor_performance(self, result: ConditionPerformance, holding_days: int = 5) -> bool:
        """
        ì¡°ê±´ë¶€ ì„±ê³¼ ê²°ê³¼ë¥¼ FACTOR_PERFORMANCEì— ì €ì¥
        
        [v1.0.3] Claude Opus 4.5 í”¼ë“œë°±: Oracle MERGE INTO í˜¸í™˜ì„± ì¶”ê°€
        """
        try:
            cursor = self.db_conn.cursor()
            
            confidence_level = get_confidence_level(result.sample_count)
            
            columns = [
                'TARGET_TYPE', 'TARGET_CODE', 'TARGET_NAME',
                'CONDITION_KEY', 'CONDITION_DESC',
                'WIN_RATE', 'AVG_RETURN', 'HOLDING_DAYS',
                'SAMPLE_COUNT', 'CONFIDENCE_LEVEL',
                'RECENT_WIN_RATE', 'RECENT_SAMPLE_COUNT',
                'ANALYSIS_DATE'
            ]
            values = (
                result.target_type,
                result.target_code,
                '',  # TARGET_NAME - ë³„ë„ ì¡°íšŒ í•„ìš”ì‹œ ì¶”ê°€
                result.condition_key,
                result.condition_desc,
                result.win_rate,
                result.avg_return,
                holding_days,
                result.sample_count,
                confidence_level,
                result.recent_win_rate,
                result.recent_sample_count,
                datetime.now().date(),
            )
            unique_keys = ['TARGET_TYPE', 'TARGET_CODE', 'CONDITION_KEY', 'HOLDING_DAYS']
            
            execute_upsert(cursor, 'FACTOR_PERFORMANCE', columns, values, unique_keys)
            
            self.db_conn.commit()
            cursor.close()
            return True
            
        except Exception as e:
            logger.error(f"   (FactorAnalyzer) FACTOR_PERFORMANCE ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    # =========================================================================
    # [v1.0.2] GPT í”¼ë“œë°± ë°˜ì˜ - ì‹ ê·œ ê¸°ëŠ¥
    # =========================================================================
    
    def _get_financial_data(self, stock_codes: List[str]) -> Dict[str, Dict]:
        """
        [v1.0.3] ì¢…ëª©ë³„ ë¶„ê¸°ë³„ ì¬ë¬´ ë°ì´í„°(PER/PBR/ROE) DBì—ì„œ ì¡°íšŒ
        
        GPT í”¼ë“œë°±: "PER/PBR/ROE ë°ì´í„° ì…ë ¥ ì—†ìŒ" í•´ê²°
        [v1.0.3] FINANCIAL_METRICS_QUARTERLY í…Œì´ë¸”ì—ì„œ ë¶„ê¸°ë³„ ë°ì´í„° ì¡°íšŒ
        
        Returns:
            {stock_code: {quarter_date_str: {'per': float, 'pbr': float, 'roe': float}}}
        """
        result = {}
        
        try:
            cursor = self.db_conn.cursor()
            
            # FINANCIAL_METRICS_QUARTERLY í…Œì´ë¸”ì—ì„œ ë¶„ê¸°ë³„ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ
            if self._is_mariadb():
                placeholders = ','.join(['%s'] * len(stock_codes))
                cursor.execute(f"""
                    SELECT STOCK_CODE, QUARTER_DATE, PER, PBR, ROE
                    FROM FINANCIAL_METRICS_QUARTERLY
                    WHERE STOCK_CODE IN ({placeholders})
                    ORDER BY STOCK_CODE, QUARTER_DATE
                """, stock_codes)
            else:
                placeholders = ','.join([f':p{i}' for i in range(len(stock_codes))])
                params = {f'p{i}': code for i, code in enumerate(stock_codes)}
                cursor.execute(f"""
                    SELECT STOCK_CODE, QUARTER_DATE, PER, PBR, ROE
                    FROM FINANCIAL_METRICS_QUARTERLY
                    WHERE STOCK_CODE IN ({placeholders})
                    ORDER BY STOCK_CODE, QUARTER_DATE
                """, params)
            
            rows = cursor.fetchall()
            cursor.close()
            
            for row in rows:
                if isinstance(row, dict):
                    code = row.get('STOCK_CODE')
                    q_date = row.get('QUARTER_DATE')
                    per = row.get('PER')
                    pbr = row.get('PBR')
                    roe = row.get('ROE')
                else:
                    code = row[0]
                    q_date = row[1]
                    per = row[2]
                    pbr = row[3]
                    roe = row[4] if len(row) > 4 else None
                
                # ë‚ ì§œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
                if hasattr(q_date, 'strftime'):
                    q_date_str = q_date.strftime('%Y-%m-%d')
                else:
                    q_date_str = str(q_date)
                
                if code not in result:
                    result[code] = {}
                
                result[code][q_date_str] = {
                    'per': float(per) if per else None,
                    'pbr': float(pbr) if pbr else None,
                    'roe': float(roe) if roe else None,
                }
            
            total_quarters = sum(len(v) for v in result.values())
            logger.debug(f"   (FactorAnalyzer) ë¶„ê¸°ë³„ ì¬ë¬´ ë°ì´í„° ë¡œë“œ: {len(result)}ê°œ ì¢…ëª©, {total_quarters}ê°œ ë¶„ê¸°")
            
        except Exception as e:
            logger.warning(f"   (FactorAnalyzer) ì¬ë¬´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return result
    
    def _get_financial_at_date(self, financial_data: Dict, stock_code: str, target_date) -> Dict:
        """
        [v1.0.3] íŠ¹ì • ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ë¶„ê¸°ì˜ ì¬ë¬´ ë°ì´í„° ë°˜í™˜
        
        Args:
            financial_data: _get_financial_data()ì˜ ë°˜í™˜ê°’
            stock_code: ì¢…ëª© ì½”ë“œ
            target_date: ëŒ€ìƒ ë‚ ì§œ (datetime ë˜ëŠ” str)
        
        Returns:
            {'per': float, 'pbr': float, 'roe': float} ë˜ëŠ” ë¹ˆ ë”•ì…”ë„ˆë¦¬
        """
        if stock_code not in financial_data:
            return {}
        
        quarters = financial_data[stock_code]
        if not quarters:
            return {}
        
        # ë‚ ì§œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        if hasattr(target_date, 'strftime'):
            target_str = target_date.strftime('%Y-%m-%d')
        else:
            target_str = str(target_date)[:10]
        
        # í•´ë‹¹ ë‚ ì§œ ì´ì „ì˜ ê°€ì¥ ìµœê·¼ ë¶„ê¸° ì°¾ê¸°
        sorted_quarters = sorted(quarters.keys())
        applicable_quarter = None
        
        for q_date in sorted_quarters:
            if q_date <= target_str:
                applicable_quarter = q_date
            else:
                break
        
        if applicable_quarter:
            return quarters[applicable_quarter]
        
        # í•´ë‹¹ ë‚ ì§œ ì´ì „ ë¶„ê¸°ê°€ ì—†ìœ¼ë©´ ê°€ì¥ ì˜¤ë˜ëœ ë¶„ê¸° ë°˜í™˜
        if sorted_quarters:
            return quarters[sorted_quarters[0]]
        
        return {}
    
    def _get_supply_demand_data(self, stock_codes: List[str], days: int = 504) -> Dict[str, pd.DataFrame]:
        """
        [v1.0.2] ì¢…ëª©ë³„ ì™¸êµ­ì¸/ê¸°ê´€ ìˆ˜ê¸‰ ë°ì´í„° ì¡°íšŒ
        
        GPT í”¼ë“œë°±: "ì™¸êµ­ì¸/ê¸°ê´€ ìˆ˜ê¸‰ ì¡°ê±´ ë¶„ì„" ì¶”ê°€
        
        Returns:
            {stock_code: DataFrame with TRADE_DATE, FOREIGN_NET, INST_NET}
        """
        result = {}
        
        try:
            cursor = self.db_conn.cursor()
            
            for code in stock_codes:
                cursor.execute("""
                    SELECT TRADE_DATE, FOREIGN_NET_BUY, INSTITUTION_NET_BUY
                    FROM STOCK_INVESTOR_TRADING
                    WHERE STOCK_CODE = %s
                    ORDER BY TRADE_DATE DESC
                    LIMIT %s
                """, (code, days))
                
                rows = cursor.fetchall()
                
                if rows:
                    if isinstance(rows[0], dict):
                        df = pd.DataFrame(rows)
                        # ì»¬ëŸ¼ëª… ì •ê·œí™”
                        if 'FOREIGN_NET_BUY' in df.columns:
                            df = df.rename(columns={
                                'FOREIGN_NET_BUY': 'FOREIGN_NET',
                                'INSTITUTION_NET_BUY': 'INST_NET'
                            })
                    else:
                        df = pd.DataFrame(rows, columns=[
                            'TRADE_DATE', 'FOREIGN_NET', 'INST_NET'
                        ])
                    df = df.sort_values('TRADE_DATE').reset_index(drop=True)
                    result[code] = df
            
            cursor.close()
            logger.debug(f"   (FactorAnalyzer) ìˆ˜ê¸‰ ë°ì´í„° ë¡œë“œ: {len(result)}ê°œ ì¢…ëª©")
            
        except Exception as e:
            logger.warning(f"   (FactorAnalyzer) ìˆ˜ê¸‰ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return result
    
    def _get_news_sentiment_history(self, stock_codes: List[str], days: int = 504) -> Dict[str, pd.DataFrame]:
        """
        [v1.0.2] ì¢…ëª©ë³„ ë‰´ìŠ¤ ê°ì„± ì ìˆ˜ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
        
        GPT í”¼ë“œë°±: "ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ ìŠ¹ë¥ " ë¶„ì„ì„ ìœ„í•œ ë°ì´í„° ë¡œë“œ
        
        Returns:
            {stock_code: DataFrame with NEWS_DATE, SENTIMENT_SCORE, CATEGORY}
        """
        result = {}
        
        try:
            cursor = self.db_conn.cursor()
            
            for code in stock_codes:
                cursor.execute("""
                    SELECT NEWS_DATE, SENTIMENT_SCORE, CATEGORY
                    FROM STOCK_NEWS_SENTIMENT
                    WHERE STOCK_CODE = %s
                    ORDER BY NEWS_DATE DESC
                    LIMIT %s
                """, (code, days))
                
                rows = cursor.fetchall()
                
                if rows:
                    if isinstance(rows[0], dict):
                        df = pd.DataFrame(rows)
                    else:
                        df = pd.DataFrame(rows, columns=[
                            'NEWS_DATE', 'SENTIMENT_SCORE', 'CATEGORY'
                        ])
                    df = df.sort_values('NEWS_DATE').reset_index(drop=True)
                    result[code] = df
            
            cursor.close()
            logger.debug(f"   (FactorAnalyzer) ë‰´ìŠ¤ ê°ì„± ë°ì´í„° ë¡œë“œ: {len(result)}ê°œ ì¢…ëª©")
            
        except Exception as e:
            logger.warning(f"   (FactorAnalyzer) ë‰´ìŠ¤ ê°ì„± ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ (í…Œì´ë¸” ì—†ì„ ìˆ˜ ìˆìŒ): {e}")
        
        return result
    
    def analyze_news_category_impact(self, 
                                     stock_codes: List[str],
                                     forward_days: int = 5) -> List[Dict]:
        """
        [v1.0.2] ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ D+N ìŠ¹ë¥  ë° í‰ê·  ìˆ˜ìµë¥  ë¶„ì„
        
        GPT í”¼ë“œë°±: "ë‰´ìŠ¤ ì˜í–¥ë„ ë¶„ì„ ë¯¸êµ¬í˜„" í•´ê²°
        NEWS_FACTOR_STATS í…Œì´ë¸”ì— ì €ì¥í•  ë°ì´í„° ìƒì„±
        
        Returns:
            [{'category': str, 'win_rate': float, 'avg_return': float, ...}]
        """
        logger.info(f"   [v1.0.2] ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ ì˜í–¥ë„ ë¶„ì„ ì‹œì‘ ({len(stock_codes)}ê°œ ì¢…ëª©)")
        
        price_data = self._get_historical_prices(stock_codes)
        news_data = self._get_news_sentiment_history(stock_codes)
        
        results = []
        category_stats = {cat: {'returns': [], 'recent_returns': []} for cat in self.NEWS_CATEGORIES}
        category_stats['ALL'] = {'returns': [], 'recent_returns': []}  # ì „ì²´ í†µê³„
        
        recent_cutoff = datetime.now() - timedelta(days=90)
        
        for code in stock_codes:
            if code not in price_data or code not in news_data:
                continue
            
            prices_df = price_data[code]
            news_df = news_data[code]
            
            if len(prices_df) < 30 or len(news_df) == 0:
                continue
            
            # ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°
            forward_returns = self._calculate_forward_returns(prices_df, forward_days)
            
            # [v1.0.4] PRICE_DATEë¥¼ dateë¡œ ë³€í™˜ (datetime â†’ date)
            if 'PRICE_DATE' in prices_df.columns:
                prices_df = prices_df.copy()
                prices_df['PRICE_DATE_ONLY'] = pd.to_datetime(prices_df['PRICE_DATE']).dt.date
            
            # ë‰´ìŠ¤ ë‚ ì§œì™€ ê°€ê²© ë°ì´í„° ë§¤ì¹­
            for _, news_row in news_df.iterrows():
                news_date_raw = news_row.get('NEWS_DATE')
                category = news_row.get('CATEGORY', 'ALL')
                sentiment = news_row.get('SENTIMENT_SCORE', 50)
                
                if category not in category_stats:
                    category = 'ALL'
                
                # [v1.0.4] datetimeì„ dateë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ
                if hasattr(news_date_raw, 'date'):
                    news_date = news_date_raw.date()
                elif hasattr(news_date_raw, 'strftime'):
                    news_date = news_date_raw
                else:
                    continue
                
                # í•´ë‹¹ ë‚ ì§œì˜ ìˆ˜ìµë¥  ì°¾ê¸° (PRICE_DATE_ONLY ì‚¬ìš©)
                if 'PRICE_DATE_ONLY' in prices_df.columns:
                    price_idx = prices_df[prices_df['PRICE_DATE_ONLY'] == news_date].index
                else:
                    price_idx = prices_df[prices_df['PRICE_DATE'] == news_date].index
                    if len(price_idx) == 0:
                        price_idx = prices_df[prices_df['PRICE_DATE'] == news_date_raw].index
                
                if len(price_idx) == 0:
                    continue
                
                idx = price_idx[0]
                if idx >= len(forward_returns):
                    continue
                
                ret = forward_returns.iloc[idx]
                if pd.isna(ret):
                    continue
                
                # í˜¸ì¬ ë‰´ìŠ¤ë§Œ ë¶„ì„ (ê°ì„± ì ìˆ˜ 70 ì´ìƒ)
                if sentiment >= 70:
                    category_stats[category]['returns'].append(ret)
                    category_stats['ALL']['returns'].append(ret)
                    
                    # [v1.0.4] recent_cutoff ë¹„êµë„ dateë¡œ í†µì¼
                    if hasattr(news_date_raw, 'date'):
                        compare_date = news_date_raw
                    else:
                        compare_date = datetime.combine(news_date, datetime.min.time())
                    
                    if compare_date >= recent_cutoff:
                        category_stats[category]['recent_returns'].append(ret)
                        category_stats['ALL']['recent_returns'].append(ret)
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„ ê³„ì‚° ë° ì €ì¥
        for category, stats in category_stats.items():
            returns = stats['returns']
            recent_returns = stats['recent_returns']
            
            if len(returns) < 5:
                continue
            
            returns_arr = np.array(returns)
            win_rate = (returns_arr > 0).mean()
            avg_return = returns_arr.mean()
            
            recent_win_rate = (np.array(recent_returns) > 0).mean() if len(recent_returns) > 0 else win_rate
            
            # [v1.0.2] Recency Weighting ì ìš©
            recency_weight = self._calculate_recency_weight(len(returns), len(recent_returns), recent_win_rate, win_rate)
            
            result = {
                'category': category,
                'win_rate': round(win_rate, 4),
                'avg_return': round(avg_return, 4),
                'sample_count': len(returns),
                'confidence': get_confidence_level(len(returns)),
                'recent_win_rate': round(recent_win_rate, 4),
                'recent_sample_count': len(recent_returns),
                'recency_weight': round(recency_weight, 4),
                'holding_days': forward_days,
            }
            results.append(result)
            
            # NEWS_FACTOR_STATSì— ì €ì¥
            self._save_news_factor_stats(result)
            
            logger.info(f"   ğŸ“° {category}: ìŠ¹ë¥ ={win_rate:.1%}, í‰ê· ìˆ˜ìµë¥ ={avg_return:.2f}%, "
                       f"í‘œë³¸={len(returns)}, ìµœê·¼ìŠ¹ë¥ ={recent_win_rate:.1%}")
        
        return results

    def analyze_disclosure_impact(self,
                                  stock_codes: List[str],
                                  forward_days: int = 5,
                                  lookback_days: int = 365) -> List[Dict]:
        """
        [v1.0.3] DART ê³µì‹œ ê¸°ë°˜ ì˜í–¥ë„ ë¶„ì„

        - STOCK_DISCLOSURES í…Œì´ë¸”ì„ ì¡°íšŒí•˜ì—¬ ì¹´í…Œê³ ë¦¬ë³„ ìŠ¹ë¥  ê³„ì‚°
        - NEWS_FACTOR_STATSì— 'ê³µì‹œ:<ì¹´í…Œê³ ë¦¬>' í˜•íƒœë¡œ ì €ì¥
        """
        logger.info(f"   [v1.0.3] ê³µì‹œ ì˜í–¥ë„ ë¶„ì„ ì‹œì‘ ({len(stock_codes)}ê°œ ì¢…ëª©, lookback={lookback_days}ì¼)")

        disclosures = self._fetch_disclosures(stock_codes, lookback_days)
        price_data = self._get_historical_prices(stock_codes, days=max(lookback_days + 60, 250))

        category_stats = {}
        recent_cutoff = datetime.now() - timedelta(days=90)

        for code in stock_codes:
            if code not in disclosures or code not in price_data:
                continue

            df = price_data[code]
            if df.empty:
                continue

            forward_returns = self._calculate_forward_returns(df, forward_days)

            for disclosure in disclosures[code]:
                disc_date = disclosure['date']
                category = disclosure['category']
                if not category:
                    category = 'ê¸°íƒ€'

                idx = df[df['PRICE_DATE'] >= disc_date].index
                if len(idx) == 0:
                    continue
                price_idx = idx[0]
                if price_idx >= len(forward_returns):
                    continue

                ret = forward_returns.iloc[price_idx]
                if pd.isna(ret):
                    continue

                key = f"ê³µì‹œ:{category}"
                if key not in category_stats:
                    category_stats[key] = {'returns': [], 'recent_returns': []}

                category_stats[key]['returns'].append(ret)
                if disc_date >= recent_cutoff:
                    category_stats[key]['recent_returns'].append(ret)

        results = []
        for category, stats in category_stats.items():
            returns = stats['returns']
            recent_returns = stats['recent_returns']
            if len(returns) < 5:
                continue

            arr = pd.Series(returns)
            win_rate = (arr > 0).mean()
            avg_return = arr.mean()
            recent_win_rate = (pd.Series(recent_returns) > 0).mean() if recent_returns else win_rate
            recency_weight = self._calculate_recency_weight(len(returns), len(recent_returns), recent_win_rate, win_rate)

            payload = {
                'category': category,
                'win_rate': round(win_rate, 4),
                'avg_return': round(avg_return, 4),
                'sample_count': len(returns),
                'confidence': get_confidence_level(len(returns)),
                'recent_win_rate': round(recent_win_rate, 4),
                'recent_sample_count': len(recent_returns),
                'recency_weight': round(recency_weight, 4),
                'holding_days': forward_days,
            }
            results.append(payload)
            self._save_news_factor_stats(payload)
            logger.info(f"   ğŸ“‘ {category}: ìŠ¹ë¥ ={win_rate:.1%}, í‘œë³¸={len(returns)}, í‰ê· ìˆ˜ìµë¥ ={avg_return:.2f}%")

        return results

    def _fetch_disclosures(self, stock_codes: List[str], lookback_days: int = 365) -> Dict[str, List[Dict]]:
        """
        [v1.0.3] STOCK_DISCLOSURES í…Œì´ë¸”ì—ì„œ ê³µì‹œ ë°ì´í„° ë¡œë“œ
        """
        logger.info(f"   (FactorAnalyzer) ê³µì‹œ ë°ì´í„° ë¡œë“œ ({lookback_days}ì¼)")
        cursor = self.db_conn.cursor()
        result = {code: [] for code in stock_codes}
        start_date = datetime.now() - timedelta(days=lookback_days)

        for code in stock_codes:
            try:
                if _is_mariadb():
                    cursor.execute(f"""
                        SELECT DISCLOSURE_DATE, CATEGORY
                        FROM {self.DISCLOSURE_TABLE}
                        WHERE STOCK_CODE = %s AND DISCLOSURE_DATE >= %s
                        ORDER BY DISCLOSURE_DATE ASC
                    """, (code, start_date))
                else:
                    cursor.execute(f"""
                        SELECT DISCLOSURE_DATE, CATEGORY
                        FROM {self.DISCLOSURE_TABLE}
                        WHERE STOCK_CODE = :1 AND DISCLOSURE_DATE >= :2
                        ORDER BY DISCLOSURE_DATE ASC
                    """, [code, start_date])
                rows = cursor.fetchall()
                entries = []
                for row in rows:
                    disc_date = row[0]
                    if isinstance(disc_date, datetime):
                        pass
                    else:
                        disc_date = datetime.strptime(str(disc_date), "%Y-%m-%d %H:%M:%S")
                    entries.append({
                        'date': disc_date,
                        'category': row[1] or 'ê¸°íƒ€'
                    })
                result[code] = entries
            except Exception as e:
                logger.debug(f"   âš ï¸ ê³µì‹œ ë¡œë“œ ì‹¤íŒ¨ ({code}): {e}")
        cursor.close()
        return result
    
    def _calculate_recency_weight(self, 
                                  total_samples: int, 
                                  recent_samples: int,
                                  recent_win_rate: float,
                                  total_win_rate: float) -> float:
        """
        [v1.0.2] Recency Weighting ê³„ì‚°
        
        GPT í”¼ë“œë°±: "Recency Weighting ë°˜ì˜ ë¶€ì¡±" í•´ê²°
        
        ìµœê·¼ ë°ì´í„°ì˜ ì„±ê³¼ê°€ ì „ì²´ì™€ ë‹¤ë¥´ë©´ ê°€ì¤‘ì¹˜ ì¡°ì •
        
        Returns:
            0.5 ~ 1.5 ì‚¬ì´ì˜ ê°€ì¤‘ì¹˜ (1.0 = ì¤‘ë¦½)
        """
        if recent_samples < 5:
            return 1.0  # ìƒ˜í”Œ ë¶€ì¡±ì‹œ ì¤‘ë¦½
        
        # ìµœê·¼ ìŠ¹ë¥ ì´ ì „ì²´ ìŠ¹ë¥ ë³´ë‹¤ ë†’ìœ¼ë©´ ê°€ì¤‘ì¹˜ ìƒìŠ¹
        if total_win_rate > 0:
            ratio = recent_win_rate / total_win_rate
            # ratioê°€ 1.2 ì´ìƒì´ë©´ 1.2, 0.8 ì´í•˜ë©´ 0.8ë¡œ ì œí•œ
            ratio = max(0.5, min(1.5, ratio))
        else:
            ratio = 1.0
        
        # ìµœê·¼ ìƒ˜í”Œ ë¹„ì¤‘ë„ ê³ ë ¤ (ìµœê·¼ ìƒ˜í”Œì´ ë§ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ)
        sample_ratio = min(recent_samples / max(total_samples, 1), 0.5) * 2
        
        # ìµœì¢… ê°€ì¤‘ì¹˜ = ìŠ¹ë¥  ë¹„ìœ¨ê³¼ ìƒ˜í”Œ ë¹„ì¤‘ì˜ ê°€ì¤‘ í‰ê· 
        recency_weight = ratio * 0.7 + (1.0 + (sample_ratio - 1.0) * 0.5) * 0.3
        
        return max(0.5, min(1.5, recency_weight))
    
    def _save_news_factor_stats(self, result: Dict) -> bool:
        """
        [v1.0.2] NEWS_FACTOR_STATS í…Œì´ë¸”ì— ë‰´ìŠ¤ ì˜í–¥ë„ ì €ì¥
        
        GPT í”¼ë“œë°±: "NEWS_FACTOR_STATS í…Œì´ë¸”ì„ ì±„ìš°ê¸° ìœ„í•œ ë¶„ì„ ë¡œì§" êµ¬í˜„
        [v1.0.3] Claude Opus 4.5 í”¼ë“œë°±: Oracle MERGE INTO í˜¸í™˜ì„± ì¶”ê°€
        """
        try:
            cursor = self.db_conn.cursor()
            
            columns = [
                'NEWS_CATEGORY', 'STOCK_GROUP', 'MARKET_REGIME',
                'WIN_RATE', 'AVG_RETURN', 'SAMPLE_COUNT',
                'CONFIDENCE_LEVEL', 'HOLDING_DAYS',
                'RECENT_WIN_RATE', 'RECENT_SAMPLE_COUNT',
                'RECENCY_WEIGHT', 'ANALYSIS_DATE'
            ]
            values = (
                result['category'],
                'ALL',  # ì „ì²´ ì¢…ëª© ëŒ€ìƒ
                'ALL',  # ì „ì²´ ì‹œì¥ êµ­ë©´
                result['win_rate'],
                result['avg_return'],
                result['sample_count'],
                result['confidence'],
                result['holding_days'],
                result['recent_win_rate'],
                result['recent_sample_count'],
                result['recency_weight'],
                datetime.now().date(),
            )
            unique_keys = ['NEWS_CATEGORY', 'STOCK_GROUP', 'MARKET_REGIME', 'HOLDING_DAYS']
            
            execute_upsert(cursor, 'NEWS_FACTOR_STATS', columns, values, unique_keys)
            
            self.db_conn.commit()
            cursor.close()
            return True
            
        except Exception as e:
            logger.debug(f"   NEWS_FACTOR_STATS ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_compound_conditions(self, stock_codes: List[str]) -> List[ConditionPerformance]:
        """
        [v1.0.2] ë³µí•© ì¡°ê±´ ë¶„ì„ (ë‰´ìŠ¤ì ìˆ˜ 70â†‘ + ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ë“±)
        
        GPT í”¼ë“œë°±: "ë‰´ìŠ¤ ë° ìˆ˜ê¸‰ ì¡°ê±´ ë¶„ì„ ë¯¸í¡" í•´ê²°
        
        ë¶„ì„ ëŒ€ìƒ ë³µí•© ì¡°ê±´:
        1. ë‰´ìŠ¤ì ìˆ˜ 70â†‘ + ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ 5ì¼ ì—°ì†
        2. ë‰´ìŠ¤ì ìˆ˜ 70â†‘ + ê¸°ê´€ ìˆœë§¤ìˆ˜
        3. RSI ê³¼ë§¤ë„ + ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜
        4. ê±°ë˜ëŸ‰ ê¸‰ì¦ + ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜
        """
        logger.info(f"   [v1.0.2] ë³µí•© ì¡°ê±´ ë¶„ì„ ì‹œì‘ ({len(stock_codes)}ê°œ ì¢…ëª©)")
        
        results = []
        
        price_data = self._get_historical_prices(stock_codes)
        supply_data = self._get_supply_demand_data(stock_codes)
        news_data = self._get_news_sentiment_history(stock_codes)
        
        # ë³µí•© ì¡°ê±´ ì •ì˜
        compound_conditions = [
            {
                'key': 'news_70_foreign_buy',
                'desc': 'ë‰´ìŠ¤ì ìˆ˜ 70â†‘ + ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜',
                'check': lambda p, s, n, d: self._check_news_foreign_condition(p, s, n, d, 70, True),
            },
            {
                'key': 'news_70_inst_buy',
                'desc': 'ë‰´ìŠ¤ì ìˆ˜ 70â†‘ + ê¸°ê´€ ìˆœë§¤ìˆ˜',
                'check': lambda p, s, n, d: self._check_news_inst_condition(p, s, n, d, 70, True),
            },
            {
                'key': 'rsi_oversold_foreign_buy',
                'desc': 'RSI ê³¼ë§¤ë„ + ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜',
                'check': lambda p, s, n, d: self._check_rsi_foreign_condition(p, s, n, d),
            },
            {
                'key': 'volume_surge_foreign_buy',
                'desc': 'ê±°ë˜ëŸ‰ ê¸‰ì¦ + ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜',
                'check': lambda p, s, n, d: self._check_volume_foreign_condition(p, s, n, d),
            },
            {
                'key': 'news_80_all_buy',
                'desc': 'ë‰´ìŠ¤ì ìˆ˜ 80â†‘ + ì™¸êµ­ì¸+ê¸°ê´€ ë™ì‹œ ìˆœë§¤ìˆ˜',
                'check': lambda p, s, n, d: self._check_news_all_buy_condition(p, s, n, d, 80),
            },
        ]
        
        for cond in compound_conditions:
            all_returns = []
            recent_returns = []
            recent_cutoff = datetime.now() - timedelta(days=90)
            
            for code in stock_codes:
                if code not in price_data:
                    continue
                
                prices_df = price_data[code]
                supply_df = supply_data.get(code, pd.DataFrame())
                news_df = news_data.get(code, pd.DataFrame())
                
                if len(prices_df) < 30:
                    continue
                
                # ì¡°ê±´ ì¶©ì¡± ì‹œì  ì°¾ê¸°
                condition_dates = cond['check'](prices_df, supply_df, news_df, code)
                
                if not condition_dates:
                    continue
                
                # ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°
                forward_returns = self._calculate_forward_returns(prices_df, 5)
                
                for date in condition_dates:
                    price_idx = prices_df[prices_df['PRICE_DATE'] == date].index
                    if len(price_idx) == 0:
                        continue
                    
                    idx = price_idx[0]
                    if idx >= len(forward_returns):
                        continue
                    
                    ret = forward_returns.iloc[idx]
                    if pd.isna(ret):
                        continue
                    
                    all_returns.append(ret)
                    if date >= recent_cutoff:
                        recent_returns.append(ret)
            
            if len(all_returns) >= 5:
                returns_arr = np.array(all_returns)
                win_rate = (returns_arr > 0).mean()
                avg_return = returns_arr.mean()
                recent_win_rate = (np.array(recent_returns) > 0).mean() if len(recent_returns) > 0 else win_rate
                
                result = ConditionPerformance(
                    target_type='ALL',
                    target_code='ALL',
                    condition_key=cond['key'],
                    condition_desc=cond['desc'],
                    win_rate=round(win_rate, 4),
                    avg_return=round(avg_return, 4),
                    sample_count=len(all_returns),
                    recent_win_rate=round(recent_win_rate, 4),
                    recent_sample_count=len(recent_returns),
                )
                results.append(result)
                self.save_factor_performance(result)
                
                logger.info(f"   ğŸ”— {cond['desc']}: ìŠ¹ë¥ ={win_rate:.1%}, "
                           f"í‰ê· ìˆ˜ìµë¥ ={avg_return:.2f}%, í‘œë³¸={len(all_returns)}")
        
        return results
    
    def _check_news_foreign_condition(self, prices_df, supply_df, news_df, code, 
                                      threshold=70, foreign_buy=True) -> List:
        """ë‰´ìŠ¤ì ìˆ˜ + ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì¡°ê±´ ì²´í¬"""
        condition_dates = []
        
        if news_df.empty or supply_df.empty:
            return condition_dates
        
        # [v1.0.5] ë‚ ì§œ í˜•ì‹ ì •ê·œí™”
        if 'TRADE_DATE' not in supply_df.columns:
            return condition_dates
        
        # ìˆ˜ê¸‰ ë°ì´í„° ë‚ ì§œë¥¼ dateë¡œ ë³€í™˜
        supply_dates = {}
        for _, row in supply_df.iterrows():
            trade_date = row['TRADE_DATE']
            trade_date_only = trade_date.date() if hasattr(trade_date, 'date') else trade_date
            supply_dates[trade_date_only] = row
        
        for _, news_row in news_df.iterrows():
            sentiment = news_row.get('SENTIMENT_SCORE', 0)
            news_date_raw = news_row.get('NEWS_DATE')
            
            if sentiment < threshold:
                continue
            
            # [v1.0.5] ë‰´ìŠ¤ ë‚ ì§œë„ dateë¡œ ë³€í™˜
            news_date = news_date_raw.date() if hasattr(news_date_raw, 'date') else news_date_raw
            
            # í•´ë‹¹ ë‚ ì§œ ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ í™•ì¸
            if news_date not in supply_dates:
                continue
            
            supply_row = supply_dates[news_date]
            foreign_net = supply_row.get('FOREIGN_NET', 0)
            if foreign_net is None:
                foreign_net = 0
            
            if foreign_buy and foreign_net > 0:
                condition_dates.append(news_date_raw)  # ì›ë³¸ ë‚ ì§œ ë°˜í™˜
        
        return condition_dates
    
    def _check_news_inst_condition(self, prices_df, supply_df, news_df, code,
                                   threshold=70, inst_buy=True) -> List:
        """ë‰´ìŠ¤ì ìˆ˜ + ê¸°ê´€ ìˆœë§¤ìˆ˜ ì¡°ê±´ ì²´í¬"""
        condition_dates = []
        
        if news_df.empty or supply_df.empty:
            return condition_dates
        
        # [v1.0.5] ë‚ ì§œ í˜•ì‹ ì •ê·œí™”
        if 'TRADE_DATE' not in supply_df.columns:
            return condition_dates
        
        supply_dates = {}
        for _, row in supply_df.iterrows():
            trade_date = row['TRADE_DATE']
            trade_date_only = trade_date.date() if hasattr(trade_date, 'date') else trade_date
            supply_dates[trade_date_only] = row
        
        for _, news_row in news_df.iterrows():
            sentiment = news_row.get('SENTIMENT_SCORE', 0)
            news_date_raw = news_row.get('NEWS_DATE')
            
            if sentiment < threshold:
                continue
            
            news_date = news_date_raw.date() if hasattr(news_date_raw, 'date') else news_date_raw
            
            if news_date not in supply_dates:
                continue
            
            supply_row = supply_dates[news_date]
            inst_net = supply_row.get('INST_NET', 0)
            if inst_net is None:
                inst_net = 0
            
            if inst_buy and inst_net > 0:
                condition_dates.append(news_date_raw)
        
        return condition_dates
    
    def _check_rsi_foreign_condition(self, prices_df, supply_df, news_df, code) -> List:
        """RSI ê³¼ë§¤ë„ + ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì¡°ê±´ ì²´í¬"""
        condition_dates = []
        
        if supply_df.empty or len(prices_df) < 20:
            return condition_dates
        
        # [v1.0.5] ìˆ˜ê¸‰ ë°ì´í„° ë‚ ì§œ ì¸ë±ì‹±
        if 'TRADE_DATE' not in supply_df.columns:
            return condition_dates
        
        supply_dates = {}
        for _, row in supply_df.iterrows():
            trade_date = row['TRADE_DATE']
            trade_date_only = trade_date.date() if hasattr(trade_date, 'date') else trade_date
            supply_dates[trade_date_only] = row
        
        # RSI ê³„ì‚°
        close = prices_df['CLOSE_PRICE']
        delta = close.diff()
        gain = delta.where(delta > 0, 0).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        
        for i, (_, row) in enumerate(prices_df.iterrows()):
            if i >= len(rsi) or pd.isna(rsi.iloc[i]):
                continue
            
            if rsi.iloc[i] >= 30:  # RSI 30 ì´ìƒì´ë©´ ê³¼ë§¤ë„ ì•„ë‹˜
                continue
            
            price_date_raw = row['PRICE_DATE']
            price_date = price_date_raw.date() if hasattr(price_date_raw, 'date') else price_date_raw
            
            if price_date not in supply_dates:
                continue
            
            supply_row = supply_dates[price_date]
            foreign_net = supply_row.get('FOREIGN_NET', 0)
            if foreign_net is None:
                foreign_net = 0
            
            if foreign_net > 0:
                condition_dates.append(price_date_raw)
        
        return condition_dates
    
    def _check_volume_foreign_condition(self, prices_df, supply_df, news_df, code) -> List:
        """ê±°ë˜ëŸ‰ ê¸‰ì¦ + ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì¡°ê±´ ì²´í¬"""
        condition_dates = []
        
        if supply_df.empty or 'VOLUME' not in prices_df.columns or len(prices_df) < 25:
            return condition_dates
        
        # [v1.0.5] ìˆ˜ê¸‰ ë°ì´í„° ë‚ ì§œ ì¸ë±ì‹±
        if 'TRADE_DATE' not in supply_df.columns:
            return condition_dates
        
        supply_dates = {}
        for _, row in supply_df.iterrows():
            trade_date = row['TRADE_DATE']
            trade_date_only = trade_date.date() if hasattr(trade_date, 'date') else trade_date
            supply_dates[trade_date_only] = row
        
        vol_ma = prices_df['VOLUME'].rolling(20).mean()
        
        for i, (_, row) in enumerate(prices_df.iterrows()):
            if i >= len(vol_ma) or pd.isna(vol_ma.iloc[i]):
                continue
            
            if row['VOLUME'] <= vol_ma.iloc[i] * 2:  # ê±°ë˜ëŸ‰ 2ë°° ë¯¸ë§Œ
                continue
            
            price_date_raw = row['PRICE_DATE']
            price_date = price_date_raw.date() if hasattr(price_date_raw, 'date') else price_date_raw
            
            if price_date not in supply_dates:
                continue
            
            supply_row = supply_dates[price_date]
            foreign_net = supply_row.get('FOREIGN_NET', 0)
            if foreign_net is None:
                foreign_net = 0
            
            if foreign_net > 0:
                condition_dates.append(price_date_raw)
        
        return condition_dates
    
    def _check_news_all_buy_condition(self, prices_df, supply_df, news_df, code, threshold=80) -> List:
        """ë‰´ìŠ¤ì ìˆ˜ + ì™¸êµ­ì¸+ê¸°ê´€ ë™ì‹œ ìˆœë§¤ìˆ˜ ì¡°ê±´ ì²´í¬"""
        condition_dates = []
        
        if news_df.empty or supply_df.empty:
            return condition_dates
        
        # [v1.0.5] ë‚ ì§œ í˜•ì‹ ì •ê·œí™”
        if 'TRADE_DATE' not in supply_df.columns:
            return condition_dates
        
        supply_dates = {}
        for _, row in supply_df.iterrows():
            trade_date = row['TRADE_DATE']
            trade_date_only = trade_date.date() if hasattr(trade_date, 'date') else trade_date
            supply_dates[trade_date_only] = row
        
        for _, news_row in news_df.iterrows():
            sentiment = news_row.get('SENTIMENT_SCORE', 0)
            news_date_raw = news_row.get('NEWS_DATE')
            
            if sentiment < threshold:
                continue
            
            news_date = news_date_raw.date() if hasattr(news_date_raw, 'date') else news_date_raw
            
            if news_date not in supply_dates:
                continue
            
            supply_row = supply_dates[news_date]
            foreign_net = supply_row.get('FOREIGN_NET', 0)
            inst_net = supply_row.get('INST_NET', 0)
            
            if foreign_net is None:
                foreign_net = 0
            if inst_net is None:
                inst_net = 0
            
            if foreign_net > 0 and inst_net > 0:
                condition_dates.append(news_date_raw)
        
        return condition_dates
    
    def analyze_factor_with_financials(self,
                                       stock_codes: List[str],
                                       factor_key: str,
                                       forward_days: int = 5) -> FactorAnalysisResult:
        """
        [v1.0.3] ì¬ë¬´ ë°ì´í„°ë¥¼ í¬í•¨í•œ íŒ©í„° ë¶„ì„ (ì‹œì ë³„ ë§¤ì¹­)
        
        GPT í”¼ë“œë°±: "PER/PBR/ROE ë°ì´í„° ì…ë ¥ ì—†ìŒ" í•´ê²°
        [v1.0.3] ê° ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ë¶„ê¸°ì˜ PER/PBR/ROE ì‚¬ìš©
        """
        factor_def = self.FACTOR_DEFINITIONS.get(factor_key)
        if not factor_def:
            raise ValueError(f"Unknown factor: {factor_key}")
        
        logger.info(f"   (FactorAnalyzer) {factor_def['name']} ë¶„ì„ ì¤‘ (ë¶„ê¸°ë³„ ì¬ë¬´ ë°ì´í„° ë§¤ì¹­)...")
        
        # ê°€ê²© ë°ì´í„° ë° ë¶„ê¸°ë³„ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ
        price_data = self._get_historical_prices(stock_codes)
        financial_data = self._get_financial_data(stock_codes)
        
        all_factors = []
        all_returns = []
        
        for code, df in price_data.items():
            if len(df) < 150:
                continue
            
            # ì¬ë¬´ íŒ©í„°ì˜ ê²½ìš°: ê° ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” ë¶„ê¸°ì˜ ê°’ ì‚¬ìš©
            calc_func = getattr(self, factor_def['calc_func'])
            
            if factor_key in ['value_per', 'value_pbr', 'quality_roe']:
                # [v1.0.3] ì‹œì ë³„ ì¬ë¬´ ë°ì´í„° ë§¤ì¹­
                factor_values = []
                valid_indices = []
                
                for idx, row in df.iterrows():
                    # í•´ë‹¹ ë‚ ì§œì˜ ì¬ë¬´ ë°ì´í„° ì¡°íšŒ
                    fin = self._get_financial_at_date(financial_data, code, idx)
                    
                    if factor_key == 'value_per':
                        val = fin.get('per')
                        if val and val > 0:
                            factor_values.append(-val)  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ ìŒìˆ˜
                            valid_indices.append(idx)
                    elif factor_key == 'value_pbr':
                        val = fin.get('pbr')
                        if val and val > 0:
                            factor_values.append(-val)  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ ìŒìˆ˜
                            valid_indices.append(idx)
                    elif factor_key == 'quality_roe':
                        val = fin.get('roe')
                        if val is not None:
                            factor_values.append(val)  # ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
                            valid_indices.append(idx)
                
                if len(factor_values) < 50:
                    continue
                
                factor_series = pd.Series(factor_values, index=valid_indices)
                forward_returns = self._calculate_forward_returns(df, forward_days)
                
                # ê³µí†µ ì¸ë±ìŠ¤ì—ì„œë§Œ ê°’ ì¶”ì¶œ
                common_idx = factor_series.index.intersection(forward_returns.index)
                if len(common_idx) < 50:
                    continue
                
                all_factors.extend(factor_series.loc[common_idx].tolist())
                all_returns.extend(forward_returns.loc[common_idx].tolist())
            else:
                factor_values = calc_func(df)
                forward_returns = self._calculate_forward_returns(df, forward_days)
                
                # ë™ì¼ ê¸¸ì´ ë³´ì¥
                combined = pd.DataFrame({'factor': factor_values, 'return': forward_returns}).dropna()
                all_factors.extend(combined['factor'].tolist())
                all_returns.extend(combined['return'].tolist())
        
        if len(all_factors) < 100:
            logger.warning(f"   (FactorAnalyzer) {factor_key} í‘œë³¸ ë¶€ì¡± ({len(all_factors)}ê°œ)")
            return FactorAnalysisResult(
                factor_key=factor_key,
                factor_name=factor_def['name'],
                ic_mean=0.0,
                ic_std=1.0,
                ir=0.0,
                hit_rate=0.5,
                recommended_weight=0.05,
                sample_count=len(all_factors),
            )
        
        # IC ê³„ì‚°
        factor_series = pd.Series(all_factors)
        return_series = pd.Series(all_returns)
        ic_mean, ic_std, ir = self.calculate_ic(factor_series, return_series)
        
        # ì ì¤‘ë¥  ê³„ì‚°
        combined = pd.DataFrame({'factor': all_factors, 'return': all_returns}).dropna()
        top_quantile = combined[combined['factor'] >= combined['factor'].quantile(0.8)]
        hit_rate = (top_quantile['return'] > 0).mean() if len(top_quantile) > 0 else 0.5
        
        # ì¶”ì²œ ê°€ì¤‘ì¹˜ ê³„ì‚°
        if ir >= 0.5:
            recommended_weight = min(0.20, 0.10 + ir * 0.1)
        elif ir >= 0:
            recommended_weight = 0.10
        else:
            recommended_weight = max(0.02, 0.05 + ir * 0.05)
        
        result = FactorAnalysisResult(
            factor_key=factor_key,
            factor_name=factor_def['name'],
            ic_mean=round(ic_mean, 4),
            ic_std=round(ic_std, 4),
            ir=round(ir, 4),
            hit_rate=round(hit_rate, 4),
            recommended_weight=round(recommended_weight, 4),
            sample_count=len(all_factors),
        )
        
        logger.info(f"   âœ… {factor_def['name']}: IC={ic_mean:.4f}, IR={ir:.4f}, "
                   f"ì ì¤‘ë¥ ={hit_rate:.1%}, í‘œë³¸={len(all_factors)}")
        
        return result
    
    def run_full_analysis(self, 
                          stock_codes: List[str] = None,
                          market_regime: str = 'ALL',
                          lookback_days: int = 730,
                          force_refresh: bool = False) -> Dict:
        """
        ì „ì²´ íŒ©í„° ë¶„ì„ ì‹¤í–‰ (ë°°ì¹˜ ì‘ì—…)
        
        [v1.0.2] GPT í”¼ë“œë°± ë°˜ì˜:
        - ì¬ë¬´ ë°ì´í„°(PER/PBR/ROE) ì—°ë™ íŒ©í„° ë¶„ì„
        - ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ ì˜í–¥ë„ ë¶„ì„
        - ë³µí•© ì¡°ê±´ ë¶„ì„ (ë‰´ìŠ¤+ìˆ˜ê¸‰)
        
        Args:
            stock_codes: ë¶„ì„ ëŒ€ìƒ ì¢…ëª© (Noneì´ë©´ ì „ì²´)
            market_regime: ì‹œì¥ êµ­ë©´
            lookback_days: ë¶„ì„ ê¸°ê°„ (ì¼)
            force_refresh: Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ì „ì²´ ì¬ë¶„ì„
        
        Returns:
            ë¶„ì„ ê²°ê³¼ ìš”ì•½
        """
        # lookback_daysì™€ force_refreshëŠ” í–¥í›„ ìºì‹œ ë¡œì§ì—ì„œ í™œìš©
        self.lookback_days = lookback_days
        self.force_refresh = force_refresh
        logger.info("=" * 60)
        logger.info("   ğŸ”¬ FactorAnalyzer ì „ì²´ ë¶„ì„ ì‹œì‘ (v1.0.2)")
        logger.info("=" * 60)
        
        start_time = datetime.now()
        
        # ì¢…ëª© ëª©ë¡ ì¡°íšŒ
        if stock_codes is None:
            stock_codes = self._get_all_stock_codes()
        
        logger.info(f"   ëŒ€ìƒ ì¢…ëª©: {len(stock_codes)}ê°œ")
        
        results = {
            'factor_analysis': [],
            'condition_analysis': [],
            'news_category_analysis': [],
            'compound_condition_analysis': [],
            'errors': [],
        }
        
        # 1. íŒ©í„°ë³„ ì˜ˆì¸¡ë ¥ ë¶„ì„ (ì¬ë¬´ ë°ì´í„° í¬í•¨)
        logger.info("\n   [Step 1] íŒ©í„° ì˜ˆì¸¡ë ¥ ë¶„ì„ (ì¬ë¬´ ë°ì´í„° ì—°ë™)")
        
        # ì¬ë¬´ ê´€ë ¨ íŒ©í„°ëŠ” ì¬ë¬´ ë°ì´í„°ë¥¼ í¬í•¨í•˜ì—¬ ë¶„ì„
        financial_factors = ['value_per', 'value_pbr', 'quality_roe']
        
        for factor_key in self.FACTOR_DEFINITIONS.keys():
            try:
                if factor_key in financial_factors:
                    # [v1.0.2] ì¬ë¬´ ë°ì´í„° í¬í•¨ ë¶„ì„
                    result = self.analyze_factor_with_financials(stock_codes, factor_key)
                else:
                    result = self.analyze_factor(stock_codes, factor_key)
                
                results['factor_analysis'].append(result)
                self.save_factor_metadata(result, market_regime)
            except Exception as e:
                logger.error(f"   âŒ {factor_key} ë¶„ì„ ì‹¤íŒ¨: {e}")
                results['errors'].append({'factor': factor_key, 'error': str(e)})
        
        # 2. ê¸°ë³¸ ì¡°ê±´ë¶€ ì„±ê³¼ ë¶„ì„
        logger.info("\n   [Step 2] ê¸°ë³¸ ì¡°ê±´ë¶€ ì„±ê³¼ ë¶„ì„")
        
        # RSI ê³¼ë§¤ë„ ì¡°ê±´
        def rsi_oversold_condition(df):
            close = df['CLOSE_PRICE']
            delta = close.diff()
            gain = delta.where(delta > 0, 0).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            return rsi < 30
        
        # ê±°ë˜ëŸ‰ ê¸‰ì¦ ì¡°ê±´
        def volume_surge_condition(df):
            if 'VOLUME' not in df.columns:
                return pd.Series([False] * len(df))
            vol_ma = df['VOLUME'].rolling(20).mean()
            return df['VOLUME'] > vol_ma * 2
        
        conditions = {
            'rsi_oversold_30': rsi_oversold_condition,
            'volume_surge_2x': volume_surge_condition,
        }
        
        for code in stock_codes[:50]:  # ìƒìœ„ 50ê°œ ì¢…ëª©ë§Œ ë¶„ì„
            for cond_key, cond_func in conditions.items():
                try:
                    result = self.analyze_condition_performance(
                        code, cond_key, cond_func
                    )
                    if result:
                        results['condition_analysis'].append(result)
                        self.save_factor_performance(result)
                except Exception as e:
                    logger.debug(f"   {code}/{cond_key} ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        # 3. [v1.0.2] ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ ì˜í–¥ë„ ë¶„ì„
        logger.info("\n   [Step 3] ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ ì˜í–¥ë„ ë¶„ì„")
        try:
            news_results = self.analyze_news_category_impact(stock_codes)
            results['news_category_analysis'] = news_results
        except Exception as e:
            logger.error(f"   âŒ ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            results['errors'].append({'step': 'news_category', 'error': str(e)})
        
        # 4. [v1.0.2] ë³µí•© ì¡°ê±´ ë¶„ì„ (ë‰´ìŠ¤+ìˆ˜ê¸‰)
        logger.info("\n   [Step 4] ë³µí•© ì¡°ê±´ ë¶„ì„ (ë‰´ìŠ¤+ìˆ˜ê¸‰)")
        try:
            compound_results = self.analyze_compound_conditions(stock_codes)
            results['compound_condition_analysis'] = compound_results
        except Exception as e:
            logger.error(f"   âŒ ë³µí•© ì¡°ê±´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            results['errors'].append({'step': 'compound_conditions', 'error': str(e)})

        # 5. [v1.0.3] ê³µì‹œ ì˜í–¥ë„ ë¶„ì„
        logger.info("\n   [Step 5] ê³µì‹œ ì˜í–¥ë„ ë¶„ì„ (DART)")
        try:
            disclosure_results = self.analyze_disclosure_impact(stock_codes)
            results['disclosure_analysis'] = disclosure_results
        except Exception as e:
            logger.error(f"   âŒ ê³µì‹œ ì˜í–¥ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            results['errors'].append({'step': 'disclosure', 'error': str(e)})
        
        # 6. [v1.0.6 Phase B] ì¥ê¸° ìˆ˜ìµë¥  ë¶„ì„ (D+20, D+60)
        logger.info("\n   [Step 6] ì¥ê¸° ìˆ˜ìµë¥  ë¶„ì„ (D+20, D+60)")
        results['long_term_analysis'] = {
            'D+20': [],
            'D+60': [],
        }
        
        # D+20 ë¶„ì„
        try:
            logger.info("   ğŸ“ˆ D+20 ìˆ˜ìµë¥  ë¶„ì„ ì¤‘...")
            for factor_key in ['technical_rsi_oversold', 'quality_roe', 'value_per']:
                if factor_key in financial_factors:
                    result = self.analyze_factor_with_financials(stock_codes, factor_key, forward_days=20)
                else:
                    result = self.analyze_factor(stock_codes, factor_key, forward_days=20)
                
                if result:
                    results['long_term_analysis']['D+20'].append({
                        'factor': factor_key,
                        'ic_mean': result.ic_mean,
                        'hit_rate': result.hit_rate,
                        'sample_count': result.sample_count,
                    })
                    logger.info(f"      {factor_key} (D+20): IC={result.ic_mean:.4f}, ì ì¤‘ë¥ ={result.hit_rate:.1%}")
        except Exception as e:
            logger.error(f"   âŒ D+20 ë¶„ì„ ì‹¤íŒ¨: {e}")
            results['errors'].append({'step': 'long_term_d20', 'error': str(e)})
        
        # D+60 ë¶„ì„
        try:
            logger.info("   ğŸ“ˆ D+60 ìˆ˜ìµë¥  ë¶„ì„ ì¤‘...")
            for factor_key in ['technical_rsi_oversold', 'quality_roe', 'value_per']:
                if factor_key in financial_factors:
                    result = self.analyze_factor_with_financials(stock_codes, factor_key, forward_days=60)
                else:
                    result = self.analyze_factor(stock_codes, factor_key, forward_days=60)
                
                if result:
                    results['long_term_analysis']['D+60'].append({
                        'factor': factor_key,
                        'ic_mean': result.ic_mean,
                        'hit_rate': result.hit_rate,
                        'sample_count': result.sample_count,
                    })
                    logger.info(f"      {factor_key} (D+60): IC={result.ic_mean:.4f}, ì ì¤‘ë¥ ={result.hit_rate:.1%}")
        except Exception as e:
            logger.error(f"   âŒ D+60 ë¶„ì„ ì‹¤íŒ¨: {e}")
            results['errors'].append({'step': 'long_term_d60', 'error': str(e)})
        
        # 7. [v1.0.6 Phase B] ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ì¥ê¸° ìˆ˜ìµë¥  ë¶„ì„
        logger.info("\n   [Step 7] ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ì¥ê¸° ìˆ˜ìµë¥  ë¶„ì„")
        results['news_long_term'] = {}
        
        for forward_days in [20, 60]:
            try:
                logger.info(f"   ğŸ“° ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ë³„ D+{forward_days} ë¶„ì„ ì¤‘...")
                news_results = self.analyze_news_category_impact(stock_codes, forward_days=forward_days)
                results['news_long_term'][f'D+{forward_days}'] = news_results
                
                for nr in news_results[:3]:  # ìƒìœ„ 3ê°œë§Œ ë¡œê·¸
                    logger.info(f"      {nr.get('NEWS_CATEGORY', nr.get('category', 'N/A'))} (D+{forward_days}): "
                               f"ìŠ¹ë¥ ={nr.get('WIN_RATE', nr.get('win_rate', 0)):.1%}, "
                               f"í‰ê· ìˆ˜ìµë¥ ={nr.get('AVG_RETURN', nr.get('avg_return', 0)):.2f}%")
            except Exception as e:
                logger.error(f"   âŒ ë‰´ìŠ¤ D+{forward_days} ë¶„ì„ ì‹¤íŒ¨: {e}")
                results['errors'].append({'step': f'news_d{forward_days}', 'error': str(e)})
        
        # 8. [v1.0.6 Phase B] ì„¹í„°ë³„ ë¶„ë¦¬ ë¶„ì„
        logger.info("\n   [Step 8] ì„¹í„°ë³„ ë¶„ë¦¬ ë¶„ì„")
        results['sector_analysis'] = {}
        
        try:
            # RSI ê³¼ë§¤ë„ ì „ëµì˜ ì„¹í„°ë³„ íš¨ê³¼
            logger.info("   ğŸ­ RSI ê³¼ë§¤ë„ ì „ëµ ì„¹í„°ë³„ ë¶„ì„...")
            rsi_by_sector = self.analyze_by_sector(stock_codes, 'technical_rsi_oversold', forward_days=5)
            results['sector_analysis']['rsi_oversold'] = rsi_by_sector
            
            # ROE ì „ëµì˜ ì„¹í„°ë³„ íš¨ê³¼
            logger.info("   ğŸ­ ROE ì „ëµ ì„¹í„°ë³„ ë¶„ì„...")
            roe_by_sector = self.analyze_by_sector(stock_codes, 'quality_roe', forward_days=5)
            results['sector_analysis']['quality_roe'] = roe_by_sector
            
            # ëª¨ë©˜í…€ ì „ëµì˜ ì„¹í„°ë³„ íš¨ê³¼
            logger.info("   ğŸ­ ëª¨ë©˜í…€ ì „ëµ ì„¹í„°ë³„ ë¶„ì„...")
            momentum_by_sector = self.analyze_by_sector(stock_codes, 'momentum_1m', forward_days=5)
            results['sector_analysis']['momentum_1m'] = momentum_by_sector
            
        except Exception as e:
            logger.error(f"   âŒ ì„¹í„°ë³„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            results['errors'].append({'step': 'sector_analysis', 'error': str(e)})
        
        elapsed = (datetime.now() - start_time).total_seconds()
        
        logger.info("\n" + "=" * 60)
        logger.info(f"   ğŸ FactorAnalyzer ë¶„ì„ ì™„ë£Œ (v1.0.6 Phase B, {elapsed:.1f}ì´ˆ)")
        logger.info(f"   - íŒ©í„° ë¶„ì„ (D+5): {len(results['factor_analysis'])}ê°œ")
        logger.info(f"   - ê¸°ë³¸ ì¡°ê±´ ë¶„ì„: {len(results['condition_analysis'])}ê°œ")
        logger.info(f"   - ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë¶„ì„ (D+5): {len(results['news_category_analysis'])}ê°œ")
        logger.info(f"   - ë³µí•© ì¡°ê±´ ë¶„ì„: {len(results['compound_condition_analysis'])}ê°œ")
        logger.info(f"   - ê³µì‹œ ì˜í–¥ë„ ë¶„ì„: {len(results.get('disclosure_analysis', []))}ê°œ")
        logger.info(f"   - ì¥ê¸° ìˆ˜ìµë¥  (D+20): {len(results.get('long_term_analysis', {}).get('D+20', []))}ê°œ")
        logger.info(f"   - ì¥ê¸° ìˆ˜ìµë¥  (D+60): {len(results.get('long_term_analysis', {}).get('D+60', []))}ê°œ")
        logger.info(f"   - ì„¹í„°ë³„ ë¶„ì„: {len(results.get('sector_analysis', {}))}ê°œ íŒ©í„°")
        logger.info(f"   - ì˜¤ë¥˜: {len(results['errors'])}ê°œ")
        logger.info("=" * 60)
        
        # [v1.0.5] ìƒì„¸ ìš”ì•½ ì¶œë ¥
        if results['factor_analysis']:
            logger.info("\nğŸ“Š [íŒ©í„°ë³„ ìš”ì•½]")
            for factor in results['factor_analysis']:
                if hasattr(factor, 'ic_mean'):
                    logger.info(f"   {factor.factor_key}: IC={factor.ic_mean:.4f}, "
                               f"ì ì¤‘ë¥ ={factor.hit_rate:.1%}, í‘œë³¸={factor.sample_count}")
        
        if results['compound_condition_analysis']:
            logger.info("\nğŸ”— [ë³µí•© ì¡°ê±´ ìš”ì•½]")
            for cond in results['compound_condition_analysis']:
                logger.info(f"   {cond.condition_desc}: ìŠ¹ë¥ ={cond.win_rate:.1%}, "
                           f"í‰ê· ìˆ˜ìµë¥ ={cond.avg_return:.2f}%, í‘œë³¸={cond.sample_count}")
        
        if results.get('disclosure_analysis'):
            logger.info("\nğŸ“‘ [ê³µì‹œ ì˜í–¥ë„ ìš”ì•½]")
            for disc in results['disclosure_analysis']:
                logger.info(f"   {disc['category']}: ìŠ¹ë¥ ={disc['win_rate']:.1%}, "
                           f"í‰ê· ìˆ˜ìµë¥ ={disc['avg_return']:.2f}%, í‘œë³¸={disc['sample_count']}")
        
        return results
    
    def _get_all_stock_codes(self) -> List[str]:
        """DBì—ì„œ ì „ì²´ ì¢…ëª© ì½”ë“œ ì¡°íšŒ"""
        try:
            cursor = self.db_conn.cursor()
            cursor.execute("""
                SELECT DISTINCT STOCK_CODE 
                FROM STOCK_DAILY_PRICES_3Y
                WHERE STOCK_CODE != '0001'
                LIMIT 200
            """)
            rows = cursor.fetchall()
            cursor.close()
            
            if rows:
                return [row[0] if not isinstance(row, dict) else row['STOCK_CODE'] 
                        for row in rows]
            return []
        except Exception as e:
            logger.error(f"   ì¢…ëª© ì½”ë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    # =========================================================================
    # [v1.0.5] ë°±í…ŒìŠ¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜
    # =========================================================================
    
    def run_backtest(self, 
                     stock_codes: List[str] = None,
                     start_date: datetime = None,
                     end_date: datetime = None,
                     top_n: int = 15,
                     holding_days: int = 5) -> Dict:
        """
        [v1.0.5] ê°„ë‹¨í•œ ë°±í…ŒìŠ¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜
        
        ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ì™€ ì „ëµìœ¼ë¡œ ê³¼ê±° ë°ì´í„°ì—ì„œ ì‹œë®¬ë ˆì´ì…˜:
        1. ë§¤ì¼ ì •ëŸ‰ ì ìˆ˜ ìƒìœ„ Nê°œ ì¢…ëª© ì„ ì •
        2. D+5 ìˆ˜ìµë¥  ì¸¡ì •
        3. ì „ëµë³„ ì„±ê³¼ ë¹„êµ
        
        Args:
            stock_codes: ëŒ€ìƒ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì „ì²´)
            start_date: ë°±í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼
            end_date: ë°±í…ŒìŠ¤íŠ¸ ì¢…ë£Œì¼
            top_n: ë§¤ì¼ ì„ ì •í•  ì¢…ëª© ìˆ˜
            holding_days: ë³´ìœ  ê¸°ê°„
        
        Returns:
            ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        logger.info("\n" + "=" * 60)
        logger.info("   ğŸ§ª ë°±í…ŒìŠ¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ (v1.0.5)")
        logger.info("=" * 60)
        
        if stock_codes is None:
            stock_codes = self._get_all_stock_codes()
        
        if start_date is None:
            start_date = datetime.now() - timedelta(days=180)  # ìµœê·¼ 6ê°œì›”
        if end_date is None:
            end_date = datetime.now() - timedelta(days=holding_days)  # ìˆ˜ìµë¥  ì¸¡ì • ê°€ëŠ¥í•œ ë§ˆì§€ë§‰ ë‚ 
        
        # ê°€ê²© ë°ì´í„° ë¡œë“œ
        price_data = self._get_historical_prices(stock_codes, days=365)
        news_data = self._get_news_sentiment_history(stock_codes)
        supply_data = self._get_supply_demand_data(stock_codes)
        
        # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
        results = {
            'strategy_rsi_roe': {'returns': [], 'win_count': 0, 'total_count': 0},
            'strategy_momentum': {'returns': [], 'win_count': 0, 'total_count': 0},
            'strategy_news_contrarian': {'returns': [], 'win_count': 0, 'total_count': 0},
        }
        
        # ë‚ ì§œë³„ ì‹œë®¬ë ˆì´ì…˜
        # ì‹¤ì œ ë°±í…ŒìŠ¤íŠ¸ëŠ” ë” ë³µì¡í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê°„ë‹¨ ë²„ì „ìœ¼ë¡œ êµ¬í˜„
        test_dates = []
        for code in stock_codes[:5]:  # ëŒ€í‘œ ì¢…ëª©ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
            if code in price_data:
                df = price_data[code]
                test_dates = df[
                    (df['PRICE_DATE'] >= start_date) & 
                    (df['PRICE_DATE'] <= end_date)
                ]['PRICE_DATE'].tolist()
                break
        
        if not test_dates:
            logger.warning("   ë°±í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ ë‚ ì§œ ì—†ìŒ")
            return {'error': 'No test dates available'}
        
        logger.info(f"   í…ŒìŠ¤íŠ¸ ê¸°ê°„: {len(test_dates)}ì¼, ì¢…ëª© ìˆ˜: {len(stock_codes)}")
        
        # ê°„ë‹¨í•œ ì „ëµ ì‹œë®¬ë ˆì´ì…˜ (RSI ê³¼ë§¤ë„ + ê³ ROE ì „ëµ)
        for i, test_date in enumerate(test_dates[::5]):  # 5ì¼ ê°„ê²©ìœ¼ë¡œ ìƒ˜í”Œë§
            date_scores = []
            
            for code in stock_codes:
                if code not in price_data:
                    continue
                
                df = price_data[code]
                date_idx = df[df['PRICE_DATE'] <= test_date].index
                
                if len(date_idx) < 20:
                    continue
                
                last_idx = date_idx[-1]
                
                # RSI ê³„ì‚°
                close = df['CLOSE_PRICE'].iloc[:last_idx+1]
                if len(close) < 14:
                    continue
                
                delta = close.diff()
                gain = delta.where(delta > 0, 0).rolling(window=14).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
                rs = gain / loss
                rsi = 100 - (100 / (1 + rs))
                
                if pd.isna(rsi.iloc[-1]):
                    continue
                
                current_rsi = rsi.iloc[-1]
                
                # RSI ê³¼ë§¤ë„ + ìƒìŠ¹ ëª¨ë©˜í…€ ì¡°í•© ì ìˆ˜
                rsi_score = max(0, (30 - current_rsi) / 30) if current_rsi < 30 else 0
                
                # ë¯¸ë˜ ìˆ˜ìµë¥  (ë°±í…ŒìŠ¤íŠ¸ìš©)
                future_idx = last_idx + holding_days
                if future_idx >= len(df):
                    continue
                
                future_price = df['CLOSE_PRICE'].iloc[future_idx]
                current_price = close.iloc[-1]
                forward_return = (future_price / current_price - 1) * 100
                
                date_scores.append({
                    'code': code,
                    'rsi': current_rsi,
                    'rsi_score': rsi_score,
                    'forward_return': forward_return,
                })
            
            if len(date_scores) < top_n:
                continue
            
            # RSI ê³¼ë§¤ë„ ì „ëµ ìƒìœ„ Nê°œ ì„ ì •
            date_scores_sorted = sorted(date_scores, key=lambda x: x['rsi_score'], reverse=True)
            top_stocks = date_scores_sorted[:top_n]
            
            for stock in top_stocks:
                results['strategy_rsi_roe']['returns'].append(stock['forward_return'])
                if stock['forward_return'] > 0:
                    results['strategy_rsi_roe']['win_count'] += 1
                results['strategy_rsi_roe']['total_count'] += 1
        
        # ê²°ê³¼ ìš”ì•½
        logger.info("\nğŸ“Š [ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½]")
        
        for strategy_name, strategy_result in results.items():
            if strategy_result['total_count'] > 0:
                returns = np.array(strategy_result['returns'])
                win_rate = strategy_result['win_count'] / strategy_result['total_count']
                avg_return = returns.mean()
                std_return = returns.std()
                sharpe = avg_return / std_return if std_return > 0 else 0
                
                logger.info(f"\n   {strategy_name}:")
                logger.info(f"      - ì´ ê±°ë˜: {strategy_result['total_count']}ê±´")
                logger.info(f"      - ìŠ¹ë¥ : {win_rate:.1%}")
                logger.info(f"      - í‰ê·  ìˆ˜ìµë¥ : {avg_return:.2f}%")
                logger.info(f"      - ìˆ˜ìµë¥  í‘œì¤€í¸ì°¨: {std_return:.2f}%")
                logger.info(f"      - ìƒ¤í”„ ë¹„ìœ¨: {sharpe:.2f}")
                
                results[strategy_name]['win_rate'] = win_rate
                results[strategy_name]['avg_return'] = avg_return
                results[strategy_name]['sharpe'] = sharpe
        
        logger.info("\n" + "=" * 60)
        logger.info("   ğŸ ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        logger.info("=" * 60)
        
        return results


# =============================================================================
# ë°°ì¹˜ ì‘ì—… ì‹¤í–‰ í•¨ìˆ˜
# =============================================================================

def run_weekly_factor_analysis(db_conn, market_regime: str = 'ALL') -> Dict:
    """
    ì£¼ê°„ íŒ©í„° ë¶„ì„ ë°°ì¹˜ ì‘ì—… ì‹¤í–‰
    
    Scoutì˜ 'ì§€ëŠ¥'ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ì£¼ê¸°ì  ì‘ì—….
    ê¶Œì¥: ë§¤ì£¼ ì¼ìš”ì¼ ë˜ëŠ” ì£¼ë§ì— ì‹¤í–‰.
    
    Args:
        db_conn: DB ì—°ê²° ê°ì²´
        market_regime: í˜„ì¬ ì‹œì¥ êµ­ë©´
    
    Returns:
        ë¶„ì„ ê²°ê³¼ ìš”ì•½
    """
    analyzer = FactorAnalyzer(db_conn)
    return analyzer.run_full_analysis(market_regime=market_regime)

