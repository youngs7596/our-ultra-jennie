#!/usr/bin/env python3
# Version: v1.0
# ì‘ì—… LLM: Claude Sonnet 4.5, Claude Opus 4.5
"""
Scout Job v1.0 - ì¢…ëª© ë°œêµ´ íŒŒì´í”„ë¼ì¸
- ê¹ê¹í•œ í•„í„°ë§ (ê¸°ë³¸ì ìˆ˜ 20, Hunter í†µê³¼ 60ì , Judge ìŠ¹ì¸ 75ì )
- [v1.0] ì¿¼í„°ì œ ë„ì…: ìµœì¢… Watchlist ìƒìœ„ 15ê°œë§Œ ì €ì¥
- [v1.0] Debate í”„ë¡¬í”„íŠ¸ ê°•í™”: Bull/Bear ìºë¦­í„° ê·¹ë‹¨ì ìœ¼ë¡œ ì„¤ì •
- Redis ìƒíƒœ ì €ì¥: Dashboardì—ì„œ ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ ì§„í–‰ ìƒí™© í™•ì¸ ê°€ëŠ¥
- ê²½ìŸì‚¬ ìˆ˜í˜œ ì ìˆ˜ ë°˜ì˜: ê²½ìŸì‚¬ ì•…ì¬ ì‹œ Hunter ì ìˆ˜ì— ê°€ì‚°
"""

import logging
import os
import sys
import time
import re
import threading
import json
import hashlib
from typing import Dict, Tuple, List, Optional
from datetime import datetime, timezone, timedelta
from dotenv import load_dotenv
import requests
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
import redis

# ë¡œê¹… ì„¤ì •ì„ ëª¨ë“  import ë³´ë‹¤ ë¨¼ì € ìˆ˜í–‰
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(funcName)s] - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)

logger = logging.getLogger(__name__)

# ê³µìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ë¥¼ ìœ„í•œ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))  # /app
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

import shared.auth as auth
import shared.database as database
from shared.kis import KISClient as KIS_API
from shared.kis.gateway_client import KISGatewayClient
from shared.llm import JennieBrain
from shared.financial_data_collector import batch_update_watchlist_financial_data
from shared.gemini import ensure_gemini_api_key  # [v3.0] Local Gemini Auth ì¶”ê°€

import chromadb
from langchain_chroma import Chroma
# from langchain_google_vertexai import VertexAIEmbeddings # [v3.0] Vertex AI ì œê±°
from langchain_google_genai import GoogleGenerativeAIEmbeddings # [v3.0] Gemini API Key ê¸°ë°˜

# [v3.8] FinanceDataReader for KOSPI 200 Universe
try:
    import FinanceDataReader as fdr
    FDR_AVAILABLE = True
    logger.info("âœ… FinanceDataReader ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError:
    FDR_AVAILABLE = False
    logger.warning("âš ï¸ FinanceDataReader ë¯¸ì„¤ì¹˜ - ë„¤ì´ë²„ ê¸ˆìœµ ìŠ¤í¬ë˜í•‘ìœ¼ë¡œ í´ë°±")

# [v2.2 ìˆ˜ì •] backtest ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from utilities.backtest import Backtester
    logger.info("âœ… Backtester ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ")
except ImportError as e:
    logger.warning(f"âš ï¸ Backtester ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨ (ë°±í…ŒìŠ¤íŠ¸ ê¸°ëŠ¥ ë¹„í™œì„±í™”): {e}")
    Backtester = None

# Chroma ì„œë²„
CHROMA_SERVER_HOST = os.getenv("CHROMA_SERVER_HOST", "10.178.0.2") 
CHROMA_SERVER_PORT = 8000

# --- (B) ì •ì  ìš°ëŸ‰ì£¼ ëª©ë¡ (ì•ˆì „ë§/Fallback) ---
BLUE_CHIP_STOCKS = [
    {"code": "0001", "name": "KOSPI", "is_tradable": False},
    {"code": "005930", "name": "ì‚¼ì„±ì „ì", "is_tradable": True},
    # ... (ì´í•˜ ìƒëµ, ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ ìœ ì§€)
    {"code": "000660", "name": "SKí•˜ì´ë‹‰ìŠ¤", "is_tradable": True},
    {"code": "035420", "name": "NAVER", "is_tradable": True},
    {"code": "035720", "name": "ì¹´ì¹´ì˜¤", "is_tradable": True},
]

# =============================================================================
# [v1.1 Refactored] ìºì‹œ/ìƒíƒœ ê´€ë¦¬ í•¨ìˆ˜ë“¤ì€ scout_cache.pyë¡œ ë¶„ë¦¬ë¨
# =============================================================================
from scout_cache import (
    # ìƒìˆ˜
    STATE_PREFIX, CANDIDATE_DIGEST_SUFFIX, CANDIDATE_HASHES_SUFFIX,
    LLM_CACHE_SUFFIX, LLM_LAST_RUN_SUFFIX, ISO_FORMAT_Z,
    REDIS_URL,
    # Redis í•¨ìˆ˜
    _get_redis, _utcnow, update_pipeline_status, save_pipeline_results,
    # CONFIG í…Œì´ë¸” í•¨ìˆ˜
    _get_scope, _make_state_key, _load_json_config, _save_json_config,
    _get_last_llm_run_at, _save_last_llm_run_at,
    _load_candidate_state, _save_candidate_state,
    _load_llm_cache, _save_llm_cache,
    # LLM_EVAL_CACHE í…Œì´ë¸” í•¨ìˆ˜
    _load_llm_cache_from_db, _save_llm_cache_to_db, _save_llm_cache_batch,
    # ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬ ë° í•´ì‹œ ê³„ì‚°
    _is_cache_valid_direct, _get_price_bucket, _get_volume_bucket, _get_foreign_direction,
    _hash_candidate_payload, _compute_candidate_hashes,
    _minutes_since, _parse_int_env, _is_cache_entry_valid,
    _record_to_watchlist_entry, _record_to_cache_payload, _cache_payload_to_record,
)

_redis_client = None  # scout_cacheì—ì„œ ê´€ë¦¬í•˜ì§€ë§Œ í˜¸í™˜ì„± ìœ ì§€


def prefetch_all_data(candidate_stocks: Dict[str, Dict], kis_api, vectorstore) -> Tuple[Dict[str, Dict], Dict[str, str]]:
    """
    [v4.2] Phase 1 ì‹œì‘ ì „ì— ëª¨ë“  ë°ì´í„°ë¥¼ ì¼ê´„ ì¡°íšŒí•˜ì—¬ ìºì‹œ
    
    Returns:
        (snapshot_cache, news_cache) - ì¢…ëª©ì½”ë“œë¥¼ í‚¤ë¡œ í•˜ëŠ” dict
    
    íš¨ê³¼: ë³‘ë ¬ ìŠ¤ë ˆë“œ ì•ˆì—ì„œ API í˜¸ì¶œ ì œê±° â†’ Rate Limit íšŒí”¼ + ì†ë„ í–¥ìƒ
    """
    stock_codes = list(candidate_stocks.keys())
    logger.info(f"   (Prefetch) {len(stock_codes)}ê°œ ì¢…ëª© ë°ì´í„° ì‚¬ì „ ì¡°íšŒ ì‹œì‘...")
    
    snapshot_cache: Dict[str, Dict] = {}
    news_cache: Dict[str, str] = {}
    
    prefetch_start = time.time()
    
    # 1. KIS API ìŠ¤ëƒ…ìƒ· ë³‘ë ¬ ì¡°íšŒ (4ê°œ ì›Œì»¤)
    logger.info(f"   (Prefetch) KIS ìŠ¤ëƒ…ìƒ· ì¡°íšŒ ì¤‘...")
    snapshot_start = time.time()
    
    def fetch_snapshot(code):
        try:
            if hasattr(kis_api, 'API_CALL_DELAY'):
                time.sleep(kis_api.API_CALL_DELAY * 0.3)  # ì•½ê°„ì˜ ë”œë ˆì´
            return code, kis_api.get_stock_snapshot(code)
        except Exception as e:
            logger.debug(f"   âš ï¸ [{code}] Snapshot ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return code, None
    
    with ThreadPoolExecutor(max_workers=8) as executor:
        futures = [executor.submit(fetch_snapshot, code) for code in stock_codes]
        for future in as_completed(futures):
            code, snapshot = future.result()
            if snapshot:
                snapshot_cache[code] = snapshot
    
    snapshot_time = time.time() - snapshot_start
    logger.info(f"   (Prefetch) âœ… KIS ìŠ¤ëƒ…ìƒ· {len(snapshot_cache)}/{len(stock_codes)}ê°œ ì¡°íšŒ ì™„ë£Œ ({snapshot_time:.1f}ì´ˆ)")
    
    # 2. ChromaDB ë‰´ìŠ¤ ë³‘ë ¬ ì¡°íšŒ (8ê°œ ì›Œì»¤)
    if vectorstore:
        logger.info(f"   (Prefetch) ChromaDB ë‰´ìŠ¤ ì¡°íšŒ ì¤‘...")
        news_start = time.time()
        
        def fetch_news(code_name):
            code, name = code_name
            try:
                news = fetch_stock_news_from_chroma(vectorstore, code, name, k=3)
                return code, news
            except Exception as e:
                logger.debug(f"   âš ï¸ [{code}] ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                return code, "ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨"
        
        code_name_pairs = [(code, info.get('name', '')) for code, info in candidate_stocks.items()]
        
        with ThreadPoolExecutor(max_workers=8) as executor:
            futures = [executor.submit(fetch_news, pair) for pair in code_name_pairs]
            for future in as_completed(futures):
                code, news = future.result()
                news_cache[code] = news
        
        news_time = time.time() - news_start
        valid_news = sum(1 for n in news_cache.values() if n and n not in ["ë‰´ìŠ¤ DB ë¯¸ì—°ê²°", "ìµœê·¼ ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ", "ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜", "ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨"])
        logger.info(f"   (Prefetch) âœ… ChromaDB ë‰´ìŠ¤ {valid_news}/{len(stock_codes)}ê°œ ì¡°íšŒ ì™„ë£Œ ({news_time:.1f}ì´ˆ)")
    
    total_time = time.time() - prefetch_start
    logger.info(f"   (Prefetch) âœ… ì „ì²´ ì‚¬ì „ ì¡°íšŒ ì™„ë£Œ ({total_time:.1f}ì´ˆ)")
    
    return snapshot_cache, news_cache


def enrich_candidates_with_market_data(candidate_stocks: Dict[str, Dict], db_conn, vectorstore) -> None:
    """
    [v4.1] í›„ë³´êµ°ì— ì‹œì¥ ë°ì´í„° ì¶”ê°€ (í•´ì‹œ ê³„ì‚°ìš©)
    
    í•´ì‹œì— í¬í•¨ë  ë°ì´í„°:
    - price: ìµœì‹  ì¢…ê°€ (5% ë²„í‚·í™”ë¨)
    - volume: ìµœì‹  ê±°ë˜ëŸ‰ (10ë§Œì£¼ ë²„í‚·í™”ë¨)
    - foreign_net: ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ (ë°©í–¥ë§Œ - buy/sell/neutral)
    - news_date: ìµœì‹  ë‰´ìŠ¤ ë‚ ì§œ (YYYY-MM-DD)
    """
    if not candidate_stocks:
        return
    
    stock_codes = list(candidate_stocks.keys())
    logger.info(f"   (Hash) {len(stock_codes)}ê°œ ì¢…ëª© ì‹œì¥ ë°ì´í„° ì¡°íšŒ ì¤‘...")
    
    # 1. DBì—ì„œ ìµœì‹  ê°€ê²©/ê±°ë˜ëŸ‰ ë°ì´í„° ì¼ê´„ ì¡°íšŒ
    try:
        cursor = db_conn.cursor()
        placeholders = ','.join(['%s'] * len(stock_codes))
        
        # ìµœì‹  ë‚ ì§œì˜ ë°ì´í„°ë§Œ ì¡°íšŒ (ê°€ê²©, ê±°ë˜ëŸ‰)
        # Note: foreign_net_buyëŠ” ì•„ì§ í…Œì´ë¸”ì— ì—†ìœ¼ë¯€ë¡œ ì œì™¸
        query = f"""
            SELECT STOCK_CODE, CLOSE_PRICE, VOLUME, PRICE_DATE
            FROM STOCK_DAILY_PRICES_3Y
            WHERE STOCK_CODE IN ({placeholders})
            AND PRICE_DATE = (
                SELECT MAX(PRICE_DATE) FROM STOCK_DAILY_PRICES_3Y AS sub 
                WHERE sub.STOCK_CODE = STOCK_DAILY_PRICES_3Y.STOCK_CODE
            )
        """
        cursor.execute(query, stock_codes)
        rows = cursor.fetchall()
        
        for row in rows:
            code = row['STOCK_CODE'] if isinstance(row, dict) else row[0]
            price = row['CLOSE_PRICE'] if isinstance(row, dict) else row[1]
            volume = row['VOLUME'] if isinstance(row, dict) else row[2]
            
            if code in candidate_stocks:
                candidate_stocks[code]['price'] = float(price) if price else 0
                candidate_stocks[code]['volume'] = int(volume) if volume else 0
        
        cursor.close()
        logger.info(f"   (Hash) âœ… DBì—ì„œ {len(rows)}ê°œ ì¢…ëª© ì‹œì¥ ë°ì´í„° ë¡œë“œ")
    except Exception as e:
        logger.warning(f"   (Hash) âš ï¸ DB ì‹œì¥ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
    
    # 2. ChromaDB ë‰´ìŠ¤ ì¡°íšŒ ìƒëµ (ì†ë„ ìµœì í™”)
    # ì´ìœ : í•´ì‹œì— ì˜¤ëŠ˜ ë‚ ì§œê°€ í¬í•¨ë˜ì–´ ìˆì–´ì„œ ë§¤ì¼ ì¬í‰ê°€ ë³´ì¥ë¨
    # ë‰´ìŠ¤ ë°ì´í„°ëŠ” Phase 1 Hunterì—ì„œ ê°œë³„ ì¢…ëª© í‰ê°€ ì‹œ ì¡°íšŒí•¨
    logger.info(f"   (Hash) âœ… ë‰´ìŠ¤ ë‚ ì§œ ì¡°íšŒ ìƒëµ (ë‚ ì§œ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™”ë¡œ ëŒ€ì²´)")


def _get_latest_news_date(vectorstore, stock_code: str, stock_name: str) -> Optional[str]:
    """ChromaDBì—ì„œ ì¢…ëª©ì˜ ìµœì‹  ë‰´ìŠ¤ ë‚ ì§œ ì¡°íšŒ"""
    try:
        docs = vectorstore.similarity_search(
            query=f"{stock_name}",
            k=1,
            filter={"stock_code": stock_code}
        )
        if docs and docs[0].metadata:
            # ë‰´ìŠ¤ ë‚ ì§œë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
            news_date = docs[0].metadata.get('date') or docs[0].metadata.get('published_at')
            if news_date:
                # ë‚ ì§œ ë¬¸ìì—´ì—ì„œ YYYY-MM-DDë§Œ ì¶”ì¶œ
                return str(news_date)[:10]
    except Exception:
        pass
    return None


def _record_to_cache_payload(record: Dict) -> Dict:
    metadata = record.get("llm_metadata", {})
    return {
        "code": record["code"],
        "name": record["name"],
        "llm_score": record.get("llm_score", 0),
        "llm_reason": record.get("llm_reason", ""),
        "llm_grade": metadata.get("llm_grade"),
        "decision_hash": metadata.get("decision_hash"),
        "llm_updated_at": metadata.get("llm_updated_at"),
        "is_tradable": record.get("is_tradable", True),
        "approved": record.get("approved", False),
    }


def _cache_payload_to_record(entry: Dict, decision_hash: str) -> Dict:
    updated_at = entry.get("llm_updated_at")
    metadata = {
        "llm_grade": entry.get("llm_grade"),
        "decision_hash": decision_hash,
        "llm_updated_at": updated_at,
        "source": "cache",
    }
    return {
        "code": entry["code"],
        "name": entry.get("name", entry["code"]),
        "llm_score": entry.get("llm_score", 0),
        "llm_reason": entry.get("llm_reason", ""),
        "is_tradable": entry.get("is_tradable", True),
        "approved": entry.get("approved", False),
        "llm_metadata": metadata,
    }

# =============================================================================
# ì„¹í„°/í…Œë§ˆ ë¶„ì„ ê¸°ëŠ¥ (v3.8)
# =============================================================================

# ì„¹í„° ë¶„ë¥˜ (KOSPI ì£¼ìš” ì„¹í„°)
SECTOR_MAPPING = {
    # ë°˜ë„ì²´/IT
    '005930': 'ë°˜ë„ì²´', '000660': 'ë°˜ë„ì²´', '009150': 'ë°˜ë„ì²´', '034220': 'ë°˜ë„ì²´',
    '066570': 'IT/ì „ì', '018260': 'IT/ì „ì', '017670': 'IT/í†µì‹ ', '030200': 'IT/í†µì‹ ',
    # ìë™ì°¨
    '005380': 'ìë™ì°¨', '000270': 'ìë™ì°¨', '012330': 'ìë™ì°¨', '086280': 'ìë™ì°¨', '018880': 'ìë™ì°¨',
    # ë°°í„°ë¦¬/ì—ë„ˆì§€
    '373220': 'ë°°í„°ë¦¬', '006400': 'ë°°í„°ë¦¬', '051910': 'í™”í•™', '096770': 'ì—ë„ˆì§€', '010950': 'ì—ë„ˆì§€',
    '003670': 'ë°°í„°ë¦¬', '361610': 'ë°°í„°ë¦¬',
    # ë°”ì´ì˜¤/í—¬ìŠ¤ì¼€ì–´
    '207940': 'ë°”ì´ì˜¤', '068270': 'ë°”ì´ì˜¤', '302440': 'ë°”ì´ì˜¤', '326030': 'ë°”ì´ì˜¤',
    # ì¸í„°ë„·/í”Œë«í¼
    '035420': 'ì¸í„°ë„·', '035720': 'ì¸í„°ë„·', '323410': 'ì¸í„°ë„·', '377300': 'ì¸í„°ë„·',
    # ê¸ˆìœµ
    '105560': 'ê¸ˆìœµ', '055550': 'ê¸ˆìœµ', '086790': 'ê¸ˆìœµ', '316140': 'ê¸ˆìœµ', '032830': 'ê¸ˆìœµ', '024110': 'ê¸ˆìœµ', '000810': 'ê¸ˆìœµ',
    # ì² ê°•/ì†Œì¬
    '005490': 'ì² ê°•', '010130': 'ì² ê°•', '011170': 'í™”í•™',
    # ê²Œì„/ì—”í„°
    '259960': 'ê²Œì„', '036570': 'ê²Œì„', '251270': 'ê²Œì„', '352820': 'ì—”í„°',
    # ìœ í†µ/ì†Œë¹„ì¬
    '051900': 'ì†Œë¹„ì¬', '090430': 'ì†Œë¹„ì¬', '033780': 'ì†Œë¹„ì¬',
    # ê±´ì„¤/ì¸í”„ë¼
    '028260': 'ê±´ì„¤', '015760': 'ì¸í”„ë¼', '009540': 'ì¡°ì„ ',
    # ì§€ì£¼íšŒì‚¬
    '034730': 'ì§€ì£¼', '003550': 'ì§€ì£¼',
}

def analyze_sector_momentum(kis_api, db_conn, watchlist_snapshot=None):
    """
    [v3.8] ì„¹í„°ë³„ ëª¨ë©˜í…€ ë¶„ì„
    ê° ì„¹í„°ì˜ í‰ê·  ìˆ˜ìµë¥ ì„ ê³„ì‚°í•˜ì—¬ í•« ì„¹í„°ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.
    
    Returns:
        dict: {ì„¹í„°ëª…: {'momentum': float, 'stocks': list, 'avg_return': float}}
    """
    logger.info("   (E) ì„¹í„°ë³„ ëª¨ë©˜í…€ ë¶„ì„ ì‹œì‘...")
    
    sector_data = {}
    
    try:
        # KOSPI 200 ì¢…ëª© ê°€ì ¸ì˜¤ê¸°
        if FDR_AVAILABLE:
            df_kospi = fdr.StockListing('KOSPI')
            top_200 = df_kospi.head(200) if len(df_kospi) > 200 else df_kospi
            
            for _, row in top_200.iterrows():
                code = str(row.get('Code', row.get('Symbol', ''))).zfill(6)
                name = row.get('Name', row.get('ì¢…ëª©ëª…', ''))
                
                # ì„¹í„° ë¶„ë¥˜
                sector = SECTOR_MAPPING.get(code, 'ê¸°íƒ€')
                
                if sector not in sector_data:
                    sector_data[sector] = {'stocks': [], 'returns': []}
                
                # ìµœê·¼ ìˆ˜ìµë¥  ê³„ì‚° (ë³€ë™ë¥  % ì‚¬ìš©)
                try:
                    # [v1.0 Fix] ChangesëŠ” ê¸ˆì•¡, ChagesRatio/ChangesRatioê°€ %
                    # FinanceDataReader ë²„ì „ì— ë”°ë¼ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
                    change_pct = row.get('ChagesRatio') or row.get('ChangesRatio') or row.get('ChangeRatio')
                    
                    if change_pct is None:
                        # Changes(ê¸ˆì•¡)ë¥¼ Close(ì¢…ê°€)ë¡œ ë‚˜ëˆ ì„œ % ê³„ì‚°
                        changes = float(row.get('Changes', 0))
                        close = float(row.get('Close', row.get('Price', 1)))
                        if close > 0:
                            change_pct = (changes / close) * 100
                        else:
                            change_pct = 0
                    else:
                        change_pct = float(change_pct)
                    
                    # ë¹„ì •ìƒì ì¸ ê°’ í•„í„°ë§ (Â±50% ì´ˆê³¼ëŠ” ë¬´ì‹œ)
                    if abs(change_pct) > 50:
                        continue
                    
                    sector_data[sector]['stocks'].append({'code': code, 'name': name})
                    sector_data[sector]['returns'].append(change_pct)
                except (ValueError, TypeError):
                    continue
        
        # ì„¹í„°ë³„ í‰ê·  ìˆ˜ìµë¥  ê³„ì‚°
        hot_sectors = {}
        for sector, data in sector_data.items():
            if data['returns']:
                avg_return = sum(data['returns']) / len(data['returns'])
                hot_sectors[sector] = {
                    'avg_return': avg_return,
                    'stock_count': len(data['stocks']),
                    'stocks': data['stocks'][:5],  # ìƒìœ„ 5ê°œ ì¢…ëª©ë§Œ
                }
        
        # ìˆ˜ìµë¥  ê¸°ì¤€ ì •ë ¬
        sorted_sectors = sorted(hot_sectors.items(), key=lambda x: x[1]['avg_return'], reverse=True)
        
        logger.info(f"   (E) âœ… ì„¹í„° ë¶„ì„ ì™„ë£Œ. í•« ì„¹í„° TOP 3:")
        for i, (sector, info) in enumerate(sorted_sectors[:3]):
            logger.info(f"       {i+1}. {sector}: í‰ê·  ìˆ˜ìµë¥  {info['avg_return']:.2f}%")
        
        return dict(sorted_sectors)
        
    except Exception as e:
        logger.warning(f"   (E) âš ï¸ ì„¹í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {}


def get_hot_sector_stocks(sector_analysis, top_n=30):
    """
    [v3.8] í•« ì„¹í„°ì˜ ì¢…ëª©ë“¤ì„ ìš°ì„  í›„ë³´ë¡œ ë°˜í™˜
    ìƒìœ„ 3ê°œ ì„¹í„°ì˜ ì¢…ëª©ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not sector_analysis:
        return []
    
    hot_stocks = []
    sorted_sectors = list(sector_analysis.items())[:3]  # ìƒìœ„ 3ê°œ ì„¹í„°
    
    for sector, info in sorted_sectors:
        for stock in info.get('stocks', []):
            hot_stocks.append({
                'code': stock['code'],
                'name': stock['name'],
                'sector': sector,
                'sector_momentum': info['avg_return'],
            })
    
    return hot_stocks[:top_n]


def get_dynamic_blue_chips(limit=200):
    """
    KOSPI ì‹œê°€ì´ì•¡ ìƒìœ„ ì¢…ëª©ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (KOSPI 200 ê¸°ì¤€)
    
    1ì°¨: FinanceDataReader ì‚¬ìš© (ì•ˆì •ì , ì‹œê°€ì´ì•¡ ìˆœ ì •ë ¬)
    2ì°¨: ë„¤ì´ë²„ ê¸ˆìœµ ìŠ¤í¬ë˜í•‘ (í´ë°±)
    
    Args:
        limit: ìˆ˜ì§‘í•  ì¢…ëª© ìˆ˜ (ê¸°ë³¸ê°’: 200, KOSPI 200 ê¸°ì¤€)
    """
    # 1ì°¨ ì‹œë„: FinanceDataReader (ê¶Œì¥)
    if FDR_AVAILABLE:
        try:
            logger.info(f"   (A) FinanceDataReaderë¡œ KOSPI ì‹œì´ ìƒìœ„ {limit}ê°œ ì¡°íšŒ ì¤‘...")
            
            # KOSPI ì „ì²´ ì¢…ëª© ì¡°íšŒ
            df_kospi = fdr.StockListing('KOSPI')
            
            # ì‹œê°€ì´ì•¡ ê¸°ì¤€ ì •ë ¬ (Marcap ì»¬ëŸ¼)
            if 'Marcap' in df_kospi.columns:
                df_sorted = df_kospi.sort_values('Marcap', ascending=False).head(limit)
            elif 'Market' in df_kospi.columns:
                # Marcapì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ìƒìœ„ Nê°œ (ì´ë¯¸ ì‹œì´ìˆœì¼ ìˆ˜ ìˆìŒ)
                df_sorted = df_kospi.head(limit)
            else:
                df_sorted = df_kospi.head(limit)
            
            dynamic_list = []
            for _, row in df_sorted.iterrows():
                code = str(row.get('Code', row.get('Symbol', ''))).zfill(6)
                name = row.get('Name', row.get('ì¢…ëª©ëª…', ''))
                if code and name:
                    dynamic_list.append({'code': code, 'name': name})
            
            logger.info(f"   (A) âœ… FinanceDataReaderë¡œ {len(dynamic_list)}ê°œ ì¢…ëª© ë¡œë“œ ì™„ë£Œ. (KOSPI ì‹œì´ ìƒìœ„)")
            return dynamic_list
            
        except Exception as e:
            logger.warning(f"   (A) âš ï¸ FinanceDataReader ì‹¤íŒ¨, ë„¤ì´ë²„ ê¸ˆìœµìœ¼ë¡œ í´ë°±: {e}")
    
    # 2ì°¨ ì‹œë„: ë„¤ì´ë²„ ê¸ˆìœµ ìŠ¤í¬ë˜í•‘ (í´ë°±)
    logger.info(f"   (A) ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ KOSPI ì‹œê°€ì´ì•¡ ìƒìœ„ {limit}ê°œ ìŠ¤í¬ë˜í•‘ ì‹œë„...")
    dynamic_list = []
    seen_codes = set()
    
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        base_url = "https://finance.naver.com/sise/sise_market_sum.naver?sosok=0"
        
        # ë„¤ì´ë²„ ê¸ˆìœµì€ í˜ì´ì§€ë‹¹ 50ê°œì”© í‘œì‹œ
        pages_needed = (limit + 49) // 50
        
        for page in range(1, pages_needed + 1):
            if len(dynamic_list) >= limit:
                break
                
            url = f"{base_url}&page={page}"
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            table = soup.find('table', class_='type_2')
            if not table:
                logger.warning(f"   (A) âš ï¸ í˜ì´ì§€ {page} í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                continue
                
            rows = table.find_all('tr')
            page_count = 0
            for row in rows:
                if len(dynamic_list) >= limit:
                    break
                
                cols = row.find_all('td')
                if len(cols) > 1 and cols[0].text.strip().isdigit():
                    a_tag = cols[1].find('a')
                    if a_tag and 'href' in a_tag.attrs and 'code=' in a_tag['href']:
                        code = a_tag['href'].split('code=')[1]
                        name = a_tag.text.strip()
                        
                        if code not in seen_codes:
                            seen_codes.add(code)
                            dynamic_list.append({'code': code, 'name': name})
                            page_count += 1
            
            logger.debug(f"   (A) í˜ì´ì§€ {page}: {page_count}ê°œ ì¶”ê°€ (ëˆ„ì : {len(dynamic_list)}ê°œ)")
            
            if page < pages_needed:
                time.sleep(0.3)
        
        logger.info(f"   (A) âœ… ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ {len(dynamic_list)}ê°œ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ.")
    except Exception as e:
        logger.error(f"   (A) âŒ ë™ì  ìš°ëŸ‰ì£¼ ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    return dynamic_list

def get_momentum_stocks(kis_api, db_conn, period_months=6, top_n=30, watchlist_snapshot=None):
    """
    ëª¨ë©˜í…€ íŒ©í„° ê¸°ë°˜ ì¢…ëª© ì„ ë³„
    """
    logger.info(f"   (D) ëª¨ë©˜í…€ íŒ©í„° ê³„ì‚° ì¤‘ (ê¸°ê°„: {period_months}ê°œì›”, ìƒìœ„ {top_n}ê°œ)...")
    momentum_scores = []
    
    try:
        # 1. KOSPI ìˆ˜ìµë¥  ê³„ì‚°
        kospi_code = "0001"
        period_days = period_months * 30
        kospi_prices = database.get_daily_prices(db_conn, kospi_code, limit=period_days)
        
        if kospi_prices.empty or len(kospi_prices) < period_days * 0.8:
            logger.warning(f"   (D) âš ï¸ KOSPI ë°ì´í„° ë¶€ì¡± ({len(kospi_prices)}ì¼). ëª¨ë©˜í…€ ê³„ì‚° ê±´ë„ˆëœ€.")
            return []
        
        kospi_start_price = float(kospi_prices['CLOSE_PRICE'].iloc[0])
        kospi_end_price = float(kospi_prices['CLOSE_PRICE'].iloc[-1])
        kospi_return = (kospi_end_price / kospi_start_price - 1) * 100
        
        # 2. Watchlist ë˜ëŠ” BLUE_CHIP_STOCKSì—ì„œ ì¢…ëª© ê°€ì ¸ì˜¤ê¸°
        # [v4.5] ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ ì „ì²´ ì¢…ëª© ëŒ€ìƒìœ¼ë¡œ ë³€ê²½ (Watchlist í•œì • X)
        all_codes = database.get_all_stock_codes(db_conn)
        
        if not all_codes:
            # Fallback: Watchlist or Bluechips
            watchlist = watchlist_snapshot or database.get_active_watchlist(db_conn)
            if not watchlist:
                stocks_to_check = [s for s in BLUE_CHIP_STOCKS if s.get('is_tradable', True)]
            else:
                stocks_to_check = [{'code': code, 'name': info.get('name', code)} for code, info in watchlist.items() if info.get('is_tradable', True)]
        else:
             # ì „ì²´ ì¢…ëª© (ì´ë¦„ì€ ì¼ë‹¨ ì½”ë“œë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ ì¶”í›„ DBì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ)
             stocks_to_check = [{'code': code, 'name': code} for code in all_codes]

        logger.info(f"   (D) {len(stocks_to_check)}ê°œ ì¢…ëª©ì˜ ëª¨ë©˜í…€ ê³„ì‚° ì¤‘... (ì „ì²´ ëŒ€ìƒ)")
        
        # 3. ê° ì¢…ëª©ì˜ ëª¨ë©˜í…€ ê³„ì‚°
        for stock in stocks_to_check:
            try:
                code = stock['code']
                name = stock.get('name', code)
                
                stock_prices = database.get_daily_prices(db_conn, code, limit=period_days)
                
                if stock_prices.empty or len(stock_prices) < period_days * 0.8:
                    continue
                
                stock_start_price = float(stock_prices['CLOSE_PRICE'].iloc[0])
                stock_end_price = float(stock_prices['CLOSE_PRICE'].iloc[-1])
                stock_return = (stock_end_price / stock_start_price - 1) * 100
                
                relative_momentum = stock_return - kospi_return
                
                momentum_scores.append({
                    'code': code,
                    'name': name,
                    'momentum': relative_momentum,
                    'absolute_return': stock_return,
                    'kospi_return': kospi_return
                })
                
                if hasattr(kis_api, 'API_CALL_DELAY'):
                    time.sleep(kis_api.API_CALL_DELAY * 0.1)
                
            except Exception as e:
                logger.debug(f"   (D) {stock.get('name', stock.get('code'))} ëª¨ë©˜í…€ ê³„ì‚° ì˜¤ë¥˜: {e}")
                continue
        
        momentum_scores.sort(key=lambda x: x['momentum'], reverse=True)
        
        logger.info(f"   (D) âœ… ëª¨ë©˜í…€ ê³„ì‚° ì™„ë£Œ. ìƒìœ„ {min(top_n, len(momentum_scores))}ê°œ ë°˜í™˜")
        return momentum_scores[:top_n]
        
    except Exception as e:
        logger.error(f"   (D) âŒ ëª¨ë©˜í…€ íŒ©í„° ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return []

# [v2.0] ìë™ íŒŒë¼ë¯¸í„° ìµœì í™” í•¨ìˆ˜ë“¤ (ìƒëµ ì—†ì´ ì „ì²´ í¬í•¨)
def run_auto_parameter_optimization(db_conn, brain):
    """
    [v2.2] ìë™ íŒŒë¼ë¯¸í„° ìµœì í™” íŒŒì´í”„ë¼ì¸
    """
    logger.info("=" * 80)
    logger.info("   [v2.2 AUTO-OPTIMIZATION] ìë™ íŒŒë¼ë¯¸í„° ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    logger.info("=" * 80)
    
    try:
        logger.info("   [Step 1/5] í˜„ì¬ íŒŒë¼ë¯¸í„° ì¡°íšŒ ì¤‘...")
        current_params = database.get_all_config(db_conn)
        backtest_period = int(current_params.get('AUTO_OPTIMIZATION_PERIOD_DAYS', '90'))
        
        if not current_params:
            logger.warning("   âš ï¸ CONFIG í…Œì´ë¸”ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ìµœì í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        
        logger.info(f"   âœ… í˜„ì¬ íŒŒë¼ë¯¸í„° {len(current_params)}ê°œ ì¡°íšŒ ì™„ë£Œ")
        
        logger.info("   [Step 2/5] í˜„ì¬ íŒŒë¼ë¯¸í„°ë¡œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        current_performance = run_simple_backtest(db_conn, current_params)
        
        if not current_performance:
            logger.warning("   âš ï¸ í˜„ì¬ íŒŒë¼ë¯¸í„° ë°±í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ìµœì í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        
        logger.info(f"   âœ… í˜„ì¬ ì„±ê³¼: MDD {current_performance['mdd']:.2f}%, ì—°í™˜ì‚°ìˆ˜ìµë¥  {current_performance['return']:.2f}%")
        
        logger.info("   [Step 3/5] ìµœì í™” í›„ë³´ íŒŒë¼ë¯¸í„° ìƒì„± ì¤‘...")
        new_params = generate_optimized_params(current_params)
        logger.info(f"   âœ… ìµœì í™” í›„ë³´ íŒŒë¼ë¯¸í„° ìƒì„± ì™„ë£Œ (ë³€ê²½: {len(new_params)}ê°œ)")
        
        logger.info("   [Step 4/5] ìµœì í™” í›„ë³´ë¡œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        new_performance = run_simple_backtest(db_conn, {**current_params, **new_params})
        
        if not new_performance:
            logger.warning("   âš ï¸ ìµœì í™” í›„ë³´ ë°±í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ìµœì í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        
        logger.info(f"   âœ… ìµœì í™” ì„±ê³¼: MDD {new_performance['mdd']:.2f}%, ì—°í™˜ì‚°ìˆ˜ìµë¥  {new_performance['return']:.2f}%")
        
        logger.info("   [Step 5/5] AI ê²€ì¦ (LLM) ì‹œì‘...")
        market_summary = f"ìµœê·¼ {backtest_period}ì¼ ì‹œì¥ ìš”ì•½"
        
        verification_result = verify_params_with_llm(
            brain, current_params, current_performance,
            new_params, new_performance, market_summary
        )
        
        if not verification_result:
            logger.warning("   âš ï¸ AI ê²€ì¦ ì‹¤íŒ¨. ìµœì í™”ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return False
        
        is_approved = verification_result.get('is_approved', False)
        confidence = verification_result.get('confidence_score', 0.0)
        reasoning = verification_result.get('reasoning', 'N/A')
        
        logger.info(f"   âœ… AI ê²€ì¦ ì™„ë£Œ: {is_approved}, ì‹ ë¢°ë„: {confidence:.2f}")
        
        logger.info("   [v2.2] ìµœì í™” ì´ë ¥ DB ì €ì¥ ì¤‘...")
        ai_decision = 'APPROVED' if is_approved else 'REJECTED'
        
        optimization_id = database.save_optimization_history(
            connection=db_conn,
            current_params=current_params,
            new_params=new_params,
            current_performance=current_performance,
            new_performance=new_performance,
            ai_decision=ai_decision,
            ai_reasoning=reasoning,
            ai_confidence=confidence,
            market_summary=market_summary,
            backtest_period=backtest_period
        )
        
        if is_approved and confidence > 0.7:
            logger.info("   [Auto-Update] CONFIG í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì‹œì‘...")
            update_count = 0
            for key, value in new_params.items():
                try:
                    database.set_config(db_conn, key, value)
                    update_count += 1
                    logger.info(f"   - {key}: {current_params.get(key)} â†’ {value}")
                except Exception as e:
                    logger.error(f"   âŒ {key} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            
            logger.info(f"   âœ… [Auto-Update] {update_count}/{len(new_params)}ê°œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
            
            if optimization_id:
                database.mark_optimization_applied(db_conn, optimization_id)
            return True
        else:
            logger.warning(f"   âš ï¸ [Auto-Update] ìŠ¹ì¸ ê±°ë¶€ ë˜ëŠ” ì‹ ë¢°ë„ ë¶€ì¡± (ì‹ ë¢°ë„: {confidence:.2f} < 0.7)")
            return False
        
    except Exception as e:
        logger.error(f"   âŒ [AUTO-OPTIMIZATION] ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return False
    finally:
        logger.info("=" * 80)

def _get_param(params: Dict, key: str, default, cast_type=float):
    try:
        if key not in params or params[key] is None:
            return default
        return cast_type(params[key])
    except (ValueError, TypeError):
        return default

def run_simple_backtest(db_conn, params):
    try:
        if Backtester is None:
            logger.error("   (Backtest) âŒ Backtester ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìµœì í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None
        
        logger.info("   (Backtest) Backtester ê¸°ë°˜ ê²€ì¦ ì‹¤í–‰ ì¤‘...")
        
        backtester = Backtester(
            db_conn,
            max_buys_per_day=_get_param(params, 'MAX_BUYS_PER_DAY', 100, int),
            profit_target_full=_get_param(params, 'PROFIT_TARGET_FULL', 10.0, float),
            profit_target_partial=_get_param(params, 'PROFIT_TARGET_PARTIAL', 5.0, float),
            rsi_threshold_1=_get_param(params, 'RSI_THRESHOLD_1', 70.0, float),
            rsi_threshold_2=_get_param(params, 'RSI_THRESHOLD_2', 75.0, float),
            rsi_threshold_3=_get_param(params, 'RSI_THRESHOLD_3', 80.0, float),
            time_based_bull=_get_param(params, 'TIME_BASED_BULL', 30, int),
            time_based_sideways=_get_param(params, 'TIME_BASED_SIDEWAYS', 30, int),
            max_position_pct=_get_param(params, 'MAX_POSITION_PCT', 5, int),
            cash_keep_pct=_get_param(params, 'CASH_KEEP_PCT', 5, int),
            hybrid_mode=True,
        )
        
        metrics = backtester.run()
        if not metrics:
            logger.warning("   (Backtest) ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        monthly_return = metrics.get('monthly_return_pct')
        total_return = metrics.get('total_return_pct')
        
        return {
            'mdd': float(metrics.get('mdd_pct', 0.0)),
            'return': float(monthly_return if monthly_return is not None else (total_return or 0.0))
        }
        
    except Exception as e:
        logger.error(f"   (Backtest) ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}", exc_info=True)
        return None

def generate_optimized_params(current_params):
    new_params = {}
    if 'SELL_RSI_OVERBOUGHT_THRESHOLD' in current_params:
        current_value = float(current_params['SELL_RSI_OVERBOUGHT_THRESHOLD'])
        adjustment = current_value * 0.05
        new_value = min(80, current_value + adjustment)
        new_params['SELL_RSI_OVERBOUGHT_THRESHOLD'] = new_value
    
    if 'ATR_MULTIPLIER' in current_params:
        current_value = float(current_params['ATR_MULTIPLIER'])
        adjustment = 0.1
        new_value = min(3.0, current_value + adjustment)
        new_params['ATR_MULTIPLIER'] = new_value
    
    return new_params

def verify_params_with_llm(brain, current_params, current_performance, 
                           new_params, new_performance, market_summary):
    try:
        logger.info("   (LLM) [v2.2] JennieBrainì„ í†µí•œ AI ê²€ì¦ ì‹œì‘...")
        result = brain.verify_parameter_change(
            current_params=current_params,
            new_params=new_params,
            current_performance=current_performance,
            new_performance=new_performance,
            market_summary=market_summary
        )
        if result:
            logger.info(f"   (LLM) âœ… AI ê²€ì¦ ì™„ë£Œ: {result.get('is_approved')}")
        return result
    except Exception as e:
        logger.error(f"   (LLM) âŒ AI ê²€ì¦ ì˜¤ë¥˜: {e}", exc_info=True)
        return None

def fetch_stock_news_from_chroma(vectorstore, stock_code: str, stock_name: str, k: int = 3) -> str:
    """
    [v3.9] ChromaDBì—ì„œ ì¢…ëª©ë³„ ìµœì‹  ë‰´ìŠ¤ ê²€ìƒ‰
    
    Args:
        vectorstore: ChromaDB vectorstore ì¸ìŠ¤í„´ìŠ¤
        stock_code: ì¢…ëª© ì½”ë“œ
        stock_name: ì¢…ëª©ëª…
        k: ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜
        
    Returns:
        ë‰´ìŠ¤ ìš”ì•½ ë¬¸ìì—´ (ì—†ìœ¼ë©´ "ìµœê·¼ ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ")
    """
    if not vectorstore:
        return "ë‰´ìŠ¤ DB ë¯¸ì—°ê²°"
    
    try:
        from datetime import datetime, timedelta, timezone
        
        # ìµœì‹  7ì¼ ì´ë‚´ ë‰´ìŠ¤ í•„í„°
        recency_timestamp = int((datetime.now(timezone.utc) - timedelta(days=7)).timestamp())
        
        # ì¢…ëª© ì½”ë“œë¡œ í•„í„°ë§ëœ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹œë„
        try:
            docs = vectorstore.similarity_search(
                query=f"{stock_name} ì‹¤ì  ìˆ˜ì£¼ í˜¸ì¬",
                k=k,
                filter={"stock_code": stock_code}
            )
            # logger.debug(f"   (D) [{stock_code}] í•„í„° ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê±´")
        except Exception:
            # í•„í„° ì‹¤íŒ¨ì‹œ ì¢…ëª©ëª…ìœ¼ë¡œ ê²€ìƒ‰
            docs = vectorstore.similarity_search(
                query=f"{stock_name} ì£¼ì‹ ë‰´ìŠ¤",
                k=k
            )
            logger.debug(f"   (D) [{stock_code}] ì¢…ëª©ëª… ê²€ìƒ‰(Fallback): {len(docs)}ê±´")
            # ì¢…ëª© ê´€ë ¨ ë‰´ìŠ¤ë§Œ í•„í„°ë§
            docs = [d for d in docs if stock_name in d.page_content or stock_code in str(d.metadata)]
        
        if docs:
            news_items = []
            for i, doc in enumerate(docs[:k], 1):
                content = doc.page_content[:100].strip()
                if content:
                    news_items.append(f"[ë‰´ìŠ¤{i}] {content}")
            
            if news_items:
                return " | ".join(news_items)
        
        return "ìµœê·¼ ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ"
        
    except Exception as e:
        logger.debug(f"   âš ï¸ [{stock_code}] ChromaDB ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return "ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜"


# =============================================================================
# [v1.0] Scout Hybrid Scoring Pipeline - ì •ëŸ‰ ê¸°ë°˜ í•„í„°ë§
# =============================================================================

def is_hybrid_scoring_enabled() -> bool:
    """Scout v1.0 í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ í™œì„±í™” ì—¬ë¶€ í™•ì¸ (SCOUT_V5_ENABLED í™˜ê²½ë³€ìˆ˜ - í•˜ìœ„í˜¸í™˜)"""
    return os.getenv("SCOUT_V5_ENABLED", "false").lower() == "true"


def process_quant_scoring_task(stock_info, quant_scorer, db_conn, kospi_prices_df=None):
    """
    [v1.0] Step 1: ì •ëŸ‰ ì ìˆ˜ ê³„ì‚° (LLM í˜¸ì¶œ ì—†ìŒ, ë¹„ìš© 0ì›)
    
    ì„¸ ì„¤ê³„ì˜ í•µì‹¬ ì•„ì´ë””ì–´ êµ¬í˜„:
    - Claude: ì •ëŸ‰ ì ìˆ˜ë¥¼ LLMê³¼ ë…ë¦½ì ìœ¼ë¡œ ê³„ì‚°
    - Gemini: ë¹„ìš© 0ì›ìœ¼ë¡œ 1ì°¨ í•„í„°ë§
    - GPT: ì¡°ê±´ë¶€ ìŠ¹ë¥  ê¸°ë°˜ ì ìˆ˜ ì‚°ì¶œ
    
    [v1.0] Gemini í”¼ë“œë°± ë°˜ì˜:
    - ë°ì´í„° ë¶€ì¡± ì‹œ is_valid=False ì„¤ì •í•˜ì—¬ "ë¬»ì–´ê°€ê¸°" í•©ê²© ë°©ì§€
    
    Args:
        stock_info: {'code': str, 'info': dict, 'snapshot': dict}
        quant_scorer: QuantScorer ì¸ìŠ¤í„´ìŠ¤
        db_conn: DB ì—°ê²° (ì¼ë´‰ ë°ì´í„° ì¡°íšŒìš©)
        kospi_prices_df: KOSPI ì¼ë´‰ ë°ì´í„°
    
    Returns:
        QuantScoreResult ê°ì²´
    """
    code = stock_info['code']
    info = stock_info['info']
    snapshot = stock_info.get('snapshot', {}) or {}
    
    try:
        # ì¼ë´‰ ë°ì´í„° ì¡°íšŒ
        daily_prices_df = database.get_daily_prices(db_conn, code, limit=150)
        
        # [v1.0] ë°ì´í„° ë¶€ì¡± ì‹œ is_valid=False ì„¤ì • (ë¬»ì–´ê°€ê¸° ë°©ì§€)
        if daily_prices_df.empty or len(daily_prices_df) < 30:
            data_len = len(daily_prices_df) if not daily_prices_df.empty else 0
            logger.debug(f"   âš ï¸ [Quant] {info['name']}({code}) ì¼ë´‰ ë°ì´í„° ë¶€ì¡± ({data_len}ì¼) â†’ is_valid=False")
            from shared.hybrid_scoring import QuantScoreResult
            return QuantScoreResult(
                stock_code=code,
                stock_name=info['name'],
                total_score=0.0,  # [v1.0] 0ì  (ì¤‘ë¦½ 50ì  ì•„ë‹˜!)
                momentum_score=0.0,
                quality_score=0.0,
                value_score=0.0,
                technical_score=0.0,
                news_stat_score=0.0,
                supply_demand_score=0.0,
                matched_conditions=[],
                condition_win_rate=None,
                condition_sample_count=0,
                condition_confidence='LOW',
                is_valid=False,  # [v1.0] ë¬»ì–´ê°€ê¸° ë°©ì§€
                invalid_reason=f'ë°ì´í„° ë¶€ì¡± ({data_len}ì¼)',
                details={'note': f'ë°ì´í„° ë¶€ì¡± ({data_len}ì¼)'},
            )
        
        # ì •ëŸ‰ ì ìˆ˜ ê³„ì‚°
        result = quant_scorer.calculate_total_quant_score(
            stock_code=code,
            stock_name=info['name'],
            daily_prices_df=daily_prices_df,
            kospi_prices_df=kospi_prices_df,
            pbr=snapshot.get('pbr'),
            per=snapshot.get('per'),
            current_sentiment_score=info.get('sentiment_score', 50),
            foreign_net_buy=snapshot.get('foreign_net_buy'),
        )
        
        # [v1.0] ì—­ì‹ í˜¸ ì¹´í…Œê³ ë¦¬ ì²´í¬
        # íŒ©í„° ë¶„ì„ ê²°ê³¼: ìˆ˜ì£¼(43.7%), ë°°ë‹¹(37.6%) ë‰´ìŠ¤ëŠ” ì—­ì‹ í˜¸!
        REVERSE_SIGNAL_CATEGORIES = {'ìˆ˜ì£¼', 'ë°°ë‹¹', 'ìì‚¬ì£¼', 'ì£¼ì£¼í™˜ì›', 'ë°°ë‹¹ë½'}
        news_category = info.get('news_category') or snapshot.get('news_category')
        
        if news_category and news_category in REVERSE_SIGNAL_CATEGORIES:
            sentiment_score = info.get('sentiment_score', 50)
            if sentiment_score >= 70:  # í˜¸ì¬ë¡œ ë¶„ë¥˜ëœ ê²½ìš°
                logger.warning(f"   âš ï¸ [v1.0] {info['name']}({code}) ì—­ì‹ í˜¸ ì¹´í…Œê³ ë¦¬({news_category}) ê°ì§€ - "
                              f"í†µê³„ìƒ ìŠ¹ë¥  50% ë¯¸ë§Œ, ì ìˆ˜ íŒ¨ë„í‹° ì ìš©")
                # ê²°ê³¼ì— ì—­ì‹ í˜¸ ì •ë³´ ì¶”ê°€
                if result.details is None:
                    result.details = {}
                result.details['reverse_signal_category'] = news_category
                result.details['reverse_signal_warning'] = True
        
        logger.debug(f"   âœ… [Quant] {info['name']}({code}) - {result.total_score:.1f}ì ")
        return result
        
    except Exception as e:
        logger.error(f"   âŒ [Quant] {code} ì •ëŸ‰ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
        from shared.hybrid_scoring import QuantScoreResult
        # [v1.0] ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ is_valid=False ì„¤ì • (ë¬»ì–´ê°€ê¸° ë°©ì§€)
        return QuantScoreResult(
            stock_code=code,
            stock_name=info['name'],
            total_score=0.0,  # [v1.0] 0ì  (ì¤‘ë¦½ 50ì  ì•„ë‹˜!)
            momentum_score=0.0,
            quality_score=0.0,
            value_score=0.0,
            technical_score=0.0,
            news_stat_score=0.0,
            supply_demand_score=0.0,
            matched_conditions=[],
            condition_win_rate=None,
            condition_sample_count=0,
            condition_confidence='LOW',
            is_valid=False,  # [v1.0] ë¬»ì–´ê°€ê¸° ë°©ì§€
            invalid_reason=f'ê³„ì‚° ì˜¤ë¥˜: {str(e)[:30]}',
            details={'error': str(e)},
        )


def process_phase1_hunter_v5_task(stock_info, brain, quant_result, snapshot_cache=None, news_cache=None):
    """
    [v1.0] Phase 1 Hunter - ì •ëŸ‰ ì»¨í…ìŠ¤íŠ¸ í¬í•¨ LLM ë¶„ì„
    [v1.0] ê²½ìŸì‚¬ ìˆ˜í˜œ ì ìˆ˜ ë°˜ì˜ ì¶”ê°€
    
    ê¸°ì¡´ Hunterì™€ ë‹¬ë¦¬, QuantScorerì˜ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•˜ì—¬
    LLMì´ ë°ì´í„° ê¸°ë°˜ íŒë‹¨ì„ í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
    """
    from shared.hybrid_scoring import format_quant_score_for_prompt
    
    code = stock_info['code']
    info = stock_info['info']
    
    # ì •ëŸ‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    quant_context = format_quant_score_for_prompt(quant_result)
    
    # [v1.0] ê²½ìŸì‚¬ ìˆ˜í˜œ ì ìˆ˜ ì¡°íšŒ
    competitor_benefit = database.get_competitor_benefit_score(code)
    competitor_bonus = competitor_benefit.get('score', 0)
    competitor_reason = competitor_benefit.get('reason', '')
    
    snapshot = snapshot_cache.get(code) if snapshot_cache else None
    if not snapshot:
        return {
            'code': code,
            'name': info['name'],
            'info': info,
            'snapshot': None,
            'quant_result': quant_result,
            'hunter_score': 0,
            'hunter_reason': 'ìŠ¤ëƒ…ìƒ· ì¡°íšŒ ì‹¤íŒ¨',
            'passed': False,
            'competitor_bonus': competitor_bonus,
        }
    
    news_from_chroma = news_cache.get(code, "ìµœê·¼ ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ") if news_cache else "ë‰´ìŠ¤ ìºì‹œ ì—†ìŒ"
    
    # [v1.0] ê²½ìŸì‚¬ ìˆ˜í˜œ ì •ë³´ë¥¼ ë‰´ìŠ¤ì— ì¶”ê°€
    if competitor_bonus > 0:
        news_from_chroma += f"\n\nâš¡ [ê²½ìŸì‚¬ ìˆ˜í˜œ ê¸°íšŒ] {competitor_reason} (+{competitor_bonus}ì )"
    
    decision_info = {
        'code': code,
        'name': info['name'],
        'technical_reason': 'N/A',
        'news_reason': news_from_chroma if news_from_chroma not in ["ë‰´ìŠ¤ DB ë¯¸ì—°ê²°", "ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜"] else ', '.join(info.get('reasons', [])),
        'per': snapshot.get('per'),
        'pbr': snapshot.get('pbr'),
        'market_cap': snapshot.get('market_cap'),
    }
    
    # [v1.0] ì •ëŸ‰ ì»¨í…ìŠ¤íŠ¸ í¬í•¨ Hunter í˜¸ì¶œ
    hunter_result = brain.get_jennies_analysis_score_v5(decision_info, quant_context)
    hunter_score = hunter_result.get('score', 0)
    
    # [v1.0] ê²½ìŸì‚¬ ìˆ˜í˜œ ê°€ì‚°ì  ì ìš© (ìµœëŒ€ +10ì )
    if competitor_bonus > 0:
        hunter_score = min(100, hunter_score + competitor_bonus)
        logger.info(f"   ğŸ¯ [ê²½ìŸì‚¬ ìˆ˜í˜œ] {info['name']}({code}) +{competitor_bonus}ì  ê°€ì‚° ({competitor_reason})")
    
    # [v1.0] ì •ëŸ‰+ì •ì„± í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜
    # [v4.1] ê¸°ì¤€ ìƒí–¥ 75ì 
    passed = hunter_score >= 75
    if hunter_score == 0: passed = False
    
    if passed:
        logger.info(f"   âœ… [v5 Hunter í†µê³¼] {info['name']}({code}) - Quant:{quant_result.total_score:.0f} â†’ Hunter:{hunter_score}ì ")
    else:
        logger.debug(f"   âŒ [v5 Hunter íƒˆë½] {info['name']}({code}) - Quant:{quant_result.total_score:.0f} â†’ Hunter:{hunter_score}ì ")
    
    return {
        'code': code,
        'name': info['name'],
        'info': info,
        'snapshot': snapshot,
        'decision_info': decision_info,
        'quant_result': quant_result,
        'hunter_score': hunter_score,
        'hunter_reason': hunter_result.get('reason', ''),
        'passed': passed,
        'competitor_bonus': competitor_bonus,  # [v1.0] ê²½ìŸì‚¬ ìˆ˜í˜œ ì ìˆ˜
        'competitor_reason': competitor_reason,
    }


def process_phase23_judge_v5_task(phase1_result, brain):
    """
    [v1.0] Phase 2-3: Debate + Judge (ì •ëŸ‰ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
    
    ì •ëŸ‰ ë¶„ì„ ê²°ê³¼ë¥¼ Judge í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•˜ì—¬
    í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.
    """
    from shared.hybrid_scoring import format_quant_score_for_prompt
    
    code = phase1_result['code']
    info = phase1_result['info']
    decision_info = phase1_result['decision_info']
    quant_result = phase1_result['quant_result']
    hunter_score = phase1_result['hunter_score']
    
    logger.info(f"   ğŸ”„ [v5 Phase 2-3] {info['name']}({code}) Debate-Judge ì‹œì‘...")
    
    # ì •ëŸ‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    quant_context = format_quant_score_for_prompt(quant_result)
    
    # Phase 2: Debate (Bull vs Bear)
    debate_log = brain.run_debate_session(decision_info)
    
    # Phase 3: Judge (ì •ëŸ‰ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
    judge_result = brain.run_judge_scoring_v5(decision_info, debate_log, quant_context)
    score = judge_result.get('score', 0)
    grade = judge_result.get('grade', 'D')
    reason = judge_result.get('reason', 'ë¶„ì„ ì‹¤íŒ¨')
    
    # [v1.0] í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° (ì •ëŸ‰ 60% + ì •ì„± 40%)
    # Gemini ì„¤ê³„ì˜ ì•ˆì „ì¥ì¹˜: ì°¨ì´ 30ì  ì´ìƒì‹œ ë³´ìˆ˜ì  ê°€ì¤‘ì¹˜
    quant_score = quant_result.total_score
    llm_score = score
    
    score_diff = abs(quant_score - llm_score)
    if score_diff >= 30:
        # ì•ˆì „ì¥ì¹˜ ë°œë™: ë‚®ì€ ìª½ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì´ë™
        if quant_score < llm_score:
            hybrid_score = quant_score * 0.75 + llm_score * 0.25
            logger.warning(f"   âš ï¸ [Safety Lock] {info['name']} - ì •ëŸ‰({quant_score:.0f}) << ì •ì„±({llm_score}) â†’ ë³´ìˆ˜ì  íŒë‹¨")
        else:
            hybrid_score = quant_score * 0.45 + llm_score * 0.55
            logger.warning(f"   âš ï¸ [Safety Lock] {info['name']} - ì •ì„±({llm_score}) << ì •ëŸ‰({quant_score:.0f}) â†’ ë³´ìˆ˜ì  íŒë‹¨")
    else:
        # ê¸°ë³¸ ë¹„ìœ¨: ì •ëŸ‰ 60% + ì •ì„± 40%
        hybrid_score = quant_score * 0.60 + llm_score * 0.40
    
    # ìµœì¢… íŒë‹¨
    is_tradable = hybrid_score >= 75  # Aë“±ê¸‰ ì´ìƒ
    approved = hybrid_score >= 50     # Cë“±ê¸‰ ì´ìƒ
    
    # ë“±ê¸‰ ì¬ê²°ì •
    if hybrid_score >= 80:
        final_grade = 'S'
    elif hybrid_score >= 70:
        final_grade = 'A'
    elif hybrid_score >= 60:
        final_grade = 'B'
    elif hybrid_score >= 50:
        final_grade = 'C'
    else:
        final_grade = 'D'
    
    if approved:
        logger.info(f"   âœ… [v5 Judge ìŠ¹ì¸] {info['name']}({code}) - Hybrid:{hybrid_score:.1f}ì  ({final_grade})")
    else:
        logger.info(f"   âŒ [v5 Judge ê±°ì ˆ] {info['name']}({code}) - Hybrid:{hybrid_score:.1f}ì  ({final_grade})")
    
    metadata = {
        'llm_grade': final_grade,
        'llm_updated_at': _utcnow().isoformat(),
        'source': 'hybrid_scorer_v5',
        'quant_score': quant_score,
        'llm_raw_score': llm_score,
        'hybrid_score': hybrid_score,
        'hunter_score': hunter_score,
        'condition_win_rate': quant_result.condition_win_rate,
    }
    
    return {
        'code': code,
        'name': info['name'],
        'is_tradable': is_tradable,
        'llm_score': hybrid_score,  # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ì €ì¥
        'llm_reason': reason,
        'approved': approved,
        'llm_metadata': metadata,
    }


def process_phase1_hunter_task(stock_info, brain, snapshot_cache=None, news_cache=None):
    """
    [v4.2] Phase 1 Hunterë§Œ ì‹¤í–‰í•˜ëŠ” íƒœìŠ¤í¬ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
    
    ë³€ê²½ì‚¬í•­:
    - KIS API ìŠ¤ëƒ…ìƒ·: ì‚¬ì „ ìºì‹œì—ì„œ ì¡°íšŒ (API í˜¸ì¶œ X)
    - ChromaDB ë‰´ìŠ¤: ì‚¬ì „ ìºì‹œì—ì„œ ì¡°íšŒ (HTTP ìš”ì²­ X)
    - LLM í˜¸ì¶œë§Œ ìˆ˜í–‰ â†’ Rate Limit ëŒ€ì‘ ìš©ì´
    """
    code = stock_info['code']
    info = stock_info['info']
    
    # [v4.2] ìºì‹œì—ì„œ ìŠ¤ëƒ…ìƒ· ì¡°íšŒ (API í˜¸ì¶œ X)
    snapshot = snapshot_cache.get(code) if snapshot_cache else None
    if not snapshot:
        logger.debug(f"   âš ï¸ [Phase 1] {info['name']}({code}) Snapshot ìºì‹œ ë¯¸ìŠ¤")
        return {
            'code': code,
            'name': info['name'],
            'info': info,
            'snapshot': None,
            'hunter_score': 0,
            'hunter_reason': 'ìŠ¤ëƒ…ìƒ· ì¡°íšŒ ì‹¤íŒ¨',
            'passed': False,
        }

    factor_info = ""
    momentum_value = None
    for reason in info.get('reasons', []):
        if 'ëª¨ë©˜í…€' in reason:
            factor_info = reason
            try:
                match = re.search(r'([\d.-]+)%', reason)
                if match:
                    momentum_value = float(match.group(1))
            except Exception:
                pass
            break
    
    # [v4.2] ìºì‹œì—ì„œ ë‰´ìŠ¤ ì¡°íšŒ (HTTP ìš”ì²­ X)
    news_from_chroma = news_cache.get(code, "ìµœê·¼ ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ") if news_cache else "ë‰´ìŠ¤ ìºì‹œ ì—†ìŒ"
    
    # ê¸°ì¡´ reasons + ChromaDB ë‰´ìŠ¤ ê²°í•©
    all_reasons = info.get('reasons', []).copy()
    if news_from_chroma and news_from_chroma not in ["ë‰´ìŠ¤ DB ë¯¸ì—°ê²°", "ìµœê·¼ ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ", "ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜", "ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨", "ë‰´ìŠ¤ ìºì‹œ ì—†ìŒ"]:
        all_reasons.append(news_from_chroma)
    
    decision_info = {
        'code': code,
        'name': info['name'],
        'technical_reason': 'N/A (ì „ëµ ë³€ê²½)',
        'news_reason': news_from_chroma if news_from_chroma not in ["ë‰´ìŠ¤ DB ë¯¸ì—°ê²°", "ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜"] else ', '.join(info['reasons']),
        'per': snapshot.get('per'),
        'pbr': snapshot.get('pbr'),
        'market_cap': snapshot.get('market_cap'),
        'factor_info': factor_info,
        'momentum_score': momentum_value
    }

    # Phase 1: Hunter (Gemini-Flashë¡œ ë¹ ë¥¸ í•„í„°ë§)
    hunter_result = brain.get_jennies_analysis_score(decision_info)
    hunter_score = hunter_result.get('score', 0)
    
    # [v1.0] Phase 1 í†µê³¼ ê¸°ì¤€: 60ì  ì´ìƒ (ìƒìœ„ 40~50ê°œ, ì•½ 20~25% ëª©í‘œ)
    passed = hunter_score >= 60
    if passed:
        logger.info(f"   âœ… [Phase 1 í†µê³¼] {info['name']}({code}) - Hunter: {hunter_score}ì ")
    else:
        logger.debug(f"   âŒ [Phase 1 íƒˆë½] {info['name']}({code}) - Hunter: {hunter_score}ì ")
    
    return {
        'code': code,
        'name': info['name'],
        'info': info,
        'snapshot': snapshot,
        'decision_info': decision_info,
        'hunter_score': hunter_score,
        'hunter_reason': hunter_result.get('reason', ''),
        'passed': passed,
    }


def process_phase23_debate_judge_task(phase1_result, brain):
    """
    [v3.8] Phase 2-3 (Debate + Judge) ì‹¤í–‰í•˜ëŠ” íƒœìŠ¤í¬ (Phase 1 í†µê³¼ ì¢…ëª©ë§Œ)
    GPT-5-minië¡œ ì‹¬ì¸µ ë¶„ì„
    """
    code = phase1_result['code']
    info = phase1_result['info']
    decision_info = phase1_result['decision_info']
    hunter_score = phase1_result['hunter_score']
    
    logger.info(f"   ğŸ”„ [Phase 2-3] {info['name']}({code}) Debate-Judge ì‹œì‘...")
    
    # Phase 2: Debate (Bull vs Bear)
    debate_log = brain.run_debate_session(decision_info)
    
    # Phase 3: Judge (Supreme Jennie)
    judge_result = brain.run_judge_scoring(decision_info, debate_log)
    score = judge_result.get('score', 0)
    grade = judge_result.get('grade', 'D')
    reason = judge_result.get('reason', 'ë¶„ì„ ì‹¤íŒ¨')
    
    # [v1.0] ìµœì¢… íŒë‹¨ - Judge ìŠ¹ì¸ ê¸°ì¤€ ì™„í™” (60â†’50ì )
    is_tradable = score >= 75  # ê°•ë ¥ ë§¤ìˆ˜: 75ì  ì´ìƒ (Aë“±ê¸‰)
    approved = score >= 50     # Watchlist ë“±ë¡: 50ì  ì´ìƒ (Cë“±ê¸‰ ì´ìƒ)
    
    if approved:
        logger.info(f"   âœ… [Judge ìŠ¹ì¸] {info['name']}({code}) - ìµœì¢…: {score}ì  ({grade})")
    else:
        logger.info(f"   âŒ [Judge ê±°ì ˆ] {info['name']}({code}) - ìµœì¢…: {score}ì  ({grade})")
    
    # ë©”íƒ€ë°ì´í„°ì— í† ë¡  ìš”ì•½ ì¼ë¶€ í¬í•¨
    metadata = {
        'llm_grade': grade,
        'llm_updated_at': _utcnow().isoformat(),
        'source': 'llm_judge',
        'hunter_score': hunter_score,
    }
    
    return {
        'code': code,
        'name': info['name'],
        'is_tradable': is_tradable,
        'llm_score': score,
        'llm_reason': reason,
        'approved': approved,
        'llm_metadata': metadata,
    }


def process_llm_decision_task(stock_info, kis_api, brain):
    """
    [Deprecated in v3.8] ê¸°ì¡´ ë‹¨ì¼ íŒ¨ìŠ¤ ì²˜ë¦¬ (í˜¸í™˜ì„± ìœ ì§€ìš©)
    """
    code = stock_info['code']
    info = stock_info['info']
    decision_hash = stock_info['decision_hash']
    
    if hasattr(kis_api, 'API_CALL_DELAY'):
        time.sleep(kis_api.API_CALL_DELAY)
    
    snapshot = kis_api.get_stock_snapshot(code)
    if not snapshot:
        logger.warning(f"   âš ï¸ [LLM ë¶„ì„] {info['name']}({code}) Snapshot ì¡°íšŒ ì‹¤íŒ¨")
        return {
            'code': code,
            'name': info['name'],
            'is_tradable': False,
            'llm_score': 0,
            'llm_reason': 'ìŠ¤ëƒ…ìƒ· ì¡°íšŒ ì‹¤íŒ¨',
            'approved': False,
            'llm_metadata': {
                'llm_grade': 'D',
                'decision_hash': decision_hash,
                'llm_updated_at': _utcnow().isoformat(),
                'source': 'llm',
            }
        }

    factor_info = ""
    momentum_value = None
    for reason in info.get('reasons', []):
        if 'ëª¨ë©˜í…€ íŒ©í„°' in reason:
            factor_info = reason
            try:
                match = re.search(r'ìƒëŒ€ ëª¨ë©˜í…€: ([\d.-]+)%', reason)
                if match:
                    momentum_value = float(match.group(1))
            except Exception:
                pass
            break
    
    decision_info = {
        'code': code,
        'name': info['name'],
        'technical_reason': 'N/A (ì „ëµ ë³€ê²½)',
        'news_reason': ', '.join(info['reasons']),
        'per': snapshot.get('per'),
        'pbr': snapshot.get('pbr'),
        'market_cap': snapshot.get('market_cap'),
        'factor_info': factor_info,
        'momentum_score': momentum_value
    }

    # [v1.0] Scout 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì ìš©
    
    # 1. Phase 1: Hunter (High Recall Filtering)
    # - ê¸°ì¡´ ë¶„ì„ ë¡œì§ì„ í™œìš©í•˜ë˜, ê¸°ì¤€ì„ ëŒ€í­ ë‚®ì¶°ì„œ(40ì ) ì ì¬ë ¥ ìˆëŠ” ì¢…ëª©ì„ ë„“ê²Œ ì¡ìŒ
    hunter_result = brain.get_jennies_analysis_score(decision_info)
    hunter_score = hunter_result.get('score', 0)
    
    if hunter_score < 40:
        logger.info(f"   âŒ [Phase 1 íƒˆë½] {info['name']}({code}) - Hunterì ìˆ˜: {hunter_score}ì  (ë¯¸ë‹¬)")
        return {
            'code': code,
            'name': info['name'],
            'is_tradable': False,
            'llm_score': hunter_score,
            'llm_reason': hunter_result.get('reason', 'Phase 1 í•„í„°ë§ íƒˆë½'),
            'approved': False,
            'llm_metadata': {
                'llm_grade': 'D',
                'decision_hash': decision_hash,
                'llm_updated_at': _utcnow().isoformat(),
                'source': 'llm_hunter_reject',
            }
        }
    
    logger.info(f"   âœ… [Phase 1 í†µê³¼] {info['name']}({code}) - Hunterì ìˆ˜: {hunter_score}ì  -> Debate ì§„ì¶œ")

    # 2. Phase 2: Debate (Bull vs Bear)
    # - í†µê³¼ëœ ì¢…ëª©ì— ëŒ€í•´ ì°¬ë°˜ í† ë¡  ì‹œë®¬ë ˆì´ì…˜
    debate_log = brain.run_debate_session(decision_info)
    
    # 3. Phase 3: Judge (Supreme Jennie)
    # - í† ë¡  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… íŒê²°
    judge_result = brain.run_judge_scoring(decision_info, debate_log)
    score = judge_result.get('score', 0)
    grade = judge_result.get('grade', 'D')
    reason = judge_result.get('reason', 'ë¶„ì„ ì‹¤íŒ¨')
    
    # [v1.0] ìµœì¢… íŒë‹¨ - Judge ìŠ¹ì¸ ê¸°ì¤€ ì™„í™” (60â†’50ì )
    is_tradable = score >= 75  # ê°•ë ¥ ë§¤ìˆ˜: 75ì  ì´ìƒ (Aë“±ê¸‰)
    approved = score >= 50     # Watchlist ë“±ë¡: 50ì  ì´ìƒ (Cë“±ê¸‰ ì´ìƒ)
    
    # ë©”íƒ€ë°ì´í„°ì— í† ë¡  ìš”ì•½ ì¼ë¶€ í¬í•¨ (ì„ íƒ ì‚¬í•­)
    metadata = {
        'llm_grade': grade,
        'decision_hash': decision_hash,
        'llm_updated_at': _utcnow().isoformat(),
        'source': 'llm_judge',
        'debate_summary': debate_log[:200] + "..." if len(debate_log) > 200 else debate_log
    }
    
    if approved:
        logger.info(f"   ğŸ‰ [Judge ìŠ¹ì¸] {info['name']}({code}) - ìµœì¢…: {score}ì  ({grade})")
    else:
        logger.info(f"   âŒ [Judge ê±°ì ˆ] {info['name']}({code}) - ìµœì¢…: {score}ì  ({grade})")
    
    return {
        'code': code,
        'name': info['name'],
        'is_tradable': is_tradable,
        'llm_score': score,
        'llm_reason': reason,
        'approved': approved,
        'llm_metadata': metadata,
    }

def fetch_kis_data_task(stock, kis_api):
    try:
        stock_code = stock['code']
        
        if hasattr(kis_api, 'API_CALL_DELAY'):
            time.sleep(kis_api.API_CALL_DELAY)
        
        price_data = kis_api.get_stock_daily_prices(stock_code, num_days_to_fetch=30)
        
        daily_prices = []
        if price_data is not None:
            if hasattr(price_data, 'empty') and not price_data.empty:
                for _, dp in price_data.iterrows():
                    # DataFrame ì»¬ëŸ¼ ì ‘ê·¼ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ (close_price ë˜ëŠ” price)
                    close_price = dp.get('close_price') if 'close_price' in dp.index else dp.get('price')
                    high_price = dp.get('high_price') if 'high_price' in dp.index else dp.get('high')
                    low_price = dp.get('low_price') if 'low_price' in dp.index else dp.get('low')
                    date_val = dp.get('price_date') if 'price_date' in dp.index else dp.get('date')
                    
                    if close_price is not None:
                        daily_prices.append({
                            'p_date': date_val, 'p_code': stock_code,
                            'p_price': close_price, 'p_high': high_price, 'p_low': low_price
                        })
            elif isinstance(price_data, list) and len(price_data) > 0:
                for dp in price_data:
                    if isinstance(dp, dict):
                        # dict ì ‘ê·¼ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ (close_price ë˜ëŠ” price)
                        close_price = dp.get('close_price') or dp.get('price')
                        high_price = dp.get('high_price') or dp.get('high')
                        low_price = dp.get('low_price') or dp.get('low')
                        date_val = dp.get('price_date') or dp.get('date')
                        
                        if close_price is not None:
                            daily_prices.append({
                                'p_date': date_val, 'p_code': stock_code,
                                'p_price': close_price, 'p_high': high_price, 'p_low': low_price
                            })
        
        fundamentals = None
        if stock.get("is_tradable", False):
            snapshot = kis_api.get_stock_snapshot(stock_code)
            if hasattr(kis_api, 'API_CALL_DELAY'):
                time.sleep(kis_api.API_CALL_DELAY)
            if snapshot:
                fundamentals = {
                    'code': stock_code,
                    'per': snapshot.get('per'),
                    'pbr': snapshot.get('pbr'),
                    'market_cap': snapshot.get('market_cap')
                }
        
        return daily_prices, fundamentals
    except Exception as e:
        logger.error(f"   (DW) âŒ {stock.get('name', 'N/A')} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return [], None

def main():
    start_time = time.time()
    logger.info("--- ğŸ¤– 'Scout Job' [v3.0 Local] ì‹¤í–‰ ì‹œì‘ ---")
    
    db_conn = None
    kis_api = None
    brain = None
    chroma_client = None

    try:
        logger.info("--- [Init] í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° MariaDB/KIS API ì—°ê²° ì‹œì‘ ---")
        load_dotenv()
        
        logger.info("ğŸ”§ DB ì—°ê²° ì¤‘... (SQLAlchemy ì‚¬ìš©)")
        db_conn = database.get_db_connection()
        if db_conn is None:
            raise Exception("MariaDB ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        logger.info("âœ… DB ì—°ê²° ì™„ë£Œ")
        
        trading_mode = os.getenv("TRADING_MODE", "REAL")
        use_gateway = os.getenv("USE_KIS_GATEWAY", "true").lower() == "true"
        
        if use_gateway:
            kis_api = KISGatewayClient()
            logger.info("âœ… KIS Gateway Client ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            kis_api = KIS_API(
                app_key=auth.get_secret(os.getenv(f"{trading_mode}_SECRET_ID_APP_KEY")),
                app_secret=auth.get_secret(os.getenv(f"{trading_mode}_SECRET_ID_APP_SECRET")),
                base_url=os.getenv(f"KIS_BASE_URL_{trading_mode}"),
                account_prefix=auth.get_secret(os.getenv(f"{trading_mode}_SECRET_ID_ACCOUNT_PREFIX")),
                account_suffix=os.getenv("KIS_ACCOUNT_SUFFIX"),
                token_file_path="/app/tokens/kis_token_scout.json",
                trading_mode=trading_mode
            )
            if not kis_api.authenticate():
                raise Exception("KIS API ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        brain = JennieBrain(
            project_id=os.getenv("GCP_PROJECT_ID", "local"),
            gemini_api_key_secret=os.getenv("SECRET_ID_GEMINI_API_KEY")
        )
        watchlist_snapshot = database.get_active_watchlist(db_conn)
        
        # ChromaDB ì´ˆê¸°í™”
        vectorstore = None
        try:
            logger.info("   ... ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹œë„ (Gemini Embeddings) ...")
            api_key = ensure_gemini_api_key()
            embeddings = GoogleGenerativeAIEmbeddings(
                model="models/gemini-embedding-001", 
                google_api_key=api_key
            )
            
            chroma_client = chromadb.HttpClient(
                host=CHROMA_SERVER_HOST, 
                port=CHROMA_SERVER_PORT
            )
            vectorstore = Chroma(
                client=chroma_client, 
                collection_name="rag_stock_data", 
                embedding_function=embeddings
            )
            logger.info("âœ… [v3.0] LLM ë° ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ.")
        except Exception as e:
            logger.warning(f"âš ï¸ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨ (RAG ê¸°ëŠ¥ ë¹„í™œì„±í™”): {e}")
            vectorstore = None

        # [Phase 0] ìë™ íŒŒë¼ë¯¸í„° ìµœì í™” (ë¹„í™œì„±í™”)
        # logger.info("--- [Phase 0] ìë™ íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘ ---")
        # try:
        #     if run_auto_parameter_optimization(db_conn, brain):
        #         logger.info("   âœ… ìë™ íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ!")
        #     else:
        #         logger.info("   â­ï¸ ìë™ íŒŒë¼ë¯¸í„° ìµœì í™” ê±´ë„ˆëœ€")
        # except Exception as e:
        #     logger.error(f"   âŒ ìë™ íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")

        # Phase 1: íŠ¸ë¦¬í”Œ ì†ŒìŠ¤ í›„ë³´ ë°œêµ´ (v3.8: ì„¹í„° ë¶„ì„ ì¶”ê°€)
        logger.info("--- [Phase 1] íŠ¸ë¦¬í”Œ ì†ŒìŠ¤ í›„ë³´ ë°œêµ´ ì‹œì‘ ---")
        update_pipeline_status(phase=1, phase_name="Hunter Scout", status="running", progress=0)
        candidate_stocks = {}

        # A: ë™ì  ìš°ëŸ‰ì£¼ (KOSPI 200 ê¸°ì¤€)
        universe_size = int(os.getenv("SCOUT_UNIVERSE_SIZE", "200"))
        for stock in get_dynamic_blue_chips(limit=universe_size):
            candidate_stocks[stock['code']] = {'name': stock['name'], 'reasons': ['KOSPI ì‹œì´ ìƒìœ„']}
        
        # E: ì„¹í„° ëª¨ë©˜í…€ ë¶„ì„ (v3.8 ì‹ ê·œ)
        sector_analysis = analyze_sector_momentum(kis_api, db_conn, watchlist_snapshot)
        hot_sector_stocks = get_hot_sector_stocks(sector_analysis, top_n=30)
        for stock in hot_sector_stocks:
            if stock['code'] not in candidate_stocks:
                candidate_stocks[stock['code']] = {
                    'name': stock['name'], 
                    'reasons': [f"í•« ì„¹í„° ({stock['sector']}, +{stock['sector_momentum']:.1f}%)"]
                }
            else:
                candidate_stocks[stock['code']]['reasons'].append(
                    f"í•« ì„¹í„° ({stock['sector']}, +{stock['sector_momentum']:.1f}%)"
                )

        # B: ì •ì  ìš°ëŸ‰ì£¼
        for stock in BLUE_CHIP_STOCKS:
            if stock['code'] not in candidate_stocks:
                candidate_stocks[stock['code']] = {'name': stock['name'], 'reasons': ['ì •ì  ìš°ëŸ‰ì£¼']}

        # C: RAG
        if vectorstore:
            try:
                logger.info("   (C) RAG ê¸°ë°˜ í›„ë³´ ë°œêµ´ ì¤‘...")
                rag_results = vectorstore.similarity_search(query="ì‹¤ì  í˜¸ì¬ ê³„ì•½ ìˆ˜ì£¼", k=50)
                for doc in rag_results:
                    stock_code = doc.metadata.get('stock_code')
                    stock_name = doc.metadata.get('stock_name')
                    if stock_code and stock_name:
                        if stock_code not in candidate_stocks:
                            candidate_stocks[stock_code] = {'name': stock_name, 'reasons': []}
                        candidate_stocks[stock_code]['reasons'].append(f"RAG í¬ì°©: {doc.page_content[:20]}...")
            except Exception as e:
                logger.warning(f"   (C) RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

        # D: ëª¨ë©˜í…€
        logger.info("   (D) ëª¨ë©˜í…€ íŒ©í„° ê¸°ë°˜ ì¢…ëª© ë°œêµ´ ì¤‘...")
        momentum_stocks = get_momentum_stocks(
            kis_api,
            db_conn,
            period_months=6,
            top_n=30,
            watchlist_snapshot=watchlist_snapshot
        )
        for stock in momentum_stocks:
            if stock['code'] not in candidate_stocks:
                candidate_stocks[stock['code']] = {
                    'name': stock['name'], 
                    'reasons': [f'ëª¨ë©˜í…€ ({stock["momentum"]:.1f}%)']
                }
        
        logger.info(f"   âœ… í›„ë³´êµ° {len(candidate_stocks)}ê°œ ë°œêµ´ ì™„ë£Œ.")

        # [v4.1] í•´ì‹œ ê³„ì‚° ì „ì— ì‹œì¥ ë°ì´í„° ì¶”ê°€ (ê°€ê²©, ê±°ë˜ëŸ‰)
        logger.info("--- [Phase 1.5] ì‹œì¥ ë°ì´í„° ê¸°ë°˜ í•´ì‹œ ê³„ì‚° ---")
        enrich_candidates_with_market_data(candidate_stocks, db_conn, vectorstore)
        
        # [v4.2] Phase 1 ì‹œì‘ ì „ì— ëª¨ë“  ë°ì´í„° ì¼ê´„ ì¡°íšŒ (ë³‘ë ¬ ìŠ¤ë ˆë“œ ì•ˆ API í˜¸ì¶œ ì œê±°)
        logger.info("--- [Phase 1.6] ë°ì´í„° ì‚¬ì „ ì¡°íšŒ (ìŠ¤ëƒ…ìƒ·/ë‰´ìŠ¤) ---")
        snapshot_cache, news_cache = prefetch_all_data(candidate_stocks, kis_api, vectorstore)

        # [v4.3] ë‰´ìŠ¤ í•´ì‹œë¥¼ candidate_stocksì— ë°˜ì˜ (í•´ì‹œ ê³„ì‚°ì— í¬í•¨)
        # ë‰´ìŠ¤ ë‚´ìš©ì´ ë°”ë€Œë©´ í•´ì‹œê°€ ë‹¬ë¼ì ¸ LLM ì¬í˜¸ì¶œë¨
        news_hash_count = 0
        for code, news in news_cache.items():
            if code in candidate_stocks and news and news not in [
                "ë‰´ìŠ¤ DB ë¯¸ì—°ê²°", "ìµœê·¼ ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ", "ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜", 
                "ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨", "ë‰´ìŠ¤ ìºì‹œ ì—†ìŒ"
            ]:
                # ë‰´ìŠ¤ ë‚´ìš©ì˜ MD5 í•´ì‹œ (ì‹œê°„ ì •ë³´ í¬í•¨ë˜ì–´ ìˆìŒ)
                candidate_stocks[code]['news_hash'] = hashlib.md5(news.encode()).hexdigest()[:16]
                news_hash_count += 1
        logger.info(f"   (Hash) âœ… ë‰´ìŠ¤ í•´ì‹œ {news_hash_count}ê°œ ë°˜ì˜ ì™„ë£Œ")

        # Phase 2: LLM ìµœì¢… ì„ ì •
        logger.info("--- [Phase 2] LLM ê¸°ë°˜ ìµœì¢… Watchlist ì„ ì • ì‹œì‘ ---")
        update_pipeline_status(
            phase=1, phase_name="Hunter Scout", status="running", 
            total_candidates=len(candidate_stocks)
        )
        
        # =============================================================
        # [v1.0] í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§ ëª¨ë“œ ë¶„ê¸°
        # =============================================================
        if is_hybrid_scoring_enabled():
            logger.info("=" * 60)
            logger.info("   ğŸš€ Scout v1.0 Hybrid Scoring Mode í™œì„±í™”!")
            logger.info("=" * 60)
            
            try:
                from shared.hybrid_scoring import (
                    QuantScorer, HybridScorer, 
                    create_hybrid_scoring_tables,
                    format_quant_score_for_prompt,
                )
                from shared.market_regime import MarketRegimeDetector
                
                # DB í…Œì´ë¸” ìƒì„± í™•ì¸
                create_hybrid_scoring_tables(db_conn)
                
                # ì‹œì¥ êµ­ë©´ ê°ì§€
                kospi_prices = database.get_daily_prices(db_conn, "0001", limit=60)
                if not kospi_prices.empty:
                    detector = MarketRegimeDetector()
                    current_regime, _ = detector.detect_regime(kospi_prices, float(kospi_prices['CLOSE_PRICE'].iloc[-1]), quiet=True)
                else:
                    current_regime = "SIDEWAYS"
                
                logger.info(f"   í˜„ì¬ ì‹œì¥ êµ­ë©´: {current_regime}")
                
                # QuantScorer ì´ˆê¸°í™”
                quant_scorer = QuantScorer(db_conn, market_regime=current_regime)
                
                # Step 1: ì •ëŸ‰ ì ìˆ˜ ê³„ì‚° (LLM í˜¸ì¶œ ì—†ìŒ, ë¹„ìš© 0ì›)
                logger.info(f"\n   [v5 Step 1] ì •ëŸ‰ ì ìˆ˜ ê³„ì‚° ({len(candidate_stocks)}ê°œ ì¢…ëª©) - ë¹„ìš© 0ì›")
                quant_results = {}
                
                for code, info in candidate_stocks.items():
                    if code == '0001':
                        continue
                    stock_info = {
                        'code': code,
                        'info': info,
                        'snapshot': snapshot_cache.get(code),
                    }
                    quant_results[code] = process_quant_scoring_task(
                        stock_info, quant_scorer, db_conn, kospi_prices
                    )
                
                # Step 2: ì •ëŸ‰ ê¸°ë°˜ 1ì°¨ í•„í„°ë§ (í•˜ìœ„ 50% íƒˆë½)
                logger.info(f"\n   [v5 Step 2] ì •ëŸ‰ ê¸°ë°˜ 1ì°¨ í•„í„°ë§ (í•˜ìœ„ 50% íƒˆë½)")
                quant_result_list = list(quant_results.values())
                filtered_results = quant_scorer.filter_candidates(quant_result_list, cutoff_ratio=0.5)
                
                filtered_codes = {r.stock_code for r in filtered_results}
                logger.info(f"   âœ… ì •ëŸ‰ í•„í„° í†µê³¼: {len(filtered_codes)}ê°œ (í‰ê·  ì ìˆ˜: {sum(r.total_score for r in filtered_results)/len(filtered_results):.1f}ì )")
                
                # Step 3: LLM ì •ì„± ë¶„ì„ (í†µê³¼ ì¢…ëª©ë§Œ)
                logger.info(f"\n   [v5 Step 3] LLM ì •ì„± ë¶„ì„ (í†µê³„ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)")
                
                final_approved_list: List[Dict] = []
                if '0001' in candidate_stocks:
                    final_approved_list.append({'code': '0001', 'name': 'KOSPI', 'is_tradable': False})
                
                llm_decision_records: Dict[str, Dict] = {}
                llm_max_workers = max(1, _parse_int_env(os.getenv("SCOUT_LLM_MAX_WORKERS"), 4))
                
                # Phase 1: Hunter (í†µê³„ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
                phase1_results = []
                with ThreadPoolExecutor(max_workers=llm_max_workers) as executor:
                    future_to_code = {}
                    for code in filtered_codes:
                        info = candidate_stocks[code]
                        quant_result = quant_results[code]
                        payload = {'code': code, 'info': info}
                        future = executor.submit(
                            process_phase1_hunter_v5_task, 
                            payload, brain, quant_result, snapshot_cache, news_cache
                        )
                        future_to_code[future] = code
                    
                    for future in as_completed(future_to_code):
                        result = future.result()
                        if result:
                            phase1_results.append(result)
                            if not result['passed']:
                                llm_decision_records[result['code']] = {
                                    'code': result['code'],
                                    'name': result['name'],
                                    'llm_score': result['hunter_score'],
                                    'llm_reason': result['hunter_reason'],
                                    'is_tradable': False,
                                    'approved': False,
                                    'hunter_score': result['hunter_score'],
                                    'llm_metadata': {'llm_grade': 'D', 'source': 'v5_hunter_reject'}
                                }
                
                phase1_passed = [r for r in phase1_results if r['passed']]
                logger.info(f"   âœ… v5 Hunter í†µê³¼: {len(phase1_passed)}/{len(filtered_codes)}ê°œ")
                
                # Phase 2-3: Debate + Judge (ìƒìœ„ ì¢…ëª©ë§Œ)
                PHASE2_MAX = int(os.getenv("SCOUT_PHASE2_MAX_ENTRIES", "50"))
                if len(phase1_passed) > PHASE2_MAX:
                    phase1_passed_sorted = sorted(phase1_passed, key=lambda x: x['hunter_score'], reverse=True)
                    phase1_passed = phase1_passed_sorted[:PHASE2_MAX]
                
                if phase1_passed:
                    logger.info(f"\n   [v5 Step 4] Debate + Judge (í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê²°í•©)")
                    
                    with ThreadPoolExecutor(max_workers=llm_max_workers) as executor:
                        future_to_code = {}
                        for p1_result in phase1_passed:
                            future = executor.submit(process_phase23_judge_v5_task, p1_result, brain)
                            future_to_code[future] = p1_result['code']
                        
                        for future in as_completed(future_to_code):
                            record = future.result()
                            if record:
                                llm_decision_records[record['code']] = record
                                if record.get('approved'):
                                    final_approved_list.append(_record_to_watchlist_entry(record))
                
                logger.info(f"   âœ… v5 ìµœì¢… ìŠ¹ì¸: {len([r for r in llm_decision_records.values() if r.get('approved')])}ê°œ")
                
                # ì¿¼í„°ì œ ì ìš©
                MAX_WATCHLIST_SIZE = 15
                if len(final_approved_list) > MAX_WATCHLIST_SIZE:
                    final_approved_list_sorted = sorted(
                        final_approved_list,
                        key=lambda x: x.get('llm_score', 0),
                        reverse=True
                    )
                    final_approved_list = final_approved_list_sorted[:MAX_WATCHLIST_SIZE]
                
                logger.info(f"\n   ğŸ Scout v1.0 ì™„ë£Œ: {len(final_approved_list)}ê°œ ì¢…ëª© ì„ ì •")
                _v5_completed = True
                
            except Exception as e:
                logger.error(f"âŒ Scout v1.0 ì‹¤í–‰ ì˜¤ë¥˜, v4 ëª¨ë“œë¡œ í´ë°±: {e}", exc_info=True)
                _v5_completed = False
        else:
            _v5_completed = False
        
        # =============================================================
        # [v4.x] ê¸°ì¡´ LLM ê¸°ë°˜ ì„ ì • ë¡œì§ (v5 ë¯¸í™œì„±í™” ë˜ëŠ” ì‹¤íŒ¨ ì‹œ)
        # =============================================================
        if not _v5_completed:
            logger.info("   (Mode) v4.x ê¸°ì¡´ LLM ê¸°ë°˜ ë¡œì§ ì‹¤í–‰")
            
            # [v4.3] ìƒˆë¡œìš´ ìºì‹œ ì‹œìŠ¤í…œ - LLM_EVAL_CACHE í…Œì´ë¸” ê¸°ë°˜ ì§ì ‘ ë¹„êµ
            llm_cache_snapshot = _load_llm_cache_from_db(db_conn)
            llm_max_workers = max(1, _parse_int_env(os.getenv("SCOUT_LLM_MAX_WORKERS"), 4))
            
            # ì˜¤ëŠ˜ ë‚ ì§œ (KST ê¸°ì¤€)
            kst = timezone(timedelta(hours=9))
            today_str = datetime.now(kst).strftime("%Y-%m-%d")

            final_approved_list: List[Dict] = []
            if '0001' in candidate_stocks:
                final_approved_list.append({'code': '0001', 'name': 'KOSPI', 'is_tradable': False})
                del candidate_stocks['0001']

            llm_decision_records: Dict[str, Dict] = {}
            cache_hits = 0
            pending_codes: List[str] = []
            cache_miss_reasons: Dict[str, str] = {}  # ë””ë²„ê¹…ìš©

            for code, info in candidate_stocks.items():
                cached = llm_cache_snapshot.get(code)
                
                # [v4.3] ì§ì ‘ ë¹„êµë¡œ ìºì‹œ ìœ íš¨ì„± ê²€ì¦
                current_data = {
                    'price_bucket': _get_price_bucket(info.get('price', 0)),
                    'volume_bucket': _get_volume_bucket(info.get('volume', 0)),
                    'news_hash': info.get('news_hash'),
                }
                
                if _is_cache_valid_direct(cached, current_data, today_str):
                    # ìºì‹œ ì ì¤‘ - ì´ì „ LLM ê²°ê³¼ ì¬ì‚¬ìš©
                    llm_decision_records[code] = {
                        'code': code,
                        'name': info['name'],
                        'llm_score': cached.get('judge_score') or cached.get('hunter_score', 0),
                        'llm_reason': cached.get('llm_reason', ''),
                        'is_tradable': cached.get('is_tradable', False),
                        'approved': cached.get('is_approved', False),
                        'llm_metadata': {
                            'llm_grade': cached.get('llm_grade'),
                            'source': 'cache',
                        }
                    }
                    cache_hits += 1
                    if cached.get('is_approved'):
                        final_approved_list.append(_record_to_watchlist_entry(llm_decision_records[code]))
                else:
                    # ìºì‹œ ë¯¸ìŠ¤ - LLM ì¬í˜¸ì¶œ í•„ìš”
                    pending_codes.append(code)
                    # ë¯¸ìŠ¤ ì›ì¸ ê¸°ë¡ (ë””ë²„ê¹…ìš©)
                    if not cached:
                        cache_miss_reasons[code] = "no_cache"
                    elif cached.get('eval_date') != today_str:
                        cache_miss_reasons[code] = f"date({cached.get('eval_date')}!={today_str})"
                    elif cached.get('price_bucket') != current_data['price_bucket']:
                        cache_miss_reasons[code] = f"price({cached.get('price_bucket')}!={current_data['price_bucket']})"
                    elif (cached.get('news_hash') or '') != (current_data.get('news_hash') or ''):
                        cache_miss_reasons[code] = "news_changed"

            if cache_hits:
                logger.info(f"   (LLM) âœ… ìºì‹œ ì ì¤‘ {cache_hits}ê±´ (ì˜¤ëŠ˜ ë‚ ì§œ + ë™ì¼ ê°€ê²©/ë‰´ìŠ¤)")
            
            if pending_codes:
                # ìºì‹œ ë¯¸ìŠ¤ ì›ì¸ ë¶„ì„
                reason_counts = {}
                for reason in cache_miss_reasons.values():
                    reason_type = reason.split("(")[0]
                    reason_counts[reason_type] = reason_counts.get(reason_type, 0) + 1
                logger.info(f"   (LLM) âš ï¸ ìºì‹œ ë¯¸ìŠ¤ {len(pending_codes)}ê±´ - ì›ì¸: {reason_counts}")

            need_llm_calls = len(pending_codes) > 0

            llm_invocation_count = 0
            if need_llm_calls:
                if brain is None:
                    logger.error("   (LLM) JennieBrain ì´ˆê¸°í™” ì‹¤íŒ¨ë¡œ ì‹ ê·œ í˜¸ì¶œì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # [v3.8] 2-Pass ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
                    # Pass 1: Phase 1 Hunter (Gemini-Flash) - ë³‘ë ¬ë¡œ ë¹ ë¥´ê²Œ í•„í„°ë§
                    logger.info(f"   (LLM) [Pass 1] Phase 1 Hunter ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘ ({len(pending_codes)}ê°œ ì¢…ëª©)")
                    update_pipeline_status(
                        phase=1, phase_name="Hunter Scout", status="running",
                        total_candidates=len(candidate_stocks)
                    )
                    phase1_start = time.time()
                    
                    phase1_results = []
                    # [v4.1] Claude Rate Limit ëŒ€ì‘: ì›Œì»¤ ìˆ˜ ì œí•œ (ê¸°ì¡´ *2 ì œê±°)
                    phase1_worker_count = min(llm_max_workers, max(1, len(pending_codes)))
                    logger.info(f"   (LLM) Phase 1 ì›Œì»¤ ìˆ˜: {phase1_worker_count}ê°œ (Rate Limit ëŒ€ì‘)")
                    
                    with ThreadPoolExecutor(max_workers=phase1_worker_count) as executor:
                        future_to_code = {}
                        for code in pending_codes:
                            payload = {
                                'code': code,
                                'info': candidate_stocks[code],
                            }
                            # [v4.2] ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒí•˜ë„ë¡ ë³€ê²½ (API í˜¸ì¶œ X)
                            future = executor.submit(process_phase1_hunter_task, payload, brain, snapshot_cache, news_cache)
                            future_to_code[future] = code
                        
                        for future in as_completed(future_to_code):
                            result = future.result()
                            if result:
                                phase1_results.append(result)
                                # Phase 1 íƒˆë½ ì¢…ëª©ë„ ê¸°ë¡ (ìºì‹œìš©)
                                if not result['passed']:
                                    llm_decision_records[result['code']] = {
                                        'code': result['code'],
                                        'name': result['name'],
                                        'is_tradable': False,
                                        'llm_score': result['hunter_score'],
                                        'llm_reason': result['hunter_reason'] or 'Phase 1 í•„í„°ë§ íƒˆë½',
                                        'approved': False,
                                        'hunter_score': result['hunter_score'],  # [v4.3] ìºì‹œ ì €ì¥ìš©
                                        'llm_metadata': {
                                            'llm_grade': 'D',
                                            'llm_updated_at': _utcnow().isoformat(),
                                            'source': 'llm_hunter_reject',
                                        }
                                    }
                    
                    phase1_passed_all = [r for r in phase1_results if r['passed']]
                    phase1_time = time.time() - phase1_start
                    logger.info(f"   (LLM) [Pass 1] Phase 1 ì™„ë£Œ: {len(phase1_passed_all)}/{len(pending_codes)}ê°œ í†µê³¼ ({phase1_time:.1f}ì´ˆ)")
                    
                    # [v4.1] Phase 2 ì§„ì… ì œí•œ: ìƒìœ„ 50ê°œë§Œ (ì†ë„ ìµœì í™”)
                    PHASE2_MAX_ENTRIES = int(os.getenv("SCOUT_PHASE2_MAX_ENTRIES", "50"))
                    if len(phase1_passed_all) > PHASE2_MAX_ENTRIES:
                        phase1_passed_sorted = sorted(phase1_passed_all, key=lambda x: x['hunter_score'], reverse=True)
                        phase1_passed = phase1_passed_sorted[:PHASE2_MAX_ENTRIES]
                        logger.info(f"   (LLM) [ì†ë„ ìµœì í™”] Phase 2 ì§„ì… ì œí•œ: ìƒìœ„ {PHASE2_MAX_ENTRIES}ê°œë§Œ ì„ íƒ (ì „ì²´ {len(phase1_passed_all)}ê°œ ì¤‘)")
                    else:
                        phase1_passed = phase1_passed_all
                    
                    # [v1.0] Redis ìƒíƒœ ì—…ë°ì´íŠ¸ - Phase 1 ì™„ë£Œ
                    update_pipeline_status(
                        phase=2, phase_name="Bull vs Bear Debate", status="running",
                        total_candidates=len(candidate_stocks),
                        passed_phase1=len(phase1_passed_all)  # ì „ì²´ í†µê³¼ ìˆ˜ í‘œì‹œ
                    )
                    
                    # Pass 2: Phase 2-3 Debate+Judge (GPT-5-mini) - ìƒìœ„ ì¢…ëª©ë§Œ
                    if phase1_passed:
                        logger.info(f"   (LLM) [Pass 2] Phase 2-3 Debate-Judge ì‹¤í–‰ ({len(phase1_passed)}ê°œ ì¢…ëª©)")
                        phase23_start = time.time()
                        
                        phase23_worker_count = min(llm_max_workers, max(1, len(phase1_passed)))
                        
                        with ThreadPoolExecutor(max_workers=phase23_worker_count) as executor:
                            future_to_code = {}
                            for phase1_result in phase1_passed:
                                future = executor.submit(process_phase23_debate_judge_task, phase1_result, brain)
                                future_to_code[future] = phase1_result['code']
                            
                            for future in as_completed(future_to_code):
                                record = future.result()
                                if not record:
                                    continue
                                llm_invocation_count += 1
                                llm_decision_records[record['code']] = record
                                if record.get('approved'):
                                    final_approved_list.append(_record_to_watchlist_entry(record))
                        
                        phase23_time = time.time() - phase23_start
                        logger.info(f"   (LLM) [Pass 2] Phase 2-3 ì™„ë£Œ ({phase23_time:.1f}ì´ˆ)")
                        
                        # [v1.0] Redis ìƒíƒœ ì—…ë°ì´íŠ¸ - Phase 2-3 ì™„ë£Œ
                        update_pipeline_status(
                            phase=3, phase_name="Final Judge", status="running",
                            total_candidates=len(candidate_stocks),
                            passed_phase1=len(phase1_passed),
                            passed_phase2=len(phase1_passed),  # Debateì€ ì „ì› ì°¸ì—¬
                            final_selected=len(final_approved_list)
                        )
                    else:
                        logger.info("   (LLM) [Pass 2] Phase 1 í†µê³¼ ì¢…ëª© ì—†ìŒ, Phase 2-3 ê±´ë„ˆëœ€")
            else:
                logger.info("   (LLM) ëª¨ë“  í›„ë³´ê°€ ìºì‹œë¡œ ì¶©ì¡±ë˜ì–´ ì‹ ê·œ í˜¸ì¶œì´ ì—†ìŠµë‹ˆë‹¤.")

            logger.info("   (LLM) ì‹ ê·œ í˜¸ì¶œ ìˆ˜: %d", llm_invocation_count)

            # [v4.3] ìƒˆë¡œìš´ ìºì‹œ í…Œì´ë¸”ì— ê²°ê³¼ ì €ì¥
            if llm_invocation_count > 0:
                new_cache_entries = {}
                for code, record in llm_decision_records.items():
                    info = candidate_stocks.get(code, {})
                    new_cache_entries[code] = {
                        'stock_name': record.get('name', ''),
                        'price_bucket': _get_price_bucket(info.get('price', 0)),
                        'volume_bucket': _get_volume_bucket(info.get('volume', 0)),
                        'news_hash': info.get('news_hash'),
                        'eval_date': today_str,
                        'hunter_score': record.get('hunter_score', record.get('llm_score', 0)),
                        'judge_score': record.get('llm_score', 0),
                        'llm_grade': record.get('llm_metadata', {}).get('llm_grade'),
                        'llm_reason': record.get('llm_reason', ''),
                        'news_used': news_cache.get(code, ''),
                        'is_approved': record.get('approved', False),
                        'is_tradable': record.get('is_tradable', False),
                    }
                _save_llm_cache_batch(db_conn, new_cache_entries)
                _save_last_llm_run_at(db_conn, _utcnow())

            # [v1.0] Phase 3: ì¿¼í„°ì œ ì ìš© (Top 15ê°œë§Œ ì €ì¥) - ì œë‹ˆ í”¼ë“œë°± ë°˜ì˜
            MAX_WATCHLIST_SIZE = 15
            
            # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ ìƒìœ„ Nê°œë§Œ ì„ íƒ
            if len(final_approved_list) > MAX_WATCHLIST_SIZE:
                final_approved_list_sorted = sorted(
                    final_approved_list, 
                    key=lambda x: x.get('llm_score', 0), 
                    reverse=True
                )
                final_approved_list = final_approved_list_sorted[:MAX_WATCHLIST_SIZE]
                logger.info(f"   (ì¿¼í„°ì œ) ìƒìœ„ {MAX_WATCHLIST_SIZE}ê°œë§Œ ì„ ì • (ì´ {len(final_approved_list_sorted)}ê°œ ì¤‘)")
        
        # =============================================================
        # [ê³µí†µ] Phase 3: ìµœì¢… Watchlist ì €ì¥
        # =============================================================
        logger.info(f"--- [Phase 3] ìµœì¢… Watchlist {len(final_approved_list)}ê°œ ì €ì¥ ---")
        database.save_to_watchlist(db_conn, final_approved_list)
        
        with ThreadPoolExecutor(max_workers=10) as executor:
            if hasattr(kis_api, 'API_CALL_DELAY'):
                future_to_data = {
                    executor.submit(fetch_kis_data_task, s, kis_api): (time.sleep(kis_api.API_CALL_DELAY), s)[1]
                    for s in final_approved_list 
                }
            else:
                future_to_data = {
                    executor.submit(fetch_kis_data_task, s, kis_api): s
                    for s in final_approved_list 
                }
            
            all_daily = []
            all_fund = []
            for future in as_completed(future_to_data):
                d, f = future.result()
                if d: all_daily.extend(d)
                if f: all_fund.append(f)
        
        if all_daily: database.save_all_daily_prices(db_conn, all_daily)
        if all_fund: database.update_all_stock_fundamentals(db_conn, all_fund)
        
        # Phase 3-A: ì¬ë¬´ ë°ì´í„° (ë„¤ì´ë²„ í¬ë¡¤ë§)
        tradable_codes = [s['code'] for s in final_approved_list if s.get('is_tradable', True)]
        if tradable_codes:
            batch_update_watchlist_financial_data(db_conn, tradable_codes)
        
        # [v1.0] Redis ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸ - ì™„ë£Œ
        update_pipeline_status(
            phase=3, phase_name="Final Judge", status="completed",
            progress=100,
            total_candidates=len(candidate_stocks) if 'candidate_stocks' in dir() else 0,
            passed_phase1=len(phase1_passed) if 'phase1_passed' in dir() else 0,
            passed_phase2=len(phase1_passed) if 'phase1_passed' in dir() else 0,
            final_selected=len(final_approved_list)
        )
        
        # [v1.0] Redis ê²°ê³¼ ì €ì¥ (Dashboardì—ì„œ ì¡°íšŒìš©)
        pipeline_results = [
            {
                "stock_code": s.get('code'),
                "stock_name": s.get('name'),
                "grade": s.get('llm_metadata', {}).get('llm_grade', 'C'),
                "final_score": s.get('llm_score', 0),
                "selected": s.get('approved', False),
                "judge_reason": s.get('llm_reason', ''),
            }
            for s in final_approved_list
        ]
        save_pipeline_results(pipeline_results)
        logger.info(f"   (Redis) Dashboardìš© ê²°ê³¼ ì €ì¥ ì™„ë£Œ ({len(pipeline_results)}ê°œ)")

    except Exception as e:
        logger.critical(f"âŒ 'Scout Job' ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
        # [v1.0] ì˜¤ë¥˜ ì‹œ Redis ìƒíƒœ ì—…ë°ì´íŠ¸
        update_pipeline_status(phase=0, phase_name="Error", status="error")
    
    finally:
        if db_conn:
            db_conn.close()
            logger.info("--- [DB] ì—°ê²° ì¢…ë£Œ ---")
            
    logger.info(f"--- ğŸ¤– 'Scout Job' ì¢…ë£Œ (ì†Œìš”: {time.time() - start_time:.2f}ì´ˆ) ---")

if __name__ == "__main__":
    main()
