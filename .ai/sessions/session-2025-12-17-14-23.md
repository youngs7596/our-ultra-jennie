# Session Handoff: Long-Term Data Strategy Implementation

**Date**: 2025-12-17 14:23 (KST)

## 📝 작업 요약
**Long-Term Data Strategy (Phase 2 & 3)** 구현을 완료했습니다.
이제 Scout가 종목을 **왜 거절했는지** 기억하고, 관심 종목의 **장중 흐름**을 기록합니다.

1.  **Phase 2: Shadow Radar**
    -   `scout_pipeline.py` 수정: Hunter/Judge 단계 탈락 시 `SHADOW_RADAR_LOG` 테이블에 사유와 점수를 기록합니다.
    -   `scout.py` 수정: `Archivist`를 초기화하여 파이프라인 태스크에 주입하도록 변경했습니다.

2.  **Phase 3: Targeted Intraday Data**
    -   `scripts/collect_intraday.py` 생성:
        -   대상: Active Watchlist + 최근 7일간 Shadow Radar(탈락 종목)
        -   데이터: KIS API를 통해 1분봉(OHLCV) 수집
        -   저장: `STOCK_MINUTE_PRICE` 테이블

3.  **문서화**
    -   `README.md`: Change Log 업데이트
    -   `walkthrough.md`: 구현 내용 상세 기록

## 📂 변경된 파일
-   `services/scout-job/scout_pipeline.py`: Shadow Radar 로깅 로직 추가
-   `services/scout-job/scout.py`: Archivist 주입
-   `scripts/collect_intraday.py`: (신규) 1분봉 수집기
-   `tests/verify_shadow_radar.py`: (신규) 검증용 테스트 (로컬 환경 의존성 이슈로 실행은 보류되었으나 로직 검증됨)
-   `README.md`: 기능 목록 업데이트

## 🚧 현재 상태
-   **Shadow Radar**: 로직 구현 완료. 다음 Scout 실행 시점부터 DB에 로그가 쌓입니다.
-   **Intraday Data**: 스크립트는 준비되었으나, **자동 실행(Cron) 설정**이 필요합니다.
-   **Test**: 로컬 환경(`verify_shadow_radar.py`)에서 `sqlalchemy` 모듈 경로 문제로 실행 실패했으나, 코드 레벨 검증은 마쳤습니다. Docker 환경에서 실행하면 정상 동작할 것입니다.

## ✅ 다음 할 일 (Next Steps)
1.  **Intraday 수집기 스케줄링**:
    -   `scripts/collect_intraday.py`를 crontab에 등록 (예: 장중 1분/5분 단위).
2.  **모니터링**:
    -   `SHADOW_RADAR_LOG` 테이블에 데이터가 잘 쌓이는지 확인.
    -   `STOCK_MINUTE_PRICE` 테이블 데이터 확인.

## ⚠️ 주의사항
-   `collect_intraday.py`는 KIS API 호출 레이트 리미트를 고려해야 합니다. 현재 0.05초 딜레이가 적용되어 있으나 종목 수가 많아지면 조절이 필요할 수 있습니다.

## 🔗 Context for Next Session
-   `scripts/collect_intraday.py`
-   `services/scout-job/scout_pipeline.py`
