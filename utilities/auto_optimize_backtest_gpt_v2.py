#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
auto_optimize_backtest_gpt_v2.py
--------------------------------

`backtest_gpt_v2.py` íŒŒë¼ë¯¸í„°ë¥¼ ë‹¤ì–‘í•œ ì¡°í•©ìœ¼ë¡œ ë³‘ë ¬ ì‹¤í–‰í•´
ê°€ì¥ í˜„ì‹¤ì ì¸ ì„±ê³¼(ê³ ìˆ˜ìµ/ì €ë³€ë™)ë¥¼ ë‚´ëŠ” ì¡°í•©ì„ íƒìƒ‰í•˜ëŠ” ìœ í‹¸ë¦¬í‹°.

- AMD 7800X3D (16 ì“°ë ˆë“œ) í™˜ê²½ì„ ê³ ë ¤í•´ ê¸°ë³¸ì ìœ¼ë¡œ ë…¼ë¦¬ ì½”ì–´ ì ˆë°˜ë§Œ ì‚¬ìš©
- í•„ìš”í•œ íŒŒë¼ë¯¸í„°ë§Œ ê³¨ë¼ ìƒ˜í”Œë§í•˜ê³ , ì¡°í•© ìˆ˜ê°€ ë§ì„ ê²½ìš° ëœë¤ ìƒ˜í”Œë¡œ ì œí•œ
- ê° ì‹¤í–‰ì€ 45ì¼/60ì¼ ë“± ì§§ì€ êµ¬ê°„ì„ ì‚¬ìš©í•´ ë¹ ë¥´ê²Œ ê²½í–¥ì„ í™•ì¸
"""

from __future__ import annotations

import argparse
import itertools
import json
import logging
import os
import random
import re
import subprocess
import sys
import time
import uuid
from concurrent.futures import ProcessPoolExecutor, as_completed
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
BACKTEST_SCRIPT = os.path.join(PROJECT_ROOT, "utilities", "backtest_gpt_v2.py")
DEFAULT_LOG_DIR = os.path.join(PROJECT_ROOT, "logs")

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger("gpt_v2_optimizer")


# ---------------------------------------------------------------------------
# íŠœë‹ ëŒ€ìƒ íŒŒë¼ë¯¸í„° (ì‹¤ì„œë¹„ìŠ¤ ì˜ì‚¬ê²°ì •ì— ì˜í–¥ì´ í° í•­ëª©ë“¤ ìœ„ì£¼)
# ---------------------------------------------------------------------------

PARAMETER_GRID = {
    # ë§¤ìˆ˜ ì¡°ê±´
    "rsi_buy": [25, 30, 35],
    "breakout_buffer_pct": [0.3, 0.5, 0.8],
    "bb_buffer_pct": [1.0, 1.5, 2.0],
    "llm_threshold": [65, 70, 75],

    # í¬ì§€ì…˜ / ìê¸ˆ
    "max_position_allocation": [10.0, 12.0, 15.0],
    "max_stock_pct": [12.0, 15.0],
    "max_sector_pct": [30.0, 35.0],
    "cash_keep_pct": [3.0, 5.0],

    # ë§¤ë„ ì¡°ê±´
    "target_profit_pct": [6.0, 8.0, 10.0],
    "base_stop_loss_pct": [4.0, 5.0, 6.0],
    "stop_loss_atr_mult": [1.6, 1.8, 2.0],
    "sell_rsi_1": [68.0, 70.0],
    "sell_rsi_2": [73.0, 75.0],
    "sell_rsi_3": [78.0, 80.0],

    # ì‹¤í–‰ ë¹ˆë„
    "max_buys_per_day": [3, 4],
    "max_hold_days": [25, 30, 35],
}


# ---------------------------------------------------------------------------
# ê²°ê³¼ íŒŒì‹± & ì ìˆ˜í™”
# ---------------------------------------------------------------------------

RESULT_JSON_PATTERN = re.compile(
    r"__BACKTEST_RESULT_JSON_START__\s*({.*})\s*__BACKTEST_RESULT_JSON_END__",
    re.DOTALL,
)


def parse_backtest_output(output: str) -> Dict[str, Optional[float]]:
    """backtest_gpt_v2.py stdout/stderrì—ì„œ ì§€í‘œë¥¼ ì¶”ì¶œ."""
    result = {
        "success": False,
        "total_return_pct": None,
        "monthly_return_pct": None,
        "mdd_pct": None,
        "final_equity": None,
    }

    # JSON ë¸”ë¡ì´ ìˆë‹¤ë©´ ìš°ì„  ì‚¬ìš©
    match = RESULT_JSON_PATTERN.search(output)
    if match:
        try:
            data = json.loads(match.group(1))
            result.update({
                "success": True,
                "total_return_pct": data.get("total_return_pct"),
                "monthly_return_pct": data.get("monthly_return_pct"),
                "mdd_pct": data.get("mdd_pct"),
                "final_equity": data.get("final_equity"),
            })
            return result
        except Exception:
            pass

    def _extract(pattern: str) -> Optional[float]:
        # ë¡œê·¸ í”„ë¦¬í”½ìŠ¤(ë‚ ì§œ, ì‹œê°„, ë ˆë²¨ ë“±)ë¥¼ ê±´ë„ˆë›°ê³  ë§¤ì¹­í•˜ë„ë¡ ìˆ˜ì •
        # ì˜ˆ: "2025-11-28 15:07:14,354 - INFO - [_report] - ìµœì¢… ëˆ„ì  ìˆ˜ìµë¥ : 0.72%"
        m = re.search(pattern, output)
        return float(m.group(1)) if m else None

    result["total_return_pct"] = _extract(r"ìµœì¢… ëˆ„ì  ìˆ˜ìµë¥ :\s*([\-0-9.]+)%")
    result["monthly_return_pct"] = _extract(r"ì›”ê°„ ìˆ˜ìµë¥ :\s*([\-0-9.]+)%")
    result["mdd_pct"] = _extract(r"ìµœëŒ€ ë‚™í­\(MDD\):\s*([0-9.]+)%")
    equity_match = re.search(r"ìµœì¢… ìì‚°:\s*([0-9,]+)ì›", output)
    if equity_match:
        result["final_equity"] = float(equity_match.group(1).replace(",", ""))

    result["success"] = all(result[k] is not None for k in ("total_return_pct", "monthly_return_pct", "mdd_pct"))
    return result


def score_result(result: Dict[str, Optional[float]]) -> float:
    """ì´ ìˆ˜ìµë¥ /ì›”ê°„ ìˆ˜ìµë¥ ì„ ë†’ì´ê³ , MDDëŠ” ë‚®ì¶”ëŠ” ë°©í–¥ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°."""
    if not result["success"]:
        return -1e6

    total_return = result["total_return_pct"] or 0.0
    monthly_return = result["monthly_return_pct"] or 0.0
    mdd = result["mdd_pct"] or 0.0

    # í˜„ì‹¤ì ì¸ ì¡°í•©: ì´ ìˆ˜ìµë¥  2ë°° ê°€ì¤‘ + ì›”ê°„ 8ë°° ê°€ì¤‘ - MDD 6ë°° íŒ¨ë„í‹°
    score = total_return * 2.0 + monthly_return * 8.0 - mdd * 6.0

    # MDDê°€ 12%ë¥¼ ë„˜ì–´ê°€ë©´ ê°•í•œ í˜ë„í‹°
    if mdd > 12.0:
        score -= (mdd - 12.0) * 20.0
    return score


# ---------------------------------------------------------------------------
# ë‹¨ì¼ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì„œë¸Œ í”„ë¡œì„¸ìŠ¤)
# ---------------------------------------------------------------------------

def run_single_backtest(params: Dict[str, float], args: argparse.Namespace) -> Dict:
    unique_id = uuid.uuid4().hex[:8]
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = os.path.join(PROJECT_ROOT, "logs", "opt_runs")
    os.makedirs(log_dir, exist_ok=True)
    
    log_file_path = os.path.join(log_dir, f"backtest_{timestamp}_{unique_id}.log")

    cmd = [
        sys.executable,
        BACKTEST_SCRIPT,
        "--days", str(args.days),
        "--log-level", "INFO",
        "--log-dir", os.path.join("logs", "opt_runs"),
        "--universe-limit", str(args.universe_limit),
        "--top-n", str(args.top_n),
    ]

    for key, value in params.items():
        cmd.append(f"--{key.replace('_', '-')}")
        cmd.append(str(value))

    # stdout/stderrë¥¼ íŒŒì¼ë¡œ ë¦¬ë‹¤ì´ë ‰ì…˜ (ë©”ëª¨ë¦¬ ë²„í¼ë§ ë°©ì§€)
    try:
        started = time.time()
        with open(log_file_path, "w", encoding="utf-8") as log_file:
            proc = subprocess.run(
                cmd,
                stdout=log_file,
                stderr=subprocess.STDOUT,
                cwd=PROJECT_ROOT,
                timeout=args.timeout,
            )
        elapsed = time.time() - started

        # ê²°ê³¼ íŒŒì‹±ì„ ìœ„í•´ ë¡œê·¸ íŒŒì¼ ì½ê¸°
        # (íŒŒì¼ì´ ë„ˆë¬´ í´ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ í•„ìš”í•œ ë¶€ë¶„ë§Œ ì½ê±°ë‚˜ ì˜ˆì™¸ì²˜ë¦¬ í•  ìˆ˜ë„ ìˆìœ¼ë‚˜, 
        #  í˜„ì¬ëŠ” ê²°ê³¼ íŒŒì‹±ì„ ìœ„í•´ ì „ì²´ë¥¼ ì½ì–´ì•¼ í•¨. ë‹¨, subprocess pipe buffer ë¬¸ì œëŠ” í•´ê²°ë¨)
        if os.path.exists(log_file_path):
            with open(log_file_path, "r", encoding="utf-8", errors="replace") as f:
                output = f.read()
        else:
            output = ""

        if proc.returncode != 0:
            return {"success": False, "error": f"Process failed (code {proc.returncode})", "params": params}

        metrics = parse_backtest_output(output)
        metrics["params"] = params
        metrics["elapsed"] = elapsed
        metrics["score"] = score_result(metrics)
        return metrics

    except subprocess.TimeoutExpired:
        return {"success": False, "error": "Timeout", "params": params}
    except Exception as exc:
        return {"success": False, "error": str(exc), "params": params}
    # ë¡œê·¸ íŒŒì¼ì€ ë””ë²„ê¹…ì„ ìœ„í•´ ë‚¨ê²¨ë‘  (ì‚­ì œí•˜ì§€ ì•ŠìŒ)


# ---------------------------------------------------------------------------
# Optimizer ë³¸ì²´
# ---------------------------------------------------------------------------

@dataclass
class OptimizationResult:
    params: Dict[str, float]
    total_return_pct: float
    monthly_return_pct: float
    mdd_pct: float
    score: float
    elapsed: float = field(default=0.0)


class GPTV2Optimizer:
    def __init__(self, args: argparse.Namespace):
        self.args = args
        self.results: List[OptimizationResult] = []
        self.best_result: Optional[OptimizationResult] = None
        
        # ê¸°ë³¸ì ìœ¼ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ ìƒˆ íŒŒì¼ëª… ì‚¬ìš©
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.history_file = os.path.join(PROJECT_ROOT, f"gpt_v2_opt_results_{timestamp}.json")
        
        # Resume ëª¨ë“œì¼ ê²½ìš° ì§€ì •ëœ íŒŒì¼ ë¡œë“œ
        if self.args.resume:
            self.history_file = self.args.resume
            self._load_history()
        
        self.summary_dir = os.path.join(DEFAULT_LOG_DIR, "optimize_summary")
        os.makedirs(self.summary_dir, exist_ok=True)

    def _load_history(self):
        if not os.path.exists(self.history_file):
            logger.warning(f"Resume íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.history_file}")
            return

        try:
            with open(self.history_file, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            for entry in data.get("results", []):
                # OptimizationResult ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ ë©”ëª¨ë¦¬ì— ë¡œë“œ
                res = OptimizationResult(
                    params=entry["params"],
                    total_return_pct=entry["total_return_pct"],
                    monthly_return_pct=entry["monthly_return_pct"],
                    mdd_pct=entry["mdd_pct"],
                    score=entry["score"],
                    elapsed=entry.get("elapsed", 0.0)
                )
                self.results.append(res)
                
                # ìµœê³  ì ìˆ˜ ê°±ì‹ 
                if self.best_result is None or res.score > self.best_result.score:
                    self.best_result = res
            
            logger.info(f"ğŸ”„ ì´ì „ ê²°ê³¼ {len(self.results)}ê°œ ë¡œë“œ ì™„ë£Œ ({self.history_file})")
        except Exception as e:
            logger.error(f"ì´ë ¥ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def _should_skip(self, params: Dict[str, float]) -> bool:
        # ë©”ëª¨ë¦¬ì— ë¡œë“œëœ ê²°ê³¼ì—ì„œ ì¤‘ë³µ í™•ì¸
        for res in self.results:
            if res.params == params:
                return True
        return False

    def _save_results(self):
        payload = {
            "timestamp": datetime.now().isoformat(),
            "results": [r.__dict__ for r in self.results],
            "best": self.best_result.__dict__ if self.best_result else None,
        }
        with open(self.history_file, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        logger.info("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ (%s)", self.history_file)
        self._write_summary()

    def _write_summary(self):
        if not self.results:
            return
        sorted_results = sorted(self.results, key=lambda r: r.score, reverse=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        summary_path = os.path.join(self.summary_dir, f"gpt_v2_opt_summary_{timestamp}.txt")
        latest_path = os.path.join(self.summary_dir, "gpt_v2_opt_summary_latest.txt")

        lines = []
        lines.append("=== GPT v2 Optimization Summary ===")
        lines.append(f"ìƒì„± ì‹œê°: {datetime.now().isoformat()}")
        lines.append(f"ì´ í…ŒìŠ¤íŠ¸ ì¡°í•©: {len(self.results)}")
        if sorted_results:
            best = sorted_results[0]
            lines.append("")
            lines.append("ğŸ… Best Combination")
            lines.append(
                f"- Score {best.score:.2f} | Total {best.total_return_pct:.2f}% | "
                f"Monthly {best.monthly_return_pct:.2f}% | MDD {best.mdd_pct:.2f}% | "
                f"Elapsed {best.elapsed:.1f}s"
            )
            lines.append(f"- Params: {json.dumps(best.params, ensure_ascii=False)}")

        lines.append("")
        lines.append("Top 10 Results")
        for idx, entry in enumerate(sorted_results[:10], start=1):
            lines.append(
                f"{idx:02d}. Score {entry.score:.2f} | Total {entry.total_return_pct:.2f}% | "
                f"Monthly {entry.monthly_return_pct:.2f}% | MDD {entry.mdd_pct:.2f}% | "
                f"Elapsed {entry.elapsed:.1f}s | Params={json.dumps(entry.params, ensure_ascii=False)}"
            )

        text = "\n".join(lines)
        with open(summary_path, "w", encoding="utf-8") as f:
            f.write(text)
        with open(latest_path, "w", encoding="utf-8") as f:
            f.write(text)
        logger.info("ğŸ“ ìš”ì•½ íŒŒì¼ ìƒì„±: %s", summary_path)

    def generate_param_sets(self) -> List[Dict[str, float]]:
        param_names = list(PARAMETER_GRID.keys())
        param_values = list(PARAMETER_GRID.values())

        combinations = []
        for combo in itertools.product(*param_values):
            params = dict(zip(param_names, combo))
            if not self._should_skip(params):
                combinations.append(params)

        if not combinations:
            logger.info("ì´ë¯¸ ëª¨ë“  ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í–ˆìŠµë‹ˆë‹¤.")
            return []

        if len(combinations) > self.args.max_combinations:
            combinations = random.sample(combinations, self.args.max_combinations)

        random.shuffle(combinations)
        return combinations

    def run(self):
        combos = self.generate_param_sets()
        if not combos:
            return

        cpu_count = os.cpu_count() or 8
        max_workers = min(self.args.max_workers, max(1, cpu_count // 2))
        logger.info(
            "ì´ ì¡°í•© %dê°œ / ë³‘ë ¬ worker %dê°œ (ì‹œìŠ¤í…œ ì½”ì–´ %d)",
            len(combos),
            max_workers,
            cpu_count,
        )

        completed = 0
        total_tasks = len(combos)

        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(run_single_backtest, params, self.args): params
                for params in combos
            }

            for future in as_completed(futures):
                completed += 1
                result = future.result()
                
                progress_str = f"({completed}/{total_tasks})"
                
                if result["success"]:
                    res_obj = OptimizationResult(
                        params=result["params"],
                        total_return_pct=result["total_return_pct"],
                        monthly_return_pct=result["monthly_return_pct"],
                        mdd_pct=result["mdd_pct"],
                        score=result["score"],
                        elapsed=result["elapsed"],
                    )
                    self.results.append(res_obj)
                    self._save_results()

                    if self.best_result is None or res_obj.score > self.best_result.score:
                        self.best_result = res_obj
                        logger.info(
                            f"{progress_str} âœ… ìƒˆë¡œìš´ ìµœê³  ì ìˆ˜! ìˆ˜ìµë¥  {res_obj.total_return_pct:.2f}% / "
                            f"MDD {res_obj.mdd_pct:.2f}% / ì ìˆ˜ {res_obj.score:.2f}"
                        )
                    else:
                        logger.info(
                            f"{progress_str} â„¹ï¸ ì™„ë£Œ (ì ìˆ˜ {res_obj.score:.2f})"
                        )
                else:
                    logger.warning(f"{progress_str} âŒ ì‹¤íŒ¨ - {result.get('error', 'Unknown')}")

        if not self.results:
            logger.info("ìœ íš¨í•œ ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        # ìµœì¢… ìš”ì•½ ì¶œë ¥
        if self.best_result:
            logger.info(
                f"ğŸ¯ ìµœì  ì¡°í•©: {self.best_result.params} | "
                f"ìˆ˜ìµë¥  {self.best_result.total_return_pct:.2f}% / "
                f"ì›”ê°„ {self.best_result.monthly_return_pct:.2f}% / "
                f"MDD {self.best_result.mdd_pct:.2f}% / "
                f"ì ìˆ˜ {self.best_result.score:.2f}"
            )
        else:
            logger.info("ìœ íš¨í•œ ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------

def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="backtest_gpt_v2 íŒŒë¼ë¯¸í„° ìë™ ìµœì í™” ìœ í‹¸")
    parser.add_argument("--days", type=int, default=180, help="ê° ì¡°í•© í…ŒìŠ¤íŠ¸ ê¸°ê°„ (ê¸°ë³¸ 180ì¼)")
    parser.add_argument("--universe-limit", type=int, default=50)
    parser.add_argument("--top-n", type=int, default=5)
    parser.add_argument("--max-combinations", type=int, default=80, help="ìµœëŒ€ ì‹œë„í•  ì¡°í•© ìˆ˜")
    parser.add_argument("--max-workers", type=int, default=os.cpu_count() // 2, help="ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤ ìˆ˜")
    parser.add_argument("--resume", type=str, default=None, help="ì´ì „ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (ì´ì–´í•˜ê¸°)")
    parser.add_argument("--timeout", type=int, default=600, help="ê° ë°±í…ŒìŠ¤íŠ¸ íƒ€ì„ì•„ì›ƒ(ì´ˆ)")
    return parser


def main():
    args = build_parser().parse_args()
    optimizer = GPTV2Optimizer(args)
    optimizer.run()


if __name__ == "__main__":
    main()

